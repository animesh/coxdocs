[
  {
    "objectID": "expandmultinumeric.html",
    "href": "expandmultinumeric.html",
    "title": "Expand Multi Numeric and string columns",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: ExpandMultiNumeric.cs"
  },
  {
    "objectID": "expandmultinumeric.html#multi-numeric-columns",
    "href": "expandmultinumeric.html#multi-numeric-columns",
    "title": "Expand Multi Numeric and string columns",
    "section": "3.1 Multi-numeric columns",
    "text": "3.1 Multi-numeric columns\nSelected multi-numeric columns that should be expanded using the procedure mentioned in the description section above (default: no columns are selected)."
  },
  {
    "objectID": "expandmultinumeric.html#text-columns",
    "href": "expandmultinumeric.html#text-columns",
    "title": "Expand Multi Numeric and string columns",
    "section": "3.2 Text columns",
    "text": "3.2 Text columns\nSelected text columns that should be expanded using the procedure mentioned in the description section above (default: no columns are selected)."
  },
  {
    "objectID": "ngsupload.html",
    "href": "ngsupload.html",
    "title": "NGS Upload",
    "section": "",
    "text": "Type: - Matrix Upload\nSource code: not public."
  },
  {
    "objectID": "ngsupload.html#experiment",
    "href": "ngsupload.html#experiment",
    "title": "NGS Upload",
    "section": "4.1 Experiment",
    "text": "4.1 Experiment\nIt specifies the type of NGS experiment the data is derived from (default: RNA sequencing and ribosome profiling)."
  },
  {
    "objectID": "ngsupload.html#files",
    "href": "ngsupload.html#files",
    "title": "NGS Upload",
    "section": "4.2 Files",
    "text": "4.2 Files\nWith the two buttons “Add file” and “Remove file” it is possible to select BAM Binary-sequence Alignment Format files. This format is generally used as a compact way to save an alignment and at the same time allowing efficient random access.\nPerseus doesn’t require an index file."
  },
  {
    "objectID": "ngsupload.html#strand-specificity",
    "href": "ngsupload.html#strand-specificity",
    "title": "NGS Upload",
    "section": "4.3 Strand specificity",
    "text": "4.3 Strand specificity\nIt describes which RNA library preparation method was used. Depending on this, reads will mostly be aligned to the same (sense) or opposite (anti-sense) strand as the feature. Alternatively, reads can be aligned to both strands (not stranded).\nLet’s demonstrate an expected distribution of reads according to an imaginary gene, consisting of one transcript, using each type of strand specificity. All reads marked red are those which we will take into account. Reads marked grey will be excluded from the coverage calculation.\n\nWe rule out reads with a mark because there is no intersection between them and the gene.\nAlso, we skip b marked reads because they have an opposite direction to that which we expect.\nLastly, we eliminate reads which don’t fit with the annotation (c) although such reads can potentially be evidence for another isoform of the gene.\n\n\n\n\nFigure 1: Stranded Single End Reads. Expected distribution of reads in a case of stranded and sense assay\n\n\n\n\n\nFigure 2: Stranded (anti-sense). Expected distribution of reads in a case of stranded and anti-sense assay\n\n\n\n\n\nFigure 3: Not-Stranded reads. Expected distribution of reads in a case of non-stranded assay\n\n\nPaired end sequencing produces two reads from one fragment and they should be from different strands (if reads is aligned to the same strand, we exclude such pairs).\nFor simplicity of visualization let’s represent paired end reads like this (Figure 4)\n\n\n\nFigure 4: Paired-end reads\n\n\nWe represent the paired end read like this for short. Definition of a, b and c marked reads is similar to single end reads’ case.\n\n\n\nFigure 5: Paired End Reads, Stranded (sense) or irst read from the pair is on sense strand. Expected distribution of reads in a case of stranded and sense assay\n\n\n\n\n\nFigure 6: Stranded (anti-sense)or first read is on anti-sense strand. Expected distribution of reads in a case of stranded and anti-sense assay\n\n\n\n\n\nFigure 7: Not-Stranded. Expected distribution of reads in a case of non-stranded assay\n\n\nIt’s worth to notice that for paired end reads the Persues by default calculates number of fragments for each gene, in other words it doesn’t count twice two reads of one pair.\nHint: In case the experimental design isn’t known, we recommend to use “Not stranded” as “Strand specificity”."
  },
  {
    "objectID": "ngsupload.html#genome-annotation",
    "href": "ngsupload.html#genome-annotation",
    "title": "NGS Upload",
    "section": "4.4 Genome annotation",
    "text": "4.4 Genome annotation\nCurrently the plugin supports GTF file format containing coordinates of genome regions for which the coverage will be calculated. We strongly recommend to download an annotation from the ensemble FTP server.\nGTF (General Feature Format): GTF file can start from several browser/track lines (information specific to genome browser) and comment lines (line should begin with the # character). The rest of the file consists of one line per feature, each consists of nine columns\n\nseqname - name of chromosome of scaffold\nsource - name of the program that generated this feature, or the data source (database or project name)\nfeature - the current version of Perseus takes into account just “cds” and “exon” features\nstart - start position of the feature (1-based coordinate)\nend - end position of the feature (1-based coordinate)\nscore - a floating point value\nstrand - valid entries include ‘+’ (forward) or ‘-’ (reverse)\nattributes - a semicolon-separated list of tag-value pairs\n\n“empty” columns are denoted with a “.”. Each line with “cds” and “exon” feature should contain “gene_id” or “transcript_id” tags."
  },
  {
    "objectID": "ngsupload.html#file",
    "href": "ngsupload.html#file",
    "title": "NGS Upload",
    "section": "4.5 File",
    "text": "4.5 File\nSpecified file path to the genome annotation."
  },
  {
    "objectID": "ngsupload.html#feature-type-name",
    "href": "ngsupload.html#feature-type-name",
    "title": "NGS Upload",
    "section": "4.6 Feature type name",
    "text": "4.6 Feature type name\nIt is possible to specify a feature name that will be used (third column of GTF).\nHint: It makes sense to set “Feature type name” parameter to “Exons” for RNA-seq analysis and choose “CDS” for ribosome profiling."
  },
  {
    "objectID": "ngsupload.html#number-of-threads",
    "href": "ngsupload.html#number-of-threads",
    "title": "NGS Upload",
    "section": "4.7 Number of threads",
    "text": "4.7 Number of threads\nSpecifies the number of used threads for uploading NGS data."
  },
  {
    "objectID": "ngsupload.html#calculate-rpkmfpkm",
    "href": "ngsupload.html#calculate-rpkmfpkm",
    "title": "NGS Upload",
    "section": "6.1 Calculate RPKM/FPKM",
    "text": "6.1 Calculate RPKM/FPKM\n\nUpload bam files to Perseus. The Required annotation (gtf file) can be found on ensemble’ FTP server (annotation should be in agreement with version of genome which was used for alignment). For the example we took publically available RNA-seq data of cultured primary human lung fibroblast which done in two replicates GSM759890 and GSM759891\nFilter rows based on categorical ‘Gene biotype’ column\nselect just protein_coding group.\nMake normalization dividing columns by $sum(Normalization) -&gt; Divide $\nBy definition of RPKM, divide previous result by gene length, multiply on \\(10^9\\) and finally take the \\(log_2(Basic -&gt; Combine\\ main\\ columns)\\).\nTo get TPM, normalise columns of RPKM/FPKM by sum and multiply on \\(10^6\\) .\n\n\n\n\nFigure 8: Upload bam files to Perseus"
  },
  {
    "objectID": "addnoise.html",
    "href": "addnoise.html",
    "title": "Add Noise",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: AddNoise.cs"
  },
  {
    "objectID": "addnoise.html#standard-deviation",
    "href": "addnoise.html#standard-deviation",
    "title": "Add Noise",
    "section": "3.1 Standard deviation",
    "text": "3.1 Standard deviation\nDefines the standard deviation of the noise distribution that will be added (default: 0.1)."
  },
  {
    "objectID": "sortbycolumn.html",
    "href": "sortbycolumn.html",
    "title": "Sort by Column",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: SortByColumn.cs"
  },
  {
    "objectID": "sortbycolumn.html#column",
    "href": "sortbycolumn.html#column",
    "title": "Sort by Column",
    "section": "3.1 Column",
    "text": "3.1 Column\nSelected expression/numerical column, whose values should be sorted (default: first expression column in the matrix)."
  },
  {
    "objectID": "sortbycolumn.html#descending",
    "href": "sortbycolumn.html#descending",
    "title": "Sort by Column",
    "section": "3.2 Descending",
    "text": "3.2 Descending\nIf checked, the matrix is sorted in descending order (largest to smallest value) by the defined expression/numerical column (default: unchecked). By default the matrix is sorted in ascending order (smallest to largest value) by the defined expression/numerical column."
  },
  {
    "objectID": "transpose.html",
    "href": "transpose.html",
    "title": "Transpose",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: Transpose.cs"
  },
  {
    "objectID": "transpose.html#new-column-names",
    "href": "transpose.html#new-column-names",
    "title": "Transpose",
    "section": "3.1 New column names",
    "text": "3.1 New column names\nSelected text column that specifies the new column names of the transposed matrix (default: first text column in the matrix)."
  },
  {
    "objectID": "transformationproc.html",
    "href": "transformationproc.html",
    "title": "Transformation processes",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: not public.\n\n===== Brief description =====\nAll values in the specified columns are transformed according to the given formula.\nOutput: The output matrix has the same structure as the input matrix. Values in the selected columns will be transformed."
  },
  {
    "objectID": "transformationproc.html#transformation",
    "href": "transformationproc.html#transformation",
    "title": "Transformation processes",
    "section": "2.1 Transformation",
    "text": "2.1 Transformation\nThe specified transformation formula (default: \\(log_2(x)\\)) that should be applied to all cells in the selected columns. The variable name is \\(x\\). Numbers with \\(.\\) are reagrded decimal point, \\(+\\), \\(-\\), \\(*\\), \\(/\\) and ^ can be used as well as scientific notation (e.g. \\(2.9e^{-15}\\)) is supported. Predefined functions can also be used, whose argument has to be enclosed by round brackets, e.g. \\(sin(2*x)\\)."
  },
  {
    "objectID": "transformationproc.html#columns",
    "href": "transformationproc.html#columns",
    "title": "Transformation processes",
    "section": "2.2 Columns",
    "text": "2.2 Columns\nSelected expression and/or numerical columns, where the transformation should be applied (default: all columns are selected).\n#Parameter window\n\n\n\nPerseus pop-up window: Basic -&gt; Transform"
  },
  {
    "objectID": "renamecolumns.html",
    "href": "renamecolumns.html",
    "title": "Rename Columns",
    "section": "",
    "text": "1 General\n\nType: - Matrix Processing\nHeading: - Rearrange\nSource code: RenameColumns.cs\n\n===== Brief description =====\nNew names can be specified for each expression column. The new names are typed in explicitly.\nOutput: Same matrix but with the new expression column names.\n\n\n2 Parameters\nFor each column in the matrix regardless of the type, the name can be changed manually by typing the new name for the column in the predefined text field.\n\n\n3 Parameter window\n\n{{perseus:user:activities:matrixprocessing:rearrange:rearrange-rename_columns-edited.png?direct|Perseus pop-up window: Rearrange -&gt; Rename columns}}"
  },
  {
    "objectID": "Download_Installation.html",
    "href": "Download_Installation.html",
    "title": "Download & Installation",
    "section": "",
    "text": "Downloading and using the software is free of charge.\nSimply download from here and unpack the compressed file MaxQuant.zip."
  },
  {
    "objectID": "Download_Installation.html#sec-mq-windows",
    "href": "Download_Installation.html#sec-mq-windows",
    "title": "Download & Installation",
    "section": "2.1 MaxQuant on Windows",
    "text": "2.1 MaxQuant on Windows\nSupported operation system versions (64 bit is required) are Windows 10 or 11 or Windows Server 2016, 2019, 2022.\n\nInstall .NET Framework 4.7.3 or higher: To find out whether you already have it, follow the instructions on How to Determine Which .NET Framework Versions Are Installed. If you need to, you can download the software and get installation instructions at the Microsoft Download Center.\n\nWe are currently working on making MaxQuant compatible with .Net 7. This will be bring further advantages to speed and stability of the tool.\n\nRun MaxQuant GUI Double click on MaxQuant.exe in the MaxQuant folder and specify your RAW files, experimental design and fasta files.\nStart MaxQuant Click on the Start button."
  },
  {
    "objectID": "Download_Installation.html#maxquant-on-linux",
    "href": "Download_Installation.html#maxquant-on-linux",
    "title": "Download & Installation",
    "section": "2.2 MaxQuant on Linux",
    "text": "2.2 MaxQuant on Linux\nWe are supporting MaxQuant on Ubuntu 20.04 or higher, but MaxQuant should also work on another distribution of Linux. You may run MaxQuant using Graphical User Interface. In this case, you should install Mono and follow instructions in Section 2.1 for MaxQuant on Windows starting from second point. This tutorial is focused on running MaxQuant using command line.\n\nInstall .NET Core 3.1 To find out whether you already have it, type in the command line\n\ndotnet --version\nIf you see at least version \\(3.1.100\\), then everything is ready to start MaxQuant.\nOtherwise you need to follow the installation instructions at .NET Core SDK 3.1 for your operating system.\nUbuntu 22.04 (for example)\nwget https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb\nsudo dpkg -i packages-microsoft-prod.deb\nsudo apt-get update; \\\nsudo apt-get install -y apt-transport-https && \\\nsudo apt-get update && \\\nsudo apt-get install -y dotnet-sdk-2.1\n\nEdit mqpar.xml file\n\nCurrently we highly recommend to preconfigure the mqpar.xml file in MaxQuant GUI. After transferring the file on Linux machine, do not forget to update file addresses accordingly. You can also use a programmatic way to change that.\ndotnet MaxQuant/bin/MaxQuantCmd.exe --changeFolder=new_mqpar.xml &lt;new folder with fasta files&gt; &lt;new folder with raw files&gt; old_mqpar.xml\nHowever if you feel familiar with a structure of mqpar.xml, you may create a template of mqpar.xml and edit it directly.\ndotnet MaxQuant/bin/MaxQuantCmd.exe --create new_mqpar.xml\n\nRun MaxQuant\n\ndotnet MaxQuant/bin/MaxQuantCmd.exe mqpar.xml"
  },
  {
    "objectID": "troubleshooting.html",
    "href": "troubleshooting.html",
    "title": "Trouble Shooting",
    "section": "",
    "text": "Q: Cannot load raw files\nA: Check if .NET and MSFileReader are installed on your computer\n\nQ: “MSFileReader appears not to be installed” error message\nA: If the software has been successfully installed, but this error message appears, try to uninstall and then re-install the MSFileReader again. Restarting the computer may also be necessary\n\nQ: No spectra are displayed\nA: Check the “Exists” status in the Viewer for each file – if it is false, the location of the raw files has changed and has to be updated. Select all files for which the location has to be updated and use “Change folder” to navigate to the correct location\n\nQ: The MS Feature View is either empty or does not display updated information\nA: Use the refresh button the Feature Controls section\n\nQ: No MaxQuant identifications are loaded\n\nA1: Make sure the raw files are in the same folder as all index files, the mqpar.xml file and all output folders created by MaxQuant during the processing.\nA2: Make sure you are using the same MaxQuant version that was used for processing the raw data\n\nQ: I have a problem that is not listed here\nA: Try asking on one of our google groups\n\nQ: I want to report a bug\nA: Use our bugs tracking system"
  },
  {
    "objectID": "rowcorrelations.html",
    "href": "rowcorrelations.html",
    "title": "Row Correlations",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: not public."
  },
  {
    "objectID": "rowcorrelations.html#type",
    "href": "rowcorrelations.html#type",
    "title": "Row Correlations",
    "section": "3.1 Type",
    "text": "3.1 Type\nDefines the measure of correlation that should be calculated between the selected rows (default: Pearson correlation). It can be selected from a list of correlation coefficients:\n\nLog2(Absence-presence enrichment factor)\nAbsence-presence -Log10(p-value)\nNumbers of valid pairs\nValid pairs percentage\nPearson correlation\n-Log10(Pearson p-value)\n-Log10(Pearson p-value) [correlation]\n-Log10(Pearson p-value) [anti-correlation]\nR squared\nSpearman rank correlation\n-Log10(Spearman p-value)\n-Log10(Spearman p-value) [correlation]\n-Log10(Spearman p-value) [anti-correlation]\nKendall rank correlation\nDistance correlation\nMutual information\nEuclidean distance\nManhattan distance\nMaximum distance"
  },
  {
    "objectID": "rowcorrelations.html#select-columns-based-on",
    "href": "rowcorrelations.html#select-columns-based-on",
    "title": "Row Correlations",
    "section": "3.2 Select columns based on",
    "text": "3.2 Select columns based on\nSelected categorical/text column that filters the rows of the input matrix (default: ). If  is chosen, all rows of the original matrix will become columns of the correlation matrix ."
  },
  {
    "objectID": "rowcorrelations.html#column-terms",
    "href": "rowcorrelations.html#column-terms",
    "title": "Row Correlations",
    "section": "3.3 Column terms",
    "text": "3.3 Column terms\nFiltering option to only include rows, which match the specified input term(s) in the selected column in “Select columns based on” (default: empty). Inclusion of multiple terms is possible in the predefined field and have to be separated by new lines. Each row is one term."
  },
  {
    "objectID": "rowcorrelations.html#select-rows-based-on",
    "href": "rowcorrelations.html#select-rows-based-on",
    "title": "Row Correlations",
    "section": "3.4 Select rows based on",
    "text": "3.4 Select rows based on\nSelected categorical/text column that filters the rows of the input matrix (default: ). If  is chosen, all rows of the original matrix will become rows of the correlation matrix ."
  },
  {
    "objectID": "rowcorrelations.html#row-terms",
    "href": "rowcorrelations.html#row-terms",
    "title": "Row Correlations",
    "section": "3.5 Row terms",
    "text": "3.5 Row terms\nFiltering option to only include rows, which match the specified input term(s) in the previously selected column in “Select rows based on” (default: empty). Inclusion of multiple terms is possible in the predefined field and have to be separated by new lines. Each row is one term."
  },
  {
    "objectID": "summarystatisticscolumns.html",
    "href": "summarystatisticscolumns.html",
    "title": "Summary statistics (columns)",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: SummaryStatisticsColumns.cs"
  },
  {
    "objectID": "summarystatisticscolumns.html#columns",
    "href": "summarystatisticscolumns.html#columns",
    "title": "Summary statistics (columns)",
    "section": "3.1 Columns",
    "text": "3.1 Columns\nSelected expression/numerical columns for which the later defined quantities should be calculated."
  },
  {
    "objectID": "summarystatisticscolumns.html#calculate",
    "href": "summarystatisticscolumns.html#calculate",
    "title": "Summary statistics (columns)",
    "section": "3.2 Calculate",
    "text": "3.2 Calculate\nList of quantities that are calculated for the selected columns (default: all of the below listed quantities are selected). The available quantities are:\n\nSum\nMean\nTurkey biweight\nStandard deviation\nCoefficient of variation\nMedian absolute deviation\nMinimum\nMaximum\nRange\nValid values\nInter-quartile range\n1st quartile\n3rd quartile\nSkewness\nKurtosis"
  },
  {
    "objectID": "columncorrelations.html",
    "href": "columncorrelations.html",
    "title": "Column Correlations",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: not public."
  },
  {
    "objectID": "columncorrelations.html#type",
    "href": "columncorrelations.html#type",
    "title": "Column Correlations",
    "section": "3.1 Type",
    "text": "3.1 Type\nDefines the measure of correlation that should be calculated between the selected columns (default: Pearson correlation). It can be selected from a list of correlation coefficients:\n\nLog2(Absence-presence enrichment factor)\nAbsence-presence -Log10(p-value)\nNumbers of valid pairs\nValid pairs percentage\nPearson correlation\n-Log10(Pearson p-value)\n-Log10(Pearson p-value) [correlation]\n-Log10(Pearson p-value) [anti-correlation]\nR squared\nSpearman rank correlation\n-Log10(Spearman p-value)\n-Log10(Spearman p-value) [correlation]\n-Log10(Spearman p-value) [anti-correlation]\nKendall rank correlation\nDistance correlation\nMutual information\nEuclidean distance\nManhattan distance\nMaximum distance"
  },
  {
    "objectID": "columncorrelations.html#rows",
    "href": "columncorrelations.html#rows",
    "title": "Column Correlations",
    "section": "3.2 Rows",
    "text": "3.2 Rows\nSelected expression/numerical columns that will be the rows of the generated correlation matrix (default: all expression columns are selected)."
  },
  {
    "objectID": "columncorrelations.html#columns",
    "href": "columncorrelations.html#columns",
    "title": "Column Correlations",
    "section": "3.3 Columns",
    "text": "3.3 Columns\nSelected expression/numerical columns that will be the columns of the generated correlation matrix (default: all expression columns are selected)."
  },
  {
    "objectID": "andromeda_protdatabases.html",
    "href": "andromeda_protdatabases.html",
    "title": "Andromeda Protdatabases - the (protein) sequence databases table",
    "section": "",
    "text": "For the here shown step by step description Andromeda was used within MaxQuant (version 1.5.3.8).\n\n\nOpen MaxQuant and go to the Andromeda configuration tab. There select the Data type “Sequence databases” (s. Figure 1).\n\n\n\nFigure 1: opening the databases table\n\n\n\n\n\nLet’s assume we have to analyze human proteome measurements and we are interested which human database is used and how it is used (see Description on the right hand side of the Andromeda window in Figure 2).\n\n\n\nFigure 2: example human protease DB\n\n\n\n\n\nNow we are assuming that a reviewer asks us to search our human proteome measurements against the tasmanian devil proteome ( Sarcophilus harrisii ) - for some reason - and we downloaded the corresponding fasta file from Uniprot.\nAfter downloading the file, we are including the database into MaxQuant. First, click the “Add” button (highlithed in Figure 3). Then a new row will be added at the end of the table and a new sequence database form will appear on the right hand side that can be edited.\n\n\n\nFigure 3: Adding a new entry to database\n\n\nThen you just have to fill in the form by defining the fasta file that should be used, the parsing rule that should be applied to retrieve the identifiers, the source of the fasta file, the taxonomy and the organism name. To define the parsing rule regular expressions are used. A regular expression is a sequence of characters that forms a search pattern with a special syntax. A good general introduction can be found, as always, on Wikipedia. If you already know generally how regular expressions work, you may only need to glance at a this Quick Reference or at an even quicker Cheat Sheet. Also you don’t have to know the taxonomy of your organism, just type in the name and use the arrows in the taxonomy line and MaxQuant will complete the form.\nDon’t forget to click the “Modify table” button (Figure 4) when you’re done to transfer the changes you made in the form to the table on the left. And to save the table you have to click the “Save changes” button.\nTo have the added sequence database available in MaxQuant you have to open a new MaxQuant window.\n\n\n\nFigure 4: Saving the entry in the database"
  },
  {
    "objectID": "andromeda_protdatabases.html#open-the-sequence-databases-table",
    "href": "andromeda_protdatabases.html#open-the-sequence-databases-table",
    "title": "Andromeda Protdatabases - the (protein) sequence databases table",
    "section": "",
    "text": "Open MaxQuant and go to the Andromeda configuration tab. There select the Data type “Sequence databases” (s. Figure 1).\n\n\n\nFigure 1: opening the databases table"
  },
  {
    "objectID": "andromeda_protdatabases.html#viewing-an-example",
    "href": "andromeda_protdatabases.html#viewing-an-example",
    "title": "Andromeda Protdatabases - the (protein) sequence databases table",
    "section": "",
    "text": "Let’s assume we have to analyze human proteome measurements and we are interested which human database is used and how it is used (see Description on the right hand side of the Andromeda window in Figure 2).\n\n\n\nFigure 2: example human protease DB"
  },
  {
    "objectID": "andromeda_protdatabases.html#adding-a-new-database",
    "href": "andromeda_protdatabases.html#adding-a-new-database",
    "title": "Andromeda Protdatabases - the (protein) sequence databases table",
    "section": "",
    "text": "Now we are assuming that a reviewer asks us to search our human proteome measurements against the tasmanian devil proteome ( Sarcophilus harrisii ) - for some reason - and we downloaded the corresponding fasta file from Uniprot.\nAfter downloading the file, we are including the database into MaxQuant. First, click the “Add” button (highlithed in Figure 3). Then a new row will be added at the end of the table and a new sequence database form will appear on the right hand side that can be edited.\n\n\n\nFigure 3: Adding a new entry to database\n\n\nThen you just have to fill in the form by defining the fasta file that should be used, the parsing rule that should be applied to retrieve the identifiers, the source of the fasta file, the taxonomy and the organism name. To define the parsing rule regular expressions are used. A regular expression is a sequence of characters that forms a search pattern with a special syntax. A good general introduction can be found, as always, on Wikipedia. If you already know generally how regular expressions work, you may only need to glance at a this Quick Reference or at an even quicker Cheat Sheet. Also you don’t have to know the taxonomy of your organism, just type in the name and use the arrows in the taxonomy line and MaxQuant will complete the form.\nDon’t forget to click the “Modify table” button (Figure 4) when you’re done to transfer the changes you made in the form to the table on the left. And to save the table you have to click the “Save changes” button.\nTo have the added sequence database available in MaxQuant you have to open a new MaxQuant window.\n\n\n\nFigure 4: Saving the entry in the database"
  },
  {
    "objectID": "changecolumntype.html",
    "href": "changecolumntype.html",
    "title": "Change Column type",
    "section": "",
    "text": "Type: -Matrix Processing\nHeading: - Rearrange\nSource code: ChangeColumnType.cs"
  },
  {
    "objectID": "changecolumntype.html#find-what",
    "href": "changecolumntype.html#find-what",
    "title": "Change Column type",
    "section": "3.1 Find what",
    "text": "3.1 Find what\nSpecified text/term that is searched in a selected text column (default: empty)."
  },
  {
    "objectID": "changecolumntype.html#look-in",
    "href": "changecolumntype.html#look-in",
    "title": "Change Column type",
    "section": "3.2 Look in",
    "text": "3.2 Look in\nSelected text column that should be searched for the specified term (default: first text column of the matrix)."
  },
  {
    "objectID": "changecolumntype.html#match-case",
    "href": "changecolumntype.html#match-case",
    "title": "Change Column type",
    "section": "3.3 Match case",
    "text": "3.3 Match case\nThe cells of the text column will be searched for a matching substring (default: checked). The results will be in a new generated categorical column called “Search: original column name”. “\\(+\\)” indicates, whether a match was successful."
  },
  {
    "objectID": "changecolumntype.html#match-whole-word",
    "href": "changecolumntype.html#match-whole-word",
    "title": "Change Column type",
    "section": "3.4 Match whole word",
    "text": "3.4 Match whole word\nThe cells of the text column will be searched to match the whole word of the specified term (default: unchecked). The results will be in a new generated categorical column called “Search: original column name”. “\\(+\\)” indicates, whether a match was successful."
  },
  {
    "objectID": "significancea.html",
    "href": "significancea.html",
    "title": "Significance A",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Outliers\nSource code: SignificanceA.cs"
  },
  {
    "objectID": "significancea.html#columns",
    "href": "significancea.html#columns",
    "title": "Significance A",
    "section": "3.1 Columns",
    "text": "3.1 Columns\nSelected expression columns for which “Significance A” should be calculated (default: no expression columns are selected)."
  },
  {
    "objectID": "significancea.html#side",
    "href": "significancea.html#side",
    "title": "Significance A",
    "section": "3.2 Side",
    "text": "3.2 Side\nTo apply a two-sided test, where the null hypothesis can be rejected regardless of the direction of the effect “both” has to be selected (default). “left” and “right” are the respective one-sided tests."
  },
  {
    "objectID": "significancea.html#use-for-truncation",
    "href": "significancea.html#use-for-truncation",
    "title": "Significance A",
    "section": "3.3 Use for truncation",
    "text": "3.3 Use for truncation\nThe truncation can be based on p-values or the Benjamini-Hochberg correction for multiple hypothesis testing (default: Benjamini-Hochberg FDR). Rows with a test result below a specified value (parameter below) are reported as significant."
  },
  {
    "objectID": "significancea.html#threshold-value",
    "href": "significancea.html#threshold-value",
    "title": "Significance A",
    "section": "3.4 Threshold value",
    "text": "3.4 Threshold value\nBased on a specified threshold a specific row is reported as significant (default: 0.05). Depending on the chosen truncation score this threshold value is applied to the p-value or to the Benjamini-Hochberg FDR."
  },
  {
    "objectID": "duplicatecolumns.html",
    "href": "duplicatecolumns.html",
    "title": "Duplicate Columns",
    "section": "",
    "text": "1 General\n\nType: - Matrix Processing\nHeading: - Rearrange\nSource code: DuplicateColumns.cs\n\n\n\n2 Brief description\nColumns of all types can be duplicated.\nOutput: Same matrix but with duplicated columns added.\n\n\n3 Parameters\nThe selected expression/numerical/multi numerical/categorical/text columns will be duplicated and included in the new generated matrix at the end of each group of column types (default: no columns are selected). The name of the new columns is the old column name with the string “_1” attached to the end.\n\n\n4 Parameter window\n\n\n\nRearrange duplicate columns"
  },
  {
    "objectID": "genericmatrixupload.html",
    "href": "genericmatrixupload.html",
    "title": "Generic Matrix Upload",
    "section": "",
    "text": "Type: - Matrix Upload\nSource code: GenericMatrixUpload.cs"
  },
  {
    "objectID": "genericmatrixupload.html#parameters",
    "href": "genericmatrixupload.html#parameters",
    "title": "Generic Matrix Upload",
    "section": "2.1 Parameters",
    "text": "2.1 Parameters\n\n2.1.1 File\nSpecifies the file path of the tab separated file that should be uploaded (default: empty). It can be specified manually by typing in the path or the file can be browsed by using the “Select” button.\n\n\n2.1.2 Main/Numerical/Categorical/Text/Multi-numerical\nEach of the listed columns in the left panel that should be loaded need to be distributed among the five different column types depending on the analysis that should be applied.\nHint: If necessary, column types can also be changed later using Change column type.\n\n\n2.1.3 Parameter window\n\n\n\nGeneric matrix upload"
  },
  {
    "objectID": "perseus_user_intereface.html",
    "href": "perseus_user_intereface.html",
    "title": "Perseus User Interface",
    "section": "",
    "text": "The title bar along the top has the Perseus logo on the left, followed by an icon that can be used to rename the session, which will be displayed and is by default “Session 1 - Perseus”. The bar below (Figure 1) has on the left a menu (indicated by the blue box with a white arrow on it) with the usual sorts of file functions (Save, Save as, Save as PDF, Open, New, New Window, Annotation Download, Help, Exit), followed by a tab label “Matrix”. On the right are buttons to split/join the Perseus window, minimize/maximize the ribbon with all the activities and the last button redirects to the documentation. The ribbon of the “Matrix” tab contains all the activities (highlighted by a cyan rectangle) that can be applied to loaded matrices.\nThe activities can be divided into five main categories. The icons of the categories Processing, Analysis and Multi-proc. are frequently used activities, which are also listed in one of the drop down menus of each category. To figure out the function behind the icon just hover over it. For simplicity the icons of these three categories are ignored in the listing below:"
  },
  {
    "objectID": "perseus_user_intereface.html#load",
    "href": "perseus_user_intereface.html#load",
    "title": "Perseus User Interface",
    "section": "1 Load",
    "text": "1 Load\n\nGeneric Matrix Upload\nCreate Gene list\nCreate Random matrix\nRaw upload\nBinary upload\nNGS upload"
  },
  {
    "objectID": "perseus_user_intereface.html#processing",
    "href": "perseus_user_intereface.html#processing",
    "title": "Perseus User Interface",
    "section": "2 Processing",
    "text": "2 Processing\n\n2.1 Basic\n\nTransform\nCombine expression columns\nColumn correlation\nRow correlation\nSummary statistics (columns)\nSummary statistics (rows)\nQuantiles\nDensity estimation\nPerformance curve\nClone\nSignificance A\nSignificance B\nAdd noise\n\n\n\n2.2 Rearrange\n\nChange column type\nRename columns\nRename columns (reg. ex.)\nCombine annotations\nDuplicate columns\nReorder/remove columns\nRemove empty columns\nTranspose\nSort by column\nExpand multi-numeric and string columns\nUnique values\nConvert multi-numeric column\nCombine categorical columns\nProcess text column\nSearch text column\n\n\n\n2.3 Normalization\n\nZ-score\nRank\nUnit vectors\nScale to interval\nWidth adjustment\nSubtract\nDivide\nModify by column\nSubtract row cluster\nUn-Z-score\n\n\n\n2.4 Filter rows\n\nFilter rows based on categorical column\nFilter rows based on numerical/expression column\nFilter rows based on text column\nFilter rows based on valid values\nFilter rows based on random sampling\n\n\n\n2.5 Filter columns\n\nFilter columns based on categorical row\nFilter columns based on valid values\n\n\n\n2.6 Quality\n\nCreate quality matrix\nFilter quality\nConvert to NaN\n\n\n\n2.7 Annot. columns\n\nAdd annotation\nTo base identifiers\nFisher exact test\nAverage categories\nCategory counting\n1D annotation enrichment\n2D annotation enrichment\n\n\n\n2.8 Annot. rows\n\nCategorical annotation rows\nNumerical annotation rows\nAverage groups\nJoin terms in categorical row\n\n\n\n2.9 Tests\n\nOne-sample tests\nTwo-samples tests\nMultiple-samples tests\nTwo-way ANOVA\n\n\n\n2.10 Imputation\n\nReplace missing values from normal distribution\nReplace imputed values by NaN\nReplace missing values by constant\n\n\n\n2.11 Modifications\n\nExpand site table\nAdd linear motifs\nAdd modification counts\nAdd known sites\nKinase-substrate relations\nAdd sequence features\nAdd regulatory sites\nShorten motif length\n\n\n\n2.12 Clustering\n\nGeneric clustering"
  },
  {
    "objectID": "perseus_user_intereface.html#analysis",
    "href": "perseus_user_intereface.html#analysis",
    "title": "Perseus User Interface",
    "section": "3 Analysis",
    "text": "3 Analysis\n\n3.1 Visualization\n\nScatter plot\nProfile plot\nHistogram\nMulti scatter plot\n3D plot\n\n\n\n3.2 Clustering/PCA\n\nHierarchical clustering [[perseus:user:activities:matrixanalysis:clusteringpca:|]]\nPrinciple component analysis [[perseus:user:activities:matrixanalysis:clusteringpca:|]]\n\n\n\n3.3 Misc.\n[[perseus:user:activities:matrixanalysis:misc:volcanoplotanalysis|Volcano plot]] * [[perseus:user:activities:matrixanalysis:misc:selectrowsmanually|Select rows manually]] * [[perseus:user:activities:matrixanalysis:misc:sequencelogo|Sequence logos]] * [[perseus:user:activities:matrixanalysis:misc:numericvenndiagram|Numeric venn diagram]]"
  },
  {
    "objectID": "perseus_user_intereface.html#multi-proc.",
    "href": "perseus_user_intereface.html#multi-proc.",
    "title": "Perseus User Interface",
    "section": "4 Multi-proc.",
    "text": "4 Multi-proc.\n\n4.1 Basic\n[[perseus:user:activities:matrixmultiprocessing:basic:matchingrowsbyname|Matching rows by name]] * [[perseus:user:activities:matrixmultiprocessing:basic:matchingcolumnsbyname|Matching columns by name]]"
  },
  {
    "objectID": "perseus_user_intereface.html#export",
    "href": "perseus_user_intereface.html#export",
    "title": "Perseus User Interface",
    "section": "5 Export",
    "text": "5 Export\n[[perseus:user:activities:matrixexport:tabseparatedexport|Generic matrix export]]\nThe remainder of the window is divided into scrollable panes (Figure 2):\n\nThe matrix pane (highlighted by a pink rectangle)\nThe workflow pane (highlighted by a blue rectangle)\nThe meta-data pane (highlighted by a green rectangle).\n\n\n\n\nFigure 2: Perseus interface overview\n\n\nThe matrix pane on the left, displays the matrix that is currently selected in the workflow pane including all the columns and rows of that matrix. In the bottom left corner of that pane you can find the number of rows (items) of the shown matrix.\nThe workflow pane in the middle, shows all the processing steps that have been applied to your data up to here including the parameter values that have been used. The generated workflow can be rearranged using the drag and drop function. Also matrices can be renamed and highlighted using different colors by right clicking on the node of choice. At the top of this pane you can find important buttons to manipulate the workflow:\n\nRe-layout: Re-formats the whole workflow to the default arrangement of the workflow\nStop activity: Stops a currently running process\nRemove selected nodes\nComplete selection downstream: Selects all nodes downstream starting at the picked node\nComplete selection upstream: Selects all nodes upstream starting at the picked node\nExport graphics: Exports the workflow as a graphic\n\nThe meta-data pane on the right, gives meta-information of a selected node. If a matrix node is selected you get information about the matrix, its creator and when it was created, how many rows and columns it contains, etc. In case an activity node is selected information about the used parameters can be retrieved and if necessary be double checked.\n\nIn the bottom right corner of the Perseus window are a progress bar and the version number.\nComment: In the newest Perseus version we changed the terminology of expression columns to main columns. The functionality of these columns is equivalent."
  },
  {
    "objectID": "cloneprocessing.html",
    "href": "cloneprocessing.html",
    "title": "Clone Processing",
    "section": "",
    "text": "1 General =====\n\nType: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: CloneProcessing.cs\n\n\n\n2 Brief description\nA copy of the input matrix is generated.\nOutput: Same as input matrix.\n\n\n\n3 Parameters\n“Clone” has no parameters."
  },
  {
    "objectID": "rawFilesTab.html",
    "href": "rawFilesTab.html",
    "title": "Raw files tab",
    "section": "",
    "text": "The Raw files tab displays information about your raw data sources and offers functions for dealing with those sources and the specification of your experimental design. This page first describes the columns of the raw files table and then the functions available to change it, organized following the buttons and button groups.\nWe often refer to a source of raw data as a raw file, but in some data formats the source is actually a folder. Currently, the file-based raw data formats supported and their (case insensitive) extensions are:\nThe folder.based raw data formats and their extensions are:"
  },
  {
    "objectID": "rawFilesTab.html#raw-files-table",
    "href": "rawFilesTab.html#raw-files-table",
    "title": "Raw files tab",
    "section": "1 Raw files table",
    "text": "1 Raw files table\nThe table displaying information about the raw data sources has seven columns.\n\nFile: the absolute path to the file or folder containing the raw data.\nExists: whether the file or folder currently exists at that location on the file system.\nSize: if the path points to an existing file (not a folder), the size of that file.\nData format: the vendor or standard defining the format in which the data is stored, and whether it is file-based or folder-based.\nParameter group: The data files may be organized at the user’s discretion in groups, which may be given different parameters.\nExperiment: The experiment is text that the user can choose and use however convenient, for example to group raw data or to remind him of the characteristics of the samples from which the data was taken.\nFraction: Often the samples will be pre-processed with a procedure, for example centrifugation, that produces several sub-samples in a particular sequence. These sub-samples can be labeled with integers in the fractions column."
  },
  {
    "objectID": "rawFilesTab.html#raw-files-functions",
    "href": "rawFilesTab.html#raw-files-functions",
    "title": "Raw files tab",
    "section": "2 Raw files functions",
    "text": "2 Raw files functions\n\n2.1 Input data group\nThe Load and Load folder buttons are described here, but you should be aware that there are two other ways to load raw files.\nOne is by loading parameters stored in an *.xml file, usually named mqpar.xml. To do this, use the Load parameters item on the drop-down menu just left of the Raw files tab. A file browser will open so you can load the parameters you want, including the raw data files.\nThe other way to load raw files is by drag-and-drop from a file explorer. The behavior will depend on what you select.\n\nIf you select a single file with an *.xml extension (usually mqpar.xml), the raw data files and other parameters stored there will be loaded.\nIf all of the items you select are recognized as raw data files, then these will be loaded.\nIf any of the items you select is not recognized as a raw data file, then each folder among the selected items will be searched recursively for raw data files. All files found will be loaded. If there are also files which are not recognized as raw data, they will be silently passed over.\n\n\n\n2.2 Load button\nPressing the Load button will open a file chooser window. The filter at the lower right may be selected to choose which type of file-based raw data source is visible and may be selected. Folder-based raw data sources cannot be loaded with this button, but the Load folder button (Section 2.4) can be used for these. The folders may be browsed and single or multiple files can be chosen in the usual way. When you have made your selection, press Open. (Remember, if you have chosen a folder, it will be opened for browsing. To load files, you must have only files selected.) The file or files chosen will be added to the table, unless they are already present there.\n\n\n2.3 Remove button\nThis button removes the selected raw data rows from the table.\n\n\n2.4 Load folder button\nThe Load folder button can be used in three ways:\n\nto open a single, folder-based raw data source,\nto open all the raw data sources of any sort (whether file-based or folder based) in the chosen folder, or\nto open all the raw data sources of any sort anywhere under the chosen folder, that is, recursively.\n\nBecause there could be many items in a directory that are not raw data sources, all such items are silently ignored.\n\n\n2.5 Change folder button\nRaw data files loaded by the buttons or with drag-and-drop will, naturally, exist. When an mqpar.xml file is loaded, however, the files mentioned may no longer exist. For example, some processing of the files may have been done and a parameter file saved, but the files subsequently moved to another folder or drive. If the files are still together, the situation may be saved by telling MaxQuant where to find them now. When you press the Change folder button you will be presented with the part of the path that the files in the table have in common and given the opportunity to change it to the path that is currently correct, either by editing or by browsing."
  },
  {
    "objectID": "rawFilesTab.html#experimental-design-file-group",
    "href": "rawFilesTab.html#experimental-design-file-group",
    "title": "Raw files tab",
    "section": "3 Experimental design file group",
    "text": "3 Experimental design file group\n\n3.1 Write template button\nNo documentation yet.\n\n\n3.2 Read from file button\nNo documentation yet."
  },
  {
    "objectID": "rawFilesTab.html#edit-experimental-design-group",
    "href": "rawFilesTab.html#edit-experimental-design-group",
    "title": "Raw files tab",
    "section": "4 Edit experimental design group",
    "text": "4 Edit experimental design group\n\n4.1 Set experiment button\nNormally the experiment is left blank when raw data is loaded. The exception is when data is loaded recursively from a folder, in which case MaxQuant generates an value for the experiment from the paths to the files. To set or change the value of experiment, choose one or more files and press the Set experiment button. You will see a pop-up window where you can enter the new value.\n\n\n4.2 Set parameter group button\nThis button allows you to set or change the value of the parameter group for the selected files to anything from Group 0 to Group 19.\n\n\n4.3 Set fractions button\nWhen you press the Set fractions button, you will be given the opportunity to set two integer values. The value you put in the lower box must be greater than or equal to the value you put in the upper box. The raw data files you have selected will be assigned fraction numbers cyclically from the lower value to the higher value, e.g 1, 2, 3, 1, 2, 3, … .\n\n\n4.4 No fractions button\nPressing this button will remove all values in the fraction column. (Not just the values for the selected files!) It will also recalculate the values in the Experiment column."
  },
  {
    "objectID": "viewer_instructions.html",
    "href": "viewer_instructions.html",
    "title": "The Viewer",
    "section": "",
    "text": "Modern software platforms enable the analysis of shotgun proteomics data in an automated fashion resulting in high quality identification and quantification results. Additional understanding of the underlying data can be gained with the help of advanced visualization tools that allow for easy navigation through large LC-MS/MS datasets potentially consisting of terabytes of raw data. The updated MaxQuant version has a map navigation component that steers the users through mass and retention time-dependent mass spectrometric signals. It can be used to monitor a peptide feature used in label-free quantification over many LC-MS runs and visualize it with advanced 3D graphic models. An expert annotation system aids the interpretation of the MS/MS spectra used for the identification of these peptide features.\nTo run MaxQuant with its Viewer module, you will need .NET framework 4.5. If you use Windows you should have Windows 10 or newer.\n\n1 Documentation outline\n\nDownload and installation\nUser interface\nGetting started\nTutorial\nTrouble shooting\nGoogle groups\nmaxquant Bug reporting\nGlossary\n\nYou can find raw files and processed data to test the Viewer (v. 1.5.2.8) here.\nImportant note: If you load the mqpar.xml file, make sure all file paths are correct! If needed, update them using the “Change folder” option.\nFor additional training, consider attending our annual MaxQuant Summer School.\nAlso watching some MaxQuant videos on our video channel provides more insight.\nFor more details and better understanding of the viewer, you might be interested in reading our publication1.\n\n\n\n\n\nReferences\n\n1. Tyanova, S. et al. Visualization of LC-MS/MS proteomics data in MaxQuant. PROTEOMICS 15, 1453–1456 (2015)."
  },
  {
    "objectID": "MQ_FirstSteps.html",
    "href": "MQ_FirstSteps.html",
    "title": "First steps with MaxQuant",
    "section": "",
    "text": "The descriptions and screenshots in this tutorial refer to the MaxQuant GUI around version 1.4.3.14 from August 2014.\nIn case you are a first time user, you might be worried by the many options and parameters that one can set in the user interface. If this is the case, we have good news for you. In almost all user cases the standard values of most parameters are fine and you only need to adjust a small number of factors. Typically there is only little information that you need to provide. Every parameter in the interface has context help which you obtain by hovering with the mouse pointer over the text string for this parameter. This documentation also has that information, and more.\nYou will have to tell MaxQuant where to find your raw data files and your fasta files, and which labels and digestion enzymes you are using. 90% of the time that will be enough, and you can leave the rest of the bells and whistles on their default values. Of course, we are assuming you have successfully installed and started MaxQuant, and that you can find the Start button once you have finished entering the processing parameters (hint: look in the lower left corner of the GUI). Below are more details on how to enter those four most important parameters:"
  },
  {
    "objectID": "MQ_FirstSteps.html#entering-raw-data",
    "href": "MQ_FirstSteps.html#entering-raw-data",
    "title": "First steps with MaxQuant",
    "section": "1 Entering Raw data",
    "text": "1 Entering Raw data\nAlong the top of the GUI there are six tabs. The first of these is Raw files. Select that tab, then click “Load” to open a browser where you can select the file containing your raw data. You can select any number of files. You can also select all the raw data files in a single folder by using the “Load folder” button (s. Figure 1). In the screen shot, two files have been loaded. (If you still have questions, there is a page that goes into details about the Raw Files tab)\n\n\n\nFigure 1: raw Files"
  },
  {
    "objectID": "MQ_FirstSteps.html#the-labels",
    "href": "MQ_FirstSteps.html#the-labels",
    "title": "First steps with MaxQuant",
    "section": "2 The Labels",
    "text": "2 The Labels\nThe second tab is Group-specific parameters. You need to go there to specify your labels. The “Type” will usually be “Standard” (obviously), and the “Multiplicity” will be \\(1\\) for label-free quantification, \\(2\\) if you have light and heavy labels, and \\(3\\) if you have light, medium, and heavy. Any number of labels can be checked in the lists. In this example, the light sample is unlabeled and the heavy sample has been labeled with Arg10 and Lys8. (You can’t see them both without scrolling. Figure 2)\n\n\n\nFigure 2: Group-specific parameters"
  },
  {
    "objectID": "MQ_FirstSteps.html#enzymes",
    "href": "MQ_FirstSteps.html#enzymes",
    "title": "First steps with MaxQuant",
    "section": "3 Enzymes",
    "text": "3 Enzymes\nAlso under the Group-specific parameters tab, you should enter the Enzyme(s) (one or more) with which you have digested your proteins. They can be moved from the list at the left and back with the arrow buttons, and the order changed with the “t” (to top), “u” (up one place), “d” (down one place), and “b” (to bottom) buttons. In this example (s. Figure 3), we used Trypsin/P.\n\n\n\nFigure 3: Enzymes"
  },
  {
    "objectID": "MQ_FirstSteps.html#load-fasta-file",
    "href": "MQ_FirstSteps.html#load-fasta-file",
    "title": "First steps with MaxQuant",
    "section": "4 Load FASTA file",
    "text": "4 Load FASTA file\nFinally you will need to go to the third tab (s. Figure 4), “Global parameters” to specify where to find the Fasta files (one or more) you want to use. The Add file button will open a file browser.\n\n\n\nFigure 4: fasta files"
  },
  {
    "objectID": "MQ_FirstSteps.html#start-the-analysis",
    "href": "MQ_FirstSteps.html#start-the-analysis",
    "title": "First steps with MaxQuant",
    "section": "5 Start the Analysis",
    "text": "5 Start the Analysis\nAfter you press the Start button, you can monitor the progress of the analysis under the fourth tab, Performance. A popup window saying ‘Done’ will appear when MaxQuant is finished. All result files will appear in the folder …\\combined\\txt as tab-delimited text files. A pdf document with a description of all columns in all tables will be written to …\\combined\\txt\\tables.pdf.\nThe fifth tab is the Viewer, used to examine the results of the analysis, which will be the topic of the viewer tutorial. All columns have interactive descriptions in the Viewer program. Just move the mouse over the beginning of the column title and click on the question mark that will appear.\nThe sixth and final tab is Andromeda configuration. Andromeda is the peptide search engine, which needs to know what modifications, proteases, and sequence databases to take into consideration. Almost all that you will ever need are pre-configured, but you can use the buttons under this tab to add more, if your experiment requires it.\nThat’s how easy it can be!\n\nFor question or problems with the running MqxQuant we would love to hear from you under Contact."
  },
  {
    "objectID": "perseus_download_guide.html",
    "href": "perseus_download_guide.html",
    "title": "Perseus Download and Installation",
    "section": "",
    "text": "The latest Perseus release is: 2.0.11 [date: 29.09.2023]"
  },
  {
    "objectID": "perseus_download_guide.html#download",
    "href": "perseus_download_guide.html#download",
    "title": "Perseus Download and Installation",
    "section": "1 Download",
    "text": "1 Download\nDownloading and using the software is free of charge.\nSimply download from our MQ home page and unpack the compressed file Perseus.zip."
  },
  {
    "objectID": "perseus_download_guide.html#requierments",
    "href": "perseus_download_guide.html#requierments",
    "title": "Perseus Download and Installation",
    "section": "2 requierments",
    "text": "2 requierments\nSupported operation system versions (64 bit is required) are Windows 10 or 11 or Windows Server 2016, 2019, 2022.\nInstall .NET Framework 4.7.2 or higher - To find out whether you already have it, follow the instructions on How to Determine Which .NET Framework Versions Are Installed. If you need to, you can download the software and get installation instructions at the Microsoft Download Center."
  },
  {
    "objectID": "perseus_download_guide.html#running",
    "href": "perseus_download_guide.html#running",
    "title": "Perseus Download and Installation",
    "section": "3 Running",
    "text": "3 Running\nTo run Perseus the GUI just double click on Perseus.exe in the Perseus folder."
  },
  {
    "objectID": "perseus_download_guide.html#hardware-requirements",
    "href": "perseus_download_guide.html#hardware-requirements",
    "title": "Perseus Download and Installation",
    "section": "4 Hardware requirements",
    "text": "4 Hardware requirements\n\nIntel Pentium III/800 MHz or higher (or compatible) although one should probably not go below a dual core processor.\n2 GB RAM minimum.\n2 GB RAM per thread that is executed in parallel is required.\nThere is no upper limit on the number of cores. Whatever you can fit into a shared memory machine will work as long as the disk performance scales up with it."
  },
  {
    "objectID": "reorderremovecolumns.html",
    "href": "reorderremovecolumns.html",
    "title": "Reorder / Remove Columns",
    "section": "",
    "text": "1 General\n\nType: - Matrix Processing\nHeading: - Rearrange\nSource code: ReorderRemoveAnnotRows.cs\n\n\n\n2 Brief description\nAnnotation rows can be removed with this activity.\nOutput: Same matrix but with annotation rows removed or in new order.\n\n\n3 Parameters\nA new matrix is generated with the specified columns by selecting/deselecting expression/numerical/multi numerical/categorical/text columns (default: all columns are selected).\n\n\n4 Parameter window\n\n\n\nReorder remove columns\n\n\n{{perseus:user:activities:matrixprocessing:rearrange:rearrange-reorder_remove_columns-edited.png?direct|Perseus pop-up window: Rearrange -&gt; Reorder/remove columns}}"
  },
  {
    "objectID": "densityestimationprocessing.html",
    "href": "densityestimationprocessing.html",
    "title": "Density Estimation Processing",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: DensityEstimationProcessing.cs"
  },
  {
    "objectID": "densityestimationprocessing.html#x",
    "href": "densityestimationprocessing.html#x",
    "title": "Density Estimation Processing",
    "section": "3.1 x",
    "text": "3.1 x\nSelected expression columns for the first dimension of the generated density map(s) (default: first expression column in the matrix). Multiple columns can be chosen for each dimension leading to the creation of multiple density maps, but the number of columns have to be the same in both dimensions."
  },
  {
    "objectID": "densityestimationprocessing.html#y",
    "href": "densityestimationprocessing.html#y",
    "title": "Density Estimation Processing",
    "section": "3.2 y",
    "text": "3.2 y\nSelected expression columns for the second dimension of the generated density map(s) (default: second expression column in the matrix). Multiple columns can be chosen for each dimension leading to the creation of multiple density maps, but the number of columns have to be the same in both dimensions."
  },
  {
    "objectID": "densityestimationprocessing.html#number-of-points",
    "href": "densityestimationprocessing.html#number-of-points",
    "title": "Density Estimation Processing",
    "section": "3.3 Number of points",
    "text": "3.3 Number of points\nThe specified number of points defines the resolution of the density map (default: 300). It reflects the number of pixel per dimension."
  },
  {
    "objectID": "densityestimationprocessing.html#distribution-type",
    "href": "densityestimationprocessing.html#distribution-type",
    "title": "Density Estimation Processing",
    "section": "3.4 Distribution type",
    "text": "3.4 Distribution type\nEach data point is smoothed out by a suitable Gaussian kernel, which is defined in the “Distribution type” (default: \\(P(x,y)\\). The function can be selected out of a predefined list:\n\n\\(P(x,y)\\)\n\\(P(y|x)\\)\n\\(P(x|y)\\)\n\\(P(x,y)/(P(x)*P(y))\\)"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "contact",
    "section": "",
    "text": "MaxQuant, Perseus, and related software packages are developed by the Computational Systems Biochemistry under Prof. Jürgen Cox.\nIf you need to contact the developers, you have a few options to proceed:\n\nIf you think something is misspelled or unclear in the documentation, consider changing it yourself (creating a pull request is quite easy).\nIf you have found a bug in the software or want to make a feature request, please create an issue on our github repository.\n\nIf you have a general usage question, ask it on the appropriate Google group.\n\nWe are also always on the lookout for promising canditates. In case you are interested in becoming a Master’s/PhD student or a postdoc, we encourage you to apply at all time via e-mail to Jürgen Cox.\nOr connect with us on GitHub or Twitter (links in top right)."
  },
  {
    "objectID": "andromeda_user-interface.html",
    "href": "andromeda_user-interface.html",
    "title": "Andromeda User Interface",
    "section": "",
    "text": "There are two way to run Andromeda, within the MaxQuant or as a stand-alone tool."
  },
  {
    "objectID": "andromeda_user-interface.html#andromeda-with-gui",
    "href": "andromeda_user-interface.html#andromeda-with-gui",
    "title": "Andromeda User Interface",
    "section": "2.1 Andromeda with GUI",
    "text": "2.1 Andromeda with GUI\nThe user interface of the Andromeda stand-alone version has the MaxQuant logo on the top left. The functionality buttons can be found on the right (highlighted green rectangle in Figure 2).\nLoading “Source Files” is possible with the “Browse” button. The corresponding “Parameter Files” can be loaded by clicking on the source files and using the “Select .apar” button. It can also be defined, whether a protein summary should be reported, whether the results should have a minimal score and how many threads should be used for the calculation.\n\n\n\nFigure 2: Andromeda User Interface standalone"
  },
  {
    "objectID": "andromeda_user-interface.html#andromeda-as-command-line-tool",
    "href": "andromeda_user-interface.html#andromeda-as-command-line-tool",
    "title": "Andromeda User Interface",
    "section": "2.2 Andromeda as command line tool",
    "text": "2.2 Andromeda as command line tool\nTo figure out how to specify the parameters in the command line tool, follow the steps below:\n\nOpen a cmd\nGo to the unziped Andromeda folder\nRun the executable AndromedaCmd.exe without parameters (highlighted by a cyan rectangle in Figure 3) to figure out the Andromeda settings (highlighted by a red rectangle in Figure 3).\n\n\n\n\nFigure 3: Andromeda User Interface standalone"
  },
  {
    "objectID": "combineannotations.html",
    "href": "combineannotations.html",
    "title": "Combine annotations",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: CombineAnnotations.cs\n\n===== Brief description =====\nSearch multiple categorical or string columns for the occurrence of a set of terms.\nOutput: A new categorical column is generated indicating the presence of any of these terms."
  },
  {
    "objectID": "combineannotations.html#categories",
    "href": "combineannotations.html#categories",
    "title": "Combine annotations",
    "section": "2.1 Categories",
    "text": "2.1 Categories\nSelect categorical and/or text columns that should be searched for the specified “Search terms” (default: no columns selected)."
  },
  {
    "objectID": "combineannotations.html#search-terms",
    "href": "combineannotations.html#search-terms",
    "title": "Combine annotations",
    "section": "2.2 Search terms",
    "text": "2.2 Search terms\nSpecified terms will be searched in the previously defined categorical and/or text columns (default: empty). Multiple terms are possible and must be separated by new lines, so each line in the “Search terms” field will be searched in each column. In the newly generated categorical column rows containing one of the search terms in one of the selected columns are indicated by a “\\(+\\)”."
  },
  {
    "objectID": "combineannotations.html#name-of-new-column",
    "href": "combineannotations.html#name-of-new-column",
    "title": "Combine annotations",
    "section": "2.3 Name of new column",
    "text": "2.3 Name of new column\nThe name of the new generated categorical column containing a “\\(+\\)” if one one “Search terms” matches one of the selected columns."
  },
  {
    "objectID": "combineannotations.html#inverse",
    "href": "combineannotations.html#inverse",
    "title": "Combine annotations",
    "section": "2.4 Inverse",
    "text": "2.4 Inverse\nIf checked, rows not matching the “Search terms” are indicated by a “\\(+\\)” (default: unchecked)."
  },
  {
    "objectID": "summarystatisticsrows.html",
    "href": "summarystatisticsrows.html",
    "title": "Summary statistics (rows)",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: SummaryStatisticsRows.cs"
  },
  {
    "objectID": "summarystatisticsrows.html#expression-column-selection",
    "href": "summarystatisticsrows.html#expression-column-selection",
    "title": "Summary statistics (rows)",
    "section": "3.1 Expression column selection",
    "text": "3.1 Expression column selection\nSelected expression columns that are used to summarize each row (default: use all expression columns). The way of choosing the expression columns can be specified by selecting one of the three options:\n\nUse all expression columns\nSelect columns\nWithin groups\n\n\n3.1.1 Columns\nThis parameter is just relevant, if “Expression column selection” is set to “Select columns”. Manually selected expression columns, whose values in each row should be used for the calculation of the defined operations (default: all expression columns are selected).\n\n\n3.1.2 Group\nThis parameter is just relevant, if “Expression column selection” is set to “Within groups”. Selected categorical row that defines which values in a row are grouped together to calculate the specified summary values (default: first categorical row in the matrix)."
  },
  {
    "objectID": "summarystatisticsrows.html#calculate",
    "href": "summarystatisticsrows.html#calculate",
    "title": "Summary statistics (rows)",
    "section": "3.2 Calculate",
    "text": "3.2 Calculate\nList of quantities that are calculated for the selected columns (default: all of the below listed quantities are selected). The available quantities are:\n\nSum\nMean\nTurkey biweight\nStandard deviation\nCoefficient of variation\nMedian absolute deviation\nMinimum\nMaximum\nRange\nValid values\nInter-quartile range\n1st quartile\n3rd quartile\nSkewness\nKurtosis"
  },
  {
    "objectID": "output_tables.html",
    "href": "output_tables.html",
    "title": "Output Tables",
    "section": "",
    "text": "MaxQuant produces multiple Output tables:"
  },
  {
    "objectID": "output_tables.html#summary-table",
    "href": "output_tables.html#summary-table",
    "title": "Output Tables",
    "section": "1 Summary Table",
    "text": "1 Summary Table\nThe summary file contains summary information for all the raw files processed with a single MaxQuant run. The summary information consists of some MaxQuant parameters, information of the raw file contents, and statistics on the peak detection. Based on this file a quick overview can be gathered on the quality of the data in the raw file.\nThe last row in this file contains the summary information for each column on each of the processed files.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nRaw file\nThe raw file processed.\n\n\nExperiment\nExperiment name assigned to this LC-MS run in the experimental design.\n\n\nFraction\nFraction assigned to this LC-MS run in the experimental design.\n\n\nEnzyme\nThe protease used to digest the protein sample.\n\n\nEnzyme mode\nThe protease used to digest the protein sample.\n\n\nEnzyme first search\nThe protease used for the first search.\n\n\nEnzyme mode first search\nThe protease used for the first search.\n\n\nUse enzyme first search\nMarked with ‘+’ when a different protease setup was used for the first search.\n\n\nVariable modifications\nThe variable modification(s) used during the identification of peptides.\n\n\nMulti modifications\nThe multi modification(s) used during the identification of peptides.\n\n\nVariable modifications first search\nThe variable modification(s) used during the first search.\n\n\nUse variable modifications first search\nMarked with ‘+’ when different variable modifications were used for the first search.\n\n\nRequantify\nThe number of labels used.\n\n\nMultiplicity\nThe number of labels used.\n\n\nMax. missed cleavages\nThe maximum allowed number of missed cleavages.\n\n\nMax. labeled AAs\nThe maximum allowed of labeled amino acids in a peptide amino acid sequence.\n\n\n“Labels” + i\nThe labels used in the labeling experiment. Allowed values for X: 0=light; 1=medium; 2=heavy label partner.\n\n\nLC-MS run type\nThe type of LC-MS run. Usually it will be ‘Standard’ which refers to a conventional shotgun proteomics run with data-dependent MS/MS.\n\n\nTime-dependent recalibration\nWhen marked with ‘+’, time-dependent recalibration was applied to improve the data quality.\n\n\nMS\nThe number of MS spectra recorded in this raw file.\n\n\nMS/MS\nThe number of MS/MS spectra recorded in this raw file.\n\n\nMS3\nThe number of MS3 spectra recorded in this raw file.\n\n\nMS/MS Submitted\nThe number of tandem MS spectra submitted for analysis.\n\n\nMS/MS Submitted (SIL)\nThe number of tandem MS spectra submitted for analysis, where the precursor ion was detected as part of a labeling cluster.\n\n\nMS/MS Submitted (ISO)\nThe number of tandem MS spectra submitted for analysis, where the precursor ion was detected as an isotopic pattern.\n\n\nMS/MS Submitted (PEAK)\nThe number of tandem MS spectra submitted for analysis, where the precursor ion was detected as a single peak.\n\n\nMS/MS Identified\nThe total number of identified tandem MS spectra.\n\n\nMS/MS Identified (SIL)\nThe total number of identified tandem MS spectra, where the precursor ion was detected as part of a labeling cluster.\n\n\nMS/MS Identified (ISO)\nThe total number of identified tandem MS spectra, where the precursor ion was detected as an isotopic pattern.\n\n\nMS/MS Identified (PEAK)\nThe total number of identified tandem MS spectra, where the precursor ion was detected as a single peak.\n\n\nMS/MS Identified [%]\nThe percentage of identified tandem MS spectra.\n\n\nMS/MS Identified (SIL) [%]\nThe percentage of identified tandem MS spectra, where the precursor ion was detected as part of a labeling cluster.\n\n\nMS/MS Identified (ISO) [%]\nThe percentage of identified tandem MS spectra, where the precursor ion was detected as an isotopic pattern.\n\n\nMS/MS Identified (PEAK) [%]\nThe percentage of identified tandem MS spectra, where the precursor ion was detected as a single peak.\n\n\nPeptide Sequences Identified\nThe total number of unique peptide amino acid sequences identified from the recorded tandem mass spectra.\n\n\nPeaks\nThe total number of peaks detected in the full scans.\n\n\nPeaks Sequenced\nThe total number of peaks sequenced by tandem MS.\n\n\nPeaks Sequenced [%]\nThe percentage of peaks sequenced by tandem MS.\n\n\nPeaks Repeatedly Sequenced\nThe total number of peaks repeatedly sequenced (i.e. 1 or more times) by tandem MS.\n\n\nPeaks Repeatedly Sequenced [%]\nThe percentage of peaks repeatedly sequenced (i.e. 1 or more times) by tandem MS.\n\n\nIsotope Patterns\nThe total number of detected isotope patterns.\n\n\nIsotope Patterns Sequenced\nThe total number of isotope patterns sequenced by tandem MS.\n\n\nIsotope Patterns Sequenced (z&gt;1)\nThe total number of isotope patterns sequenced by tandem MS with a charge state of 2 or more.\n\n\nIsotope Patterns Sequenced [%]\nThe percentage of isotope patterns sequenced by tandem MS.\n\n\nIsotope Patterns Sequenced (z&gt;1) [%]\nThe percentage of isotope patterns sequenced by tandem MS with a charge state of 2 or more.\n\n\nIsotope Patterns Repeatedly Sequenced\nThe total number of isotope patterns repeatedly sequenced (i.e. 1 or more times) by tandem MS.\n\n\nIsotope Patterns Repeatedly Sequenced [%]\nThe percentage of isotope patterns repeatedly sequenced (i.e. 1 or more times) by tandem MS.\n\n\nMultiplets\nThe total number of detected labeling pairs.\n\n\n“Multiplets z=” + z\n“The total number of detected labeling pairs with a charge state of” + z + “.”\n\n\nMultiplets Sequenced\nThe total number of labeling pairs sequenced by tandem MS.\n\n\nMultiplets Sequenced [%]\nThe percentage of labeling pairs sequenced by tandem MS.\n\n\nMultiplets Repeatedly Sequenced\nThe total number of labeling pairs repeatedly sequenced (i.e. 1 or more times) by tandem MS.\n\n\nMultiplets Repeatedly Sequenced [%]\nThe percentage of labeling pairs repeatedly sequenced (i.e. 1 or more times) by tandem MS.\n\n\nMultiplets Identified\nThe total number of labeling pairs identified.\n\n\nMultiplets Identified [%]\nThe percentage of labeling pairs identified.\n\n\nMultiplets\nThe total number of detected labeling triplets.\n\n\n“Multiplets z=” + z\n“The total number of detected labeling triplets with a charge state of” + z + “.”\n\n\nMultiplets Sequenced\nThe total number of labeling triplets sequenced by tandem MS.\n\n\nMultiplets Sequenced [%]\nThe percentage of labeling triplets sequenced by tandem MS.\n\n\nMultiplets Repeatedly Sequenced\nThe total number of labeling triplets repeatedly sequenced (i.e. 1 or more times) by tandem MS.\n\n\nMultiplets Repeatedly Sequenced [%]\nThe percentage of labeling triplets repeatedly sequenced (i.e. 1 or more times) by tandem MS.\n\n\nMultiplets Identified\nThe total number of labeling triplets identified.\n\n\nMultiplets Identified [%]\nThe percentage of labeling triplets identified.\n\n\nRecalibrated\nWhen marked with ‘+’, the masses taken from the raw file were recalibrated.\n\n\nAv. Absolute Mass Deviation [ppm]\nThe average absolute mass deviation found comparing to the identification mass in parts per million.\n\n\nMass Standard Deviation [ppm]\nThe standard deviation of the mass deviation found comparing to the identification mass in parts per million.\n\n\nAv. Absolute Mass Deviation [mDa]\nThe average absolute mass deviation found comparing to the identification mass in milli-Dalton.\n\n\nMass Standard Deviation [mDa]\nThe standard deviation of the mass deviation found comparing to the identification mass in milli-Dalton.\n\n\nLabel free norm param\nThe normalization factor used to scale the intensity values in a label-free experiment.\n\n\nMBRFDR\nFalse discovery rate for matching between runs."
  },
  {
    "objectID": "output_tables.html#evidence-table",
    "href": "output_tables.html#evidence-table",
    "title": "Output Tables",
    "section": "2 Evidence Table",
    "text": "2 Evidence Table\nThe evidence file combines all the information about the identified peptides and normally is the only file required for processing the results. Additional information about the peptides, modifications, proteins, etc. can be found in the other files by unique identifier linkage.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nSequence\nThe identified AA sequence of the peptide.\n\n\nLength\nThe length of the sequence stored in the column ‘Sequence’.\n\n\naa + ” Count”\n“The number of instances of” + aa + ” contained within the sequence. The value for this can reliably be determined in the case of labeling partners based on the distance between the partners. These counts are used to solidify the peptide identification process.”\n\n\nModifications\nPost-translational modifications contained within the identified peptide sequence.\n\n\nModified sequence\nSequence representation including the post-translational modifications (abbreviation of the modification in brackets before the modified AA). The sequence is always surrounded by underscore characters (’_’).\n\n\ntitle + ” Probabilities”\n“Sequence representation of the peptide including PTM positioning probabilities ([0..1], where 1 is best match) for ’” + title + “’.”\n\n\ntitle + ” Score Diffs”\nSequence representation for each of the possible PTM positions in each possible configuration, the difference is calculated between the identification score with the PTM added to that position and the best scoring identification where no PTM is added to that position. When this value is negative, it is unlikely that the particular modification is located at this position.\n\n\ntitle\n“The number of occurrences of the modification ’” + title + “’.”\n\n\n“Missed cleavages (” + enzyme + “)”\nNumber of missed enzymatic cleavages.\n\n\nMissed cleavages\nNumber of missed enzymatic cleavages.\n\n\nProteins\nThe identifiers of the proteins this particular peptide is associated with.\n\n\nLeading proteins\nThe identifiers of the proteins in the proteinGroups file, with this protein as best match, this particular peptide is associated with. When multiple matches are found here, the best scoring protein can be found in the ‘Leading Razor Protein’ column.\n\n\nLeading razor protein\nThe identifier of the best scoring protein, from the proteinGroups file this, this peptide is associated to.\n\n\nGene names\nNames of genes this peptide is associated with.\n\n\nProtein names\nNames of proteins this peptide is associated with.\n\n\nType\nThe type of the feature. ‘MSMS’ - for an MS/MS spectrum without an MS1 isotope pattern assigned. ‘ISO-MSMS’ - MS1 isotope cluster identified by MS/MS. ‘MULTI-MSMS’ - MS1 labeling cluster identified by MS/MS. ‘MULTI-SECPEP’ - MS1 labeling cluster identified by MS/MS as second peptide. ‘MULTI-MATCH’ - MS1 labeling cluster identified by matching between runs. In case of label-free data there is no difference between ‘MULTI’ and ‘ISO’.\n\n\nLabeling State\nLabeling state of the precursor isotope pattern used to identify the peptide.\n\n\nRaw file\nThe name of the RAW-file the mass spectral data was derived from.\n\n\nFraction\nThe fraction in which this peptide was detected.\n\n\ncolName\n\n\n\nMS/MS m/z\nThe m/z used for fragmentation (not necessarily the mono-isotopic m/z).\n\n\nCharge\nThe charge-state of the precursor ion.\n\n\nm/z\nThe recalibrated mass-over-charge value of the precursor ion.\n\n\nMass\nThe predicted monoisotopic mass of the identified peptide sequence.\n\n\nResolution\nThe resolution of precursor ion measured in Full Width at Half Maximum (FWHM).\n\n\nUncalibrated - Calibrated m/z [ppm]\nThe difference between the uncalibrated and recalibrated mass-over-charge value of the precursor ion measured in parts-per-million. This gives an indication of the mass drift in the original data, which was automatically corrected by MaxQuant.\n\n\nUncalibrated - Calibrated m/z [Da]\nThe difference between the uncalibrated and recalibrated mass-over-charge value of the precursor ion measured in parts-per-million. This gives an indication of the mass drift in the original data, which was automatically corrected by MaxQuant.\n\n\nMass Error [ppm]\nMass error of the recalibrated mass-over-charge value of the precursor ion in comparison to the predicted monoisotopic mass of the identified peptide sequence in parts per million.\n\n\nMass Error [Da]\nMass error of the recalibrated mass-over-charge value of the precursor ion in comparison to the predicted monoisotopic mass of the identified peptide sequence in milli-Dalton.\n\n\nUncalibrated Mass Error [ppm]\nMass error of the uncalibrated mass-over-charge value of the precursor ion in comparison to the predicted monoisotopic mass of the identified peptide sequence. Note: This column can contain missing values (denoted as NaN).\n\n\nUncalibrated Mass Error [Da]\nMass error of the uncalibrated mass-over-charge value of the precursor ion in comparison to the predicted monoisotopic mass of the identified peptide sequence. Note: This column can contain missing values (denoted as NaN).\n\n\nMax intensity m/z 0\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 0\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 1\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 0\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 1\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 2\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nRetention time\nThe uncalibrated retention time in minutes in the elution profile of the precursor ion.\n\n\nRetention length\nThe total retention time of the peak (last timepoint - first timepoint).\n\n\nCalibrated retention time\nThe recalibrated retention time in minutes in the elution profile of the precursor ion.\n\n\nCalibrated retention time start\nThe recalibrated retention start in minutes in the elution profile of the precursor ion.\n\n\nCalibrated retention time finish\nThe recalibrated retention finish in minutes in the elution profile of the precursor ion.\n\n\nRetention time calibration\nThe difference in minutes between the uncalibrated and recalibrated retention time. This gives an indication of the retention time drift in the original data, which was automatically corrected by MaxQuant. Note: This column can contain missing values (NaN).\n\n\nMatch time difference\nWhen the option ‘match between runs’ is used in MaxQuant, this value indicates the time difference between the feature from the raw file it was taken from and the feature from the raw file it was matched to.\n\n\nMatch m/z difference\nWhen the option ‘match between runs’ is used in MaxQuant, this value indicates the m/z difference between the feature from the raw file it was taken from and the feature from the raw file it was matched to.\n\n\nMatch q-value\nThis is the q-value for features that have been identified by ‘matching between runs’.\n\n\nMatch score\nThe andromeda score of the MS/MS identification that is the source of this identification by ‘matching between runs’.\n\n\nNumber of data points\nThe number of data points (peak centroids) collected for this peptide feature.\n\n\nNumber of scans\nThe number of MS scans that the 3d peaks of this peptide feature are overlapping with.\n\n\nNumber of isotopic peaks\nThe number of isotopic peaks contained in this peptide feature.\n\n\nPIF\nShort for Parent Ion Fraction; indicates the fraction the target peak makes up of the total intensity in the inclusion window.\n\n\nFraction of total spectrum\nThe percentage the ion intensity makes up of the total intensity of the whole spectrum.\n\n\nBase peak fraction\nThe percentage the parent ion intensity in comparison to the highest peak in the MS spectrum.\n\n\nPEP\nPosterior Error Probability of the identification. This value essentially operates as a p-value, where smaller is more significant.\n\n\nMS/MS Count\nThe number of sequencing events for this sequence, which matches the number of identifiers stored in the column ‘MS/MS IDs’. This number is independent of the times the AA sequence has been identified through (other) modifications (e.g. heavy label, oxidation, etc.), about which information can be found in the columns ‘Labeling State’ and ‘Modification’.\n\n\nMS/MS Scan Number\nThe RAW-file derived scan number of the MS/MS with the highest peptide identification score (the highest score is stored in the column ‘Score’).\n\n\nScore\nAndromeda score for the best associated MS/MS spectrum.\n\n\nDelta score\nScore difference to the second best identified peptide.\n\n\nCombinatorics\nNumber of possible distributions of the modifications over the peptide sequence.\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L shift\n\n\n\nRatio M/L\nThe ratio between two medium and light label partners.\n\n\nRatio M/L normalized\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio M/L shift\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L shift\n\n\n\nRatio H/M\nThe ratio between two heavy and medium label partners.\n\n\nRatio H/M normalized\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/M shift\n\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity M\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nReverse\nWhen marked with ‘+’, this particular peptide was found to be part of a protein derived from the reversed part of the decoy database. These should be removed for further data analysis.\n\n\nPotential contaminant\nWhen marked with ‘+’, this particular peptide was found to be part of a commonly occurring contaminant. These should be removed for further data analysis.\n\n\nid\nA unique (consecutive) identifier for each row in the evidence table, which is used to cross-link the information in this file with the information stored in the other files.\n\n\nProtein group IDs\nThe identifier of the protein-group this redundant peptide sequence is associated with, which can be used to look up the extended protein information in the file ‘proteinGroups.txt’. As a single peptide can be linked to multiple proteins (e.g. in the case of razor-proteins), multiple id’s can be stored here separated by a semicolon. As a protein can be identified by multiple peptides, the same id can be found in different rows.\n\n\nPeptide ID\nThe identifier of the non-redundant peptide sequence.\n\n\nMod. peptide ID\nIdentifier of the associated modification summary stored in the file ‘modificationSpecificPeptides.txt’.\n\n\nMS/MS IDs\nIdentifier(s) of the associated MS/MS summary(s) stored in the file ‘msms.txt’.\n\n\nBest MS/MS\nIdentifier(s) of the best MS/MS associated spectrum stored in the file ‘msms.txt’.\n\n\nAIF MS/MS IDs\nIdentifier(s) of the associated All Ion Fragmentation MS/MS summary(s) stored in the file ‘aifMsms.txt’.\n\n\nt + ” site IDs”\n“Identifier(s) of the modification summary stored in the file ’” + t + “Sites.txt’.”\n\n\n“Reporter intensity” + i\n\n\n\n“Reporter intensity not corrected” + i\n\n\n\n“Reporter intensity count” + i\n\n\n\nReporter PIF\n\n\n\nReporter fraction"
  },
  {
    "objectID": "output_tables.html#peptide-table",
    "href": "output_tables.html#peptide-table",
    "title": "Output Tables",
    "section": "3 Peptide Table",
    "text": "3 Peptide Table\nThe peptides table contains information on the identified peptides in the processed raw-files.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nSequence\nThe amino acid sequence of the identified peptide.\n\n\nN-term cleavage window\n“Sequence window from -” + cleaveWindowHalf + ” to ” + cleaveWindowHalf + ” around the N-terminal cleavage site of this peptide.”\n\n\nC-term cleavage window\n“Sequence window from -” + cleaveWindowHalf + ” to ” + cleaveWindowHalf + ” around the C-terminal cleavage site of this peptide.”\n\n\nAmino acid before\nThe amino acid in the protein sequence before the peptide.\n\n\nFirst amino acid\nThe amino acid in the first position of the peptide sequence.\n\n\nSecond amino acid\nThe amino acid in the first position of the peptide sequence.\n\n\nSecond last amino acid\nThe amino acid in the last position of the peptide sequence.\n\n\nLast amino acid\nThe amino acid in the last position of the peptide sequence.\n\n\nAmino acid after\nThe amino acid in the protein sequence after the peptide.\n\n\naa + ” Count”\n“The number of instances of the ’” + aa + “’ amino acid contained within the sequence.”\n\n\nLength\nThe length of the sequence stored in the column “Sequence”.\n\n\nMutated\n\n\n\nMutation names\n\n\n\n“Missed cleavages (” + enzyme + “)”\nNumber of missed enzymatic cleavages.\n\n\nMissed cleavages\nNumber of missed enzymatic cleavages.\n\n\nMass\nMonoisotopic mass of the peptide.\n\n\nProteins\nIdentifiers of proteins this peptide is associated with.\n\n\nLeading razor protein\nIdentifiers of the best scoring protein this peptide is associated with.\n\n\nStart position\nPosition of the first amino acid of this peptide in the protein sequence. (one-based)\n\n\nEnd position\nPosition of the last amino acid of this peptide in the protein sequence. (one-based)\n\n\nGene names\nNames of genes this peptide is associated with.\n\n\nProtein names\nNames of proteins this peptide is associated with.\n\n\nUnique (Groups)\nWhen marked with ‘+’, this particular peptide is unique to a single protein group in the proteinGroups file.\n\n\nUnique (Proteins)\nWhen marked with ‘+’, this particular peptide is unique to a single protein sequence in the fasta file(s).\n\n\nCharges\nAll charge states that have been observed.\n\n\nPEP\nPosterior Error Probability of the identification. This value essentially operates as a p-value, where smaller is more significant.\n\n\nScore\nHighest Andromeda score for the associated MS/MS spectra.\n\n\n“Identification type” + exp\nIndicates whether this experiment was identified by MS/MS or only by matching between runs.\n\n\nFraction Average\n\n\n\nFraction Std. Dev.\n\n\n\n“Fraction” + t\n\n\n\ncolName + ” ” + t\nNumber of evidence entries for this ‘Experiment’.\n\n\nReverse\nWhen marked with ‘+’, this particular peptide was found to be part of a protein derived from the reversed part of the decoy database. These should be removed for further data analysis.\n\n\nPotential contaminant\nWhen marked with ‘+’, this particular peptide was found to be part of a commonly occurring contaminant. These should be removed for further data analysis.\n\n\nid\nA unique (consecutive) identifier for each row in the peptides table, which is used to cross-link the information in this table with the information stored in the other tables.\n\n\nProtein group IDs\nThe identifiers of the protein groups this peptide was linked to, referenced against the proteinGroups table.\n\n\nMod. peptide IDs\nIdentifier(s) for peptide sequence(s), associated with the peptide, referenced against the corresponding modified peptides table.\n\n\nEvidence IDs\nIdentifier(s) for analyzed peptide evidence associated with the protein group referenced against the evidences table.\n\n\nMS/MS IDs\nThe identifiers of the MS/MS scans identifying this peptide, referenced against the msms table.\n\n\nBest MS/MS\nThe identifier of the best (in terms of quality) MS/MS scan identifying this peptide, referenced against the msms table.\n\n\nt + ” site IDs”\nIdentifier(s) for site(s) associated with the protein group, which show(s) evidence of the modification, referenced against the appropriate modification site file.\n\n\nMS/MS Count\n\n\n\n“Reporter intensity” + i\n\n\n\n“Reporter intensity not corrected” + i\n\n\n\n“Reporter intensity count” + i\n\n\n\n“Reporter intensity” + i + ” ” + exp\n\n\n\n“Reporter intensity not corrected” + i + ” ” + exp\n\n\n\n“Reporter intensity count” + i + ” ” + exp\n\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity L” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\n“Intensity M” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\n“Intensity H” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity M\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity L” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\n“Intensity H” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Ratio M/L” + exp\nThe ratio between two medium and light label partners.\n\n\n“Ratio M/L normalized” + exp\nThe ratio between two medium and light label partners.\n\n\n“Ratio M/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio M/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio M/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio M/L type” + exp\n\n\n\n“Ratio H/L” + exp\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L normalized” + exp\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/L type” + exp\n\n\n\n“Ratio H/M” + exp\nThe ratio between two heavy and medium label partners.\n\n\n“Ratio H/M normalized” + exp\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/M variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/M count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/M iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/M type” + exp\n\n\n\n“Ratio H/L” + exp\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L normalized” + exp\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/L type” + exp\n\n\n\nRatio M/L\nThe ratio between two medium and light label partners.\n\n\nRatio M/L normalized\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio M/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio M/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio M/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio M/L type\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/L type\n\n\n\nRatio H/M\nThe ratio between two heavy and medium label partners.\n\n\nRatio H/M normalized\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/M variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/M count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/M iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/M type\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/L type"
  },
  {
    "objectID": "output_tables.html#modification-specific-peptide-table",
    "href": "output_tables.html#modification-specific-peptide-table",
    "title": "Output Tables",
    "section": "4 Modification-Specific Peptide Table",
    "text": "4 Modification-Specific Peptide Table\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nSequence\nThe identified AA sequence of the peptide.\n\n\naa + ” Count”\n“The number of instances of the ’” + aa + “’ AA contained within the sequence. The value for this can reliably be determined in the case of SILAC partners based on the distance between the partners. These counts are used to solidify the peptide identification process.”\n\n\nModifications\nPost-translational modifications contained within the sequence. When no modifications exist, this is set to ‘unmodified’.\n\n\nMass\nCharge corrected mass of the precursor ion.\n\n\nMass Fractional Part\nThe values after the decimal point (ie value - floor(value)).\n\n\nProtein Groups\nIDs of the protein groups to whoch this peptide belongs.\n\n\nProteins\nThe identifiers of the proteins this particular peptide is associated with.\n\n\nGene Names\nNames of genes this peptide is associated with.\n\n\nProtein Names\nNames of proteins this peptide is associated with.\n\n\nUnique (Groups)\nWhen marked with ‘+’, this particular peptide is unique to a single protein group in the proteinGroups file.\n\n\nUnique (Proteins)\nWhen marked with ‘+’, this particular peptide is unique to a single protein sequence in the fasta file(s).\n\n\nmodName\n“Number of” + modName + ” on this peptide.”\n\n\n“Missed cleavages (” + enzyme + “)”\nNumber of missed enzymatic cleavages.\n\n\nMissed cleavages\nNumber of missed enzymatic cleavages.\n\n\n“Identification type” + exp\nIndicates whether this experiment was identified by MS/MS or only by matching between runs.\n\n\nFraction Average\n\n\n\nFraction Std. Dev.\n\n\n\n“Fraction” + t\n\n\n\ncolName + ” ” + t\nNumber of evidence entries for this ‘Experiment’.\n\n\nRetention time\nRetention time in minutes averaged over the evidence entries belonging to this modification-specific peptide.\n\n\nCalibrated retention time\nCalibrated retention time averaged over the evidence entries belonging to this modification-specific peptide. Obviously this only makes sense if retention time recalibration has been performed which is the case when matching between run is selected.\n\n\nCharges\nAll charge states that have been observed.\n\n\nPEP\nPosterior Error Probability of the identification. This value essentially operates as a p-value, where smaller is more significant.\n\n\nMS/MS scan number\nThe RAW-file derived scan number of the MS/MS with the highest peptide identification score (the highest score is stored in the column ‘Score’).\n\n\nRaw file\nThe name of the RAW-file the mass spectral data was derived from.\n\n\nScore\nAndromeda score for the best identified among the associated MS/MS spectra.\n\n\nDelta score\nScore difference to the second best identified peptide.\n\n\nReverse\nWhen marked with ‘+’, this particular peptide was found to be part of a protein derived from the reversed part of the decoy database. These should be removed for further data analysis.\n\n\nPotential contaminant\nWhen marked with ‘+’, this particular peptide was found to be part of a commonly occurring contaminant. These should be removed for further data analysis.\n\n\nid\nA unique (consecutive) identifier for each row in the peptides table, which is used to cross-link the information in this table with the information stored in the other tables.\n\n\nProtein group IDs\nThe identifiers of the protein groups this peptide was linked to, referenced against the proteinGroups table.\n\n\nPeptide ID\nIdentifier of the associated peptide sequence summary, which can be found in the file ‘peptides.txt’.\n\n\nEvidence IDs\nIdentifier(s) for analyzed peptide evidence associated with the protein group referenced against the evidences table.\n\n\nMS/MS IDs\nThe identifiers of the MS/MS scans identifying this peptide, referenced against the msms table.\n\n\nBest MS/MS\nThe identifier of the best (in terms of quality) MS/MS scan identifying this peptide, referenced against the msms table.\n\n\nt + ” site IDs”\nIdentifier(s) for site(s) associated with this peptide, which show(s) evidence of the modification, referenced against the appropriate modification site file.\n\n\nMS/MS Count\n\n\n\n“Reporter intensity” + i\n\n\n\n“Reporter intensity not corrected” + i\n\n\n\n“Reporter intensity count” + i\n\n\n\n“Reporter intensity” + i + ” ” + exp\n\n\n\n“Reporter intensity not corrected” + i + ” ” + exp\n\n\n\n“Reporter intensity count” + i + ” ” + exp\n\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity L” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\n“Intensity M” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\n“Intensity H” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity L” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\n“Intensity H” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity M\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Ratio M/L” + exp\nThe ratio between two medium and light label partners.\n\n\n“Ratio M/L normalized” + exp\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio M/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio M/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio M/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio M/L type” + exp\n\n\n\n“Ratio H/L” + exp\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L normalized” + exp\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/L type” + exp\n\n\n\n“Ratio H/M” + exp\nThe ratio between two heavy and medium label partners.\n\n\n“Ratio H/M normalized” + exp\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/M variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/M count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/M iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/M type” + exp\n\n\n\n“Ratio H/L” + exp\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L normalized” + exp\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/L type” + exp\n\n\n\nRatio M/L\nThe ratio between two medium and light label partners.\n\n\nRatio M/L normalized\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio M/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio M/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio M/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio M/L type\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/L type\n\n\n\nRatio H/M\nThe ratio between two heavy and medium label partners.\n\n\nRatio H/M normalized\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/M variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/M count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/M iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/M type\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/L type"
  },
  {
    "objectID": "output_tables.html#site-table",
    "href": "output_tables.html#site-table",
    "title": "Output Tables",
    "section": "5 Site Table",
    "text": "5 Site Table\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nProteins\nIdentifiers of proteins this site is associated with.\n\n\nPositions within proteins\nFor each protein identifier in the ‘Proteins’ column you find here the psoition of the site in the respective protein sequence. The index of the first amino acid in the sequence is 1.\n\n\nLeading proteins\n\n\n\nProtein\nIdentifier of the protein this peptide is associated with.\n\n\nProtein names\nNames of proteins this peptide is associated with.\n\n\nGene names\nNames of genes this peptide is associated with.\n\n\nFasta headers\nDescriptions of proteins this peptide is associated with.\n\n\nLocalization prob\n\n\n\nScore diff\n\n\n\nPEP\nThe posterior error probability (PEP) of the best identified modified peptide containing this site.\n\n\nScore\nThe Andromeda score of the best identified modified peptide containing this site.\n\n\nDelta score\nThe Andromeda delta score of the best identified modified peptide containing this site.\n\n\nScore for localization\nThe Andromeda score of the MS/MS spectrum used for calculating the localization score for this site.\n\n\n“Localization prob” + exp\n\n\n\n“Score diff” + exp\n\n\n\n“PEP” + exp\n\n\n\n“Score” + exp\n\n\n\nDiagnostic peak\n\n\n\n“Number of” + mod\n“Different numbers of” + mod + ” on peptides that this site is involved in.”\n\n\nAmino acid\n\n\n\nSequence window\n\n\n\nModification window\n\n\n\nPeptide window coverage\n\n\n\nmod + ” Probabilities”\n\n\n\nmod + ” Score diffs”\n\n\n\nPosition in peptide\n\n\n\nCharge\nCharge state of the precursor ion.\n\n\nMass error [ppm]\nMass error of the recalibrated mass-over-charge value of the precursor ion in comparison to the predicted monoisotopic mass of the identified peptide sequence.\n\n\n“Identification type” + exp\nIndicates whether this experiment was identified by MS/MS or only by matching between runs.\n\n\nReverse\nWhen marked with ‘+’, this particular peptide was found to be part of a protein derived from the reversed part of the protein sequence database. These should be removed for further data analysis.\n\n\nPotential contaminant\nWhen marked with ‘+’, this particular peptide was found to be part of a commonly occurring contaminant. These should be removed for further data analysis.\n\n\nid\nA unique (consecutive) identifier for each row in the site table, which is used to cross-link the information in this file with the information stored in the other files.\n\n\nProtein group IDs\nThe identifier of the protein-group this peptide sequence is associated with, which can be used to look up the extended protein information in the file ‘proteinGroups.txt’. As a single peptide can be linked to multiple proteins (e.g. in the case of razor-proteins), multiple id’s can be stored here separated by a semicolon. As a protein can be identified by multiple peptides, the same id can be found in different rows.\n\n\nPositions\nThe positions of the modifications in the protein amino acid sequence.\n\n\nPosition\nThe position of the modification in the protein amino acid sequence.\n\n\nPeptide IDs\nIdentifier(s) of the associated peptide sequence(s) summary, which can be found in the file ‘peptides.txt’.\n\n\nMod. peptide IDs\nIdentifier(s) of the associated peptide sequence(s) summary, which can be found in the file ‘modificationSpecificPeptides.txt’.\n\n\nEvidence IDs\nIdentifier(s) for analyzed peptide evidence associated with the protein group referenced against the evidences table.\n\n\nMS/MS IDs\nThe identifiers of the MS/MS scans identifying this peptide, referenced against the msms table.\n\n\nBest localization evidence ID\n\n\n\nBest localization MS/MS ID\n\n\n\nBest localization raw file\n\n\n\nBest localization scan number\n\n\n\nBest score evidence ID\n\n\n\nBest score MS/MS ID\n\n\n\nBest score raw file\n\n\n\nBest score scan number\n\n\n\nBest PEP evidence ID\n\n\n\nBest PEP MS/MS ID\n\n\n\nBest PEP raw file\n\n\n\nBest PEP scan number\n\n\n\n“Reporter intensity” + i\n\n\n\n“Reporter intensity not corrected” + i\n\n\n\n“Reporter intensity count” + i\n\n\n\n“Reporter intensity” + i + ” ” + exp\n\n\n\n“Reporter intensity not corrected” + i + ” ” + exp\n\n\n\n“Reporter intensity count” + i + ” ” + exp\n\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity L” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\n“Intensity M” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\n“Intensity H” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\n“Ratio mod/base L” + exp\n\n\n\n“Ratio mod/base M” + exp\n\n\n\n“Ratio mod/base H” + exp\n\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity L” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\n“Intensity H” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\n“Ratio mod/base L” + exp\n\n\n\n“Ratio mod/base H” + exp\n\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Ratio mod/base” + exp\n\n\n\n“Intensity” + exp + “___” + j\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Occupancy” + exp\n\n\n\n“Occupancy ratio” + exp\n\n\n\n“Occupancy error scale” + exp\n\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity M\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nRatio mod/base L\n\n\n\nRatio mod/base M\n\n\n\nRatio mod/base H\n\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nRatio mod/base L\n\n\n\nRatio mod/base H\n\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity___” + j\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nRatio mod/base\n\n\n\n“Ratio M/L” + exp\nThe ratio between two medium and light label partners.\n\n\n“Ratio M/L” + exp + “___” + i\nThe ratio between two medium and light label partners.\n\n\n“Ratio M/L normalized” + exp\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio M/L normalized” + exp + “___” + i\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio M/L unmod. pep.” + exp\n\n\n\n“Ratio M/L localized” + exp\n\n\n\n“Ratio M/L nmods” + exp\n\n\n\n“Ratio M/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio M/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio M/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio M/L type” + exp\n\n\n\n“Ratio H/L” + exp\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L” + exp + “___” + i\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L normalized” + exp\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L normalized” + exp + “___” + i\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L unmod. pep.” + exp\n\n\n\n“Ratio H/L localized” + exp\n\n\n\n“Ratio H/L nmods” + exp\n\n\n\n“Ratio H/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/L type” + exp\n\n\n\n“Ratio H/M” + exp\nThe ratio between two heavy and medium label partners.\n\n\n“Ratio H/M” + exp + “___” + i\nThe ratio between two heavy and medium label partners.\n\n\n“Ratio H/M normalized” + exp\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/M normalized” + exp + “___” + i\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/M unmod. pep.” + exp\n\n\n\n“Ratio H/M localized” + exp\n\n\n\n“Ratio H/M nmods” + exp\n\n\n\n“Ratio H/M variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/M count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/M iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/M type” + exp\n\n\n\n“Occupancy L” + exp\n\n\n\n“Occupancy M” + exp\n\n\n\n“Occupancy H” + exp\n\n\n\n“Ratio H/L” + exp\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L” + exp + “___” + i\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L normalized” + exp\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L normalized” + exp + “___” + i\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L unmod. pep.” + exp\n\n\n\n“Ratio H/L localized” + exp\n\n\n\n“Ratio H/L nmods” + exp\n\n\n\n“Ratio H/L variability [%]” + exp\n\n\n\n“Ratio H/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/L type” + exp\n\n\n\n“Occupancy L” + exp\n\n\n\n“Occupancy H” + exp\n\n\n\nRatio M/L\nThe ratio between two medium and light label partners.\n\n\n“Ratio M/L___” + i\nThe ratio between two medium and light label partners.\n\n\nRatio M/L normalized\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio M/L normalized___” + i\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio M/L unmod. pep.\n\n\n\nRatio M/L localized\n\n\n\nRatio M/L nmods\n\n\n\nRatio M/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio M/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio M/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio M/L type\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L___” + i\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L normalized___” + i\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L unmod. pep.\n\n\n\nRatio H/L localized\n\n\n\nRatio H/L nmods\n\n\n\nRatio H/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/L type\n\n\n\nRatio H/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/M\nThe ratio between two heavy and medium label partners.\n\n\n“Ratio H/M___” + i\nThe ratio between two heavy and medium label partners.\n\n\nRatio H/M normalized\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/M normalized___” + i\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/M unmod. pep.\n\n\n\nRatio H/M localized\n\n\n\nRatio H/M nmods\n\n\n\nRatio H/M variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/M count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/M iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/M type\n\n\n\nOccupancy L\n\n\n\nOccupancy M\n\n\n\nOccupancy H\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L___” + i\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L normalized___” + i\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L unmod. pep.\n\n\n\nRatio H/L localized\n\n\n\nRatio H/L nmods\n\n\n\nRatio H/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/L type\n\n\n\nOccupancy L\n\n\n\nOccupancy H"
  },
  {
    "objectID": "output_tables.html#protein-groups",
    "href": "output_tables.html#protein-groups",
    "title": "Output Tables",
    "section": "6 Protein Groups",
    "text": "6 Protein Groups\nThe Protein Groups table contains information on the identified proteins in the processed raw-files. Each single row contains the group of proteins that could be reconstructed from a set of peptides.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nProtein IDs\nIdentifier(s) of protein(s) contained in the protein group. They are sorted by number of identified peptides in descending order.\n\n\nMajority protein IDs\nThese are the IDs of those proteins that have at least half of the peptides that the leading protein has.\n\n\nPeptide counts (all)\nNumber of peptides associated with each protein in protein group, occuring in the order as the protein IDs occur in the ‘Protein IDs’ column. Here distinct peptide sequences are counted. Modified forms or different charges are counted as one peptide.\n\n\nPeptide counts (razor+unique)\nNumber of peptides associated with each protein in protein group, occuring in the order as the protein IDs occur in the ‘Protein IDs’ column. Here distinct peptide sequences are counted. Modified forms or different charges are counted as one peptide.\n\n\nPeptide counts (unique)\nNumber of peptides associated with each protein in protein group, occuring in the order as the protein IDs occur in the ‘Protein IDs’ column. Here distinct peptide sequences are counted. Modified forms or different charges are counted as one peptide.\n\n\nProtein names\nName(s) of protein(s) contained within the group.\n\n\nGene names\nName(s) of the gene(s) associated to the protein(s) contained within the group.\n\n\nMutated peptide count\n\n\n\nMutation names\n\n\n\n“Mutated peptide count” + exp\n\n\n\n“Mutation names” + exp\n\n\n\nFasta headers\nFasta headers(s) of protein(s) contained within the group.\n\n\nNumber of proteins\nNumber of proteins contained within the group. This corresponds to the number of entries in the colum ‘Protein IDs’.\n\n\nPeptides\nThe total number of peptide sequences associated with the protein group (i.e. for all the proteins in the group).\n\n\nRazor + unique peptides\nThe total number of razor + unique peptides associated with the protein group (i.e. these peptides are shared with another protein group).\n\n\nUnique peptides\nThe total number of unique peptides associated with the protein group (i.e. these peptides are not shared with another protein group).\n\n\n“Peptides” + exp\n“Number of peptides (distinct peptide sequences) in experiment” + exp\n\n\n“Razor + unique peptides” + exp\n“Number of razor + unique peptides (distinct peptide sequences) in experiment” + exp\n\n\n“Unique peptides” + exp\n“Number of unique peptides (distinct peptide sequences) in experiment” + exp\n\n\nSequence coverage [%]\nPercentage of the sequence that is covered by the identified peptides of the best protein sequence contained in the group.\n\n\nUnique + razor sequence coverage [%]\nPercentage of the sequence that is covered by the identified unique and razor peptides of the best protein sequence contained in the group.\n\n\nUnique sequence coverage [%]\nPercentage of the sequence that is covered by the identified unique peptides of the best protein sequence contained in the group.\n\n\nMol. weight [kDa]\nMolecular weight of the leading protein sequence contained in the protein group.\n\n\nSequence length\nThe length of the leading protein sequence contained in the group.\n\n\nSequence lengths\nThe length of all sequences of the proteins contained in the group.\n\n\nFraction average\n\n\n\n“Fraction” + t\n\n\n\nQ-value\nThis is the ratio of reverse to forward protein groups.\n\n\nScore\nProtein score which is derived from peptide posterior error probabilities.\n\n\n“Identification type” + exp\nIndicates whether this experiment was identified by MS/MS or only by matching between runs.\n\n\n“Sequence coverage” + exp + ” [%]”\nPercentage of the sequence that is covered by the identified peptides in this sample of the longest protein sequence contained within the group.\n\n\nOnly identified by site\nWhen marked with ‘+’, this particular protein group was identified only by a modification site.\n\n\nReverse\nWhen marked with ‘+’, this particular protein group contains no protein, made up of at least 50% of the peptides of the leading protein, with a peptide derived from the reversed part of the decoy database. These should be removed for further data analysis. The 50% rule is in place to prevent spurious protein hits to erroneously flag the protein group as reverse.\n\n\nPotential contaminant\nWhen marked with ‘+’, this particular protein group was found to be a commonly occurring contaminant. These should be removed for further data analysis.\n\n\nid\nA unique (consecutive) identifier for each row in the proteinGroups table, which is used to cross-link the information in this file with the information stored in the other files.\n\n\nPeptide IDs\nIdentifier(s) of the associated peptide sequence(s) summary, which can be found in the file ‘peptides.txt’.\n\n\nPeptide is razor\nIndicates for each peptide ID if it is a razor or group unique peptide (true) or a non unique non razor peptide (false).\n\n\nMod. peptide IDs\n\n\n\nEvidence IDs\n\n\n\nMS/MS IDs\n\n\n\nBest MS/MS\nThe identifier of the best (in terms of quality) MS/MS scans identifying the peptides of this protein, referenced against the msms table.\n\n\nt + ” site IDs”\nIdentifier(s) for site(s) associated with the protein group, which show(s) evidence of the modification, referenced against the appropriate modification site file.\n\n\nt + ” site positions”\nPositions of the sites in the leading protein of this group.\n\n\n“LFQ intensity L” + exp\n\n\n\n“LFQ intensity M” + exp\n\n\n\n“LFQ intensity H” + exp\n\n\n\n“LFQ intensity L” + exp\n\n\n\n“LFQ intensity H” + exp\n\n\n\n“LFQ intensity” + exp\n\n\n\n“iBAQ” + exp\n\n\n\n“iBAQ L” + exp\n\n\n\n“iBAQ M” + exp\n\n\n\n“iBAQ H” + exp\n\n\n\niBAQ\n\n\n\niBAQ L\n\n\n\niBAQ M\n\n\n\niBAQ H\n\n\n\n“iBAQ” + exp\n\n\n\n“iBAQ L” + exp\n\n\n\n“iBAQ H” + exp\n\n\n\niBAQ\n\n\n\niBAQ L\n\n\n\niBAQ H\n\n\n\n“iBAQ” + exp\n\n\n\niBAQ\n\n\n\nAVALON\n\n\n\nMS/MS Count\n\n\n\n“MS/MS Count” + exp\n\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity L” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\n“Intensity M” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\n“Intensity H” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity M\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Intensity L” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\n“Intensity H” + exp\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\n“Intensity” + exp\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\n“Ratio M/L” + exp\nThe ratio between two medium and light label partners.\n\n\n“Ratio M/L normalized” + exp\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio M/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio M/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio M/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio M/L type” + exp\n\n\n\n“Ratio H/L” + exp\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L normalized” + exp\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/L type” + exp\n\n\n\n“Ratio H/M” + exp\nThe ratio between two heavy and medium label partners.\n\n\n“Ratio H/M normalized” + exp\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/M variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/M count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/M iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/M type” + exp\n\n\n\nRatio M/L\nThe ratio between two medium and light label partners.\n\n\nRatio M/L normalized\nNormalized ratio between two heavy and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio M/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio M/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio M/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio M/L type\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/L type\n\n\n\nRatio H/M\nThe ratio between two heavy and medium label partners.\n\n\nRatio H/M normalized\nNormalized ratio between two heavy and medium label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/M variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/M count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/M iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/M type\n\n\n\n“Ratio H/L” + exp\nThe ratio between two heavy and light label partners.\n\n\n“Ratio H/L normalized” + exp\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\n“Ratio H/L variability [%]” + exp\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\n“Ratio H/L count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\n“Ratio H/L iso-count” + exp\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\n“Ratio H/L type” + exp\n\n\n\nRatio H/L\nThe ratio between two heavy and light label partners.\n\n\nRatio H/L normalized\nNormalized ratio between two medium and light label partners. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L variability [%]\nCoefficient of variability over all redundant quantifiable peptides. It is calculated as the standard deviation of the naturally logarithmized ratios times 100.\n\n\nRatio H/L count\nNumber of redundant peptides (MS1 features) used for quantitation.\n\n\nRatio H/L iso-count\nNumber of redundant peptides (MS1 features) used for quantitation that are quantified with the re-quantify method.\n\n\nRatio H/L type\n\n\n\n“Reporter intensity” + i\n\n\n\n“Reporter intensity not corrected” + i\n\n\n\n“Reporter intensity count” + i\n\n\n\n“Reporter intensity” + i + ” ” + exp\n\n\n\n“Reporter intensity not corrected” + i + ” ” + exp\n\n\n\n“Reporter intensity count” + i + ” ” + exp"
  },
  {
    "objectID": "output_tables.html#all-peptides",
    "href": "output_tables.html#all-peptides",
    "title": "Output Tables",
    "section": "7 All Peptides",
    "text": "7 All Peptides\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nRaw file\nName of the raw file the spectral data was extracted from.\n\n\nType\nThe type of detection for the peptide. MULTI - A labeling multiplet was detected. ISO - An isotope pattern was detected.\n\n\nCharge\nThe charge state of the peptide.\n\n\nm/z\nThe mass divided by the charge of the charged peptide.\n\n\nMass\nThe mass of the neutral peptide ((m/z-proton) * charge).\n\n\nUncalibrated m/z\nm/z before recalibrations have been applied.\n\n\nResolution\nThe resolution of the peak detected for the peptide measured in Full Width at Half Maximum (FWHM).\n\n\nNumber of data points\nThe number of data points (peak centroids) collected for this peptide feature.\n\n\nNumber of scans\nThe number of MS scans that the 3d peaks of this peptide feature are overlapping with.\n\n\nNumber of isotopic peaks\nThe number of isotopic peaks contained in this peptide feature.\n\n\nPIF\nShort for Parent Ion Fraction; indicates the fraction the target peak makes up of the total intensity in the inclusion window.\n\n\nMass fractional part\nThe values after the radix point (ie value - floor(value)).\n\n\nMass deficit\nEmpirically derived deviation measure to the next nearest integer scaled to center around 0. Can be used to visually detect contaminants in a plot setting Mass against this value. ma+b - round(ma+b) m: the peptide mass a: 0.999555 b: -0.10\n\n\nMass precision [ppm]\nThe precision of the mass detection of the peptide in parts-per-million.\n\n\nMax intensity m/z 0\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 0\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 1\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 0\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 1\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nMax intensity m/z 2\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nRetention time\nThe retention time of the peak detected for the peptide measured in minutes.\n\n\nRetention length\nThe total retention time width of the peak (last timepoint - first timepoint) in seconds.\n\n\nRetention length (FWHM)\nThe full width at half maximum value retention time width of the peak in seconds.\n\n\nMin scan number\nThe first scan-number at which the peak was encountered.\n\n\nMax scan number\nThe last scan-number at which the peak was encountered.\n\n\nIdentified\nWhen marked with ‘+’ this particular MS/MS scan was identified as a peptide; when marked with ‘-’ no identification was made.\n\n\nMS/MS IDs\nUnique identifier linking this identification to the MS/MS scans.\n\n\nSequence\nThe identified AA sequence of the peptide.\n\n\nLength\n“The length of the sequence stored in the column Sequence”.”\n\n\nModifications\nPost-translational modifications contained within the sequence. When no modifications exist, this is set to ‘unmodified’. Note: This column only set when this MS/MS spectrum has been identified.\n\n\nModified sequence\nSequence representation of the peptide including location(s) of modified AAs. Note: This column only set when this MS/MS spectrum has been identified.\n\n\nProteins\nIdentifiers of proteins this peptide is associated with. Note: This column only set when this MS/MS spectrum has been identified.\n\n\nScore\nThe score of the identification (higher is better). Note: This column only set when this MS/MS spectrum has been identified.\n\n\nt.Abbreviation + ” Count”\n“The number of instances of” + t.Abbreviation + ” contained within the sequence. The value for this can reliably be determined in the case of label partners, based on the distance between the partners. These counts are used to solidify the peptide identification process.”\n\n\nRatio H/L\nThe ratio between two heavy and light multiplet members.\n\n\nRatio H/L normalized\nNormalized ratio between two heavy and light multiplet members. The median of the total ratio population was shifted to 1.\n\n\nRatio M/L\nThe ratio between two medium and light multiplet members.\n\n\nRatio M/L normalized\nNormalized ratio between two medium and light multiplet members. The median of the total ratio population was shifted to 1.\n\n\nRatio H/L\nThe ratio between two heavy and light multiplet members.\n\n\nRatio H/L normalized\nNormalized ratio between two heavy and light multiplet members. The median of the total ratio population was shifted to 1.\n\n\nRatio H/M\nThe ratio between two heavy and medium multiplet members.\n\n\nRatio H/M normalized\nNormalized ratio between two heavy and medium multiplet members. The median of the total ratio population was shifted to 1.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensity\nSummed up eXtracted Ion Current (XIC) of all isotopic clusters associated with the identified AA sequence. In case of a labeled experiment this is the total intensity of all the isotopic patterns in the label cluster.\n\n\nIntensity L\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the light label partner.\n\n\nIntensity M\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the medium label partner.\n\n\nIntensity H\nSummed up eXtracted Ion Current (XIC) of the isotopic cluster linked to the heavy label partner.\n\n\nIntensities\nThe intensity values of the isotopes.\n\n\nIntensities L\nThe intensity values of the light label partner isotopes.\n\n\nIntensities H\nThe intensity values of the heavy label partner isotopes.\n\n\nIntensities L\nThe intensity values of the light label partner isotopes.\n\n\nIntensities M\nThe intensity values of the medium label partner isotopes.\n\n\nIntensities H\nThe intensity values of the heavy label partner isotopes.\n\n\nMS/MS Count\nThe number of MS/MS spectra recorded for the peptide.\n\n\nMSMS Scan Numbers\nThe scan numbers where the MS/MS spectra were recorded.\n\n\nMSMS label States\nThe label partner detected for the peptide. The value 0 is always the light partner. In the case of double label labeling 1 is the heavy partner. In the case of triple label labeling 1 is the medium and 2 the heavy partner.\n\n\nMSMS Isotope Indices\nIndices of the isotopic peaks that the MS/MS spectra reside on. A value of 0 corresponds to the monoisotopic peak.\n\n\nDP Mass Difference\n\n\n\nDP Time Difference\n\n\n\nDP Score\n\n\n\nDP PEP\n\n\n\nDP Positional Probability\n\n\n\nDP Base Sequence\n\n\n\nDP Probabilities\n\n\n\nDP AA\n\n\n\nDP Base Scan Number\n\n\n\nDP Mod Scan Number\n\n\n\nDP Decoy\n\n\n\nDP Proteins\n\n\n\nDP Cluster Index\n\n\n\nDP Cluster Mass\n\n\n\nDP Cluster Mass SD\n\n\n\nDP Cluster Size Total\n\n\n\nDP Cluster Size Forward\n\n\n\nDP Cluster Size Reverse\n\n\n\nDP Modification\n\n\n\nDP Peptide Length Difference\n\n\n\nDP Gene Names\n\n\n\nDP Protein Names\n\n\n\nDP Ratio mod/base\n\n\n\nDP Ratio mod/base\n\n\n\nDP Base Ratio H/L\n\n\n\nDP Base Ratio H/L Normalized\n\n\n\nDP Occupancy L\n\n\n\nDP Occupancy H\n\n\n\nDP Ratio mod/base\n\n\n\nDP Base Ratio M/L\n\n\n\nDP Base Ratio M/L Normalized\n\n\n\nDP Base Ratio H/L\n\n\n\nDP Base Ratio H/L Normalized\n\n\n\nDP Base Ratio H/M\n\n\n\nDP Base Ratio H/M Normalized\n\n\n\nDP Occupancy L\n\n\n\nDP Occupancy M\n\n\n\nDP Occupancy H\n\n\n\nMD modification\n\n\n\nMD mass error\n\n\n\nMD time difference\n\n\n\nMD sequence\n\n\n\nMD base scan number\n\n\n\nMD proteins\n\n\n\nMD gene names\n\n\n\nMD protein names\n\n\n\nCentroid mass differences [Da]\n\n\n\nCentroid mass differences [ppm]\n\n\n\nIsotope mass differences [Da]\n\n\n\nIsotope mass differences [ppm]"
  },
  {
    "objectID": "output_tables.html#msscans-table",
    "href": "output_tables.html#msscans-table",
    "title": "Output Tables",
    "section": "8 msScans Table",
    "text": "8 msScans Table\nThe msScans table contains information about the full scans, which can be used to verify data quality and generated useful statistics about the interaction between the samples and LC.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nRaw file\nThe name of the RAW-file the mass spectral data originates from.\n\n\nScan number\nThe scan number (defined in the raw-file) at which the full scan was made.\n\n\nScan index\nThe consecutive index of this full scan.\n\n\nRetention time\nThe retention time at which the full scan was made.\n\n\nCycle time\nThe total time (full scan including the tandem MS scans) this full scan has taken up.\n\n\nIon injection time\nThe total injection time that was required to capture the specified amount of ions. This value is limited by a maximum, which can be used to determine whether the time has maxed out (indicative of a bad acquisition).\n\n\nBase peak intensity\nThe intensity of the most intense ion in the spectrum.\n\n\nTotal ion current\nThe total intensity acquired in the full scan.\n\n\nMS/MS count\nThe number of tandem MS scans that were made based on this full scan (e.g. a top 10 method selects the top 10 most intense ions in the scan and fragments those).\n\n\nMass calibration\nThe applied mass correction in Th to the full scan.\n\n\nFraction\nThe fraction measured with this full scan.\n\n\ncolName\n\n\n\nPeak length\nThe average time between the start and the end of the peaks detected in the full scan.\n\n\nIsotope pattern length\nThe average time between the start and the end of the isotope patterns detected in the full scan.\n\n\nMultiplet length\nThe average time between the start and the end of the isotope patterns of the labeling multiplets detected in the full scan.\n\n\nPeaks / s\nThe average number of peaks detected per second of chromatography.\n\n\nSingle peaks / s\nThe average number of single peaks detected per second of chromatography.\n\n\nIsotope patterns / s\nThe average number of isotope patterns detected per second of chromatography.\n\n\nSingle isotope patterns / s\nThe average number of single isotope patterns detected per of second chromatography.\n\n\nMultiplets / s\nThe average number of labeling multiplets detected per of second chromatography.\n\n\nIdentified multiplets / s\nThe percentage of labeling multiplets actually identified.\n\n\nMultiplet identification rate [%]\nThe percentage of the detected labeling multiplets that were identified.\n\n\nAIF peaks / s\nThe average number of AIF peaks detected per second of chromatography.\n\n\nAIF single peaks / s\nThe average number of AIF single peaks detected per second of chromatography.\n\n\nAIF isotope patterns / s\nThe average number of AIF isotope patterns detected per second of chromatography.\n\n\nAIF single isotope patterns / s\nThe average number of AIF single isotope patterns detected per of second chromatography.\n\n\nAIF multiplets / s\nThe average number of AIF labeling multiplets detected per of second chromatography.\n\n\nMS/MS / s\nThe average number of MS/MS events per second of chromatography.\n\n\nIdentified MS/MS / s\nThe average number of identified MS/MS events per second of chromatography.\n\n\nMS/MS identification rate [%]\nThe percentage of tandem MS scans that were identified.\n\n\nIntens Comp Factor\nTaken from the Thermo RAW file.\n\n\nCTCD Comp\nTaken from the Thermo RAW file.\n\n\nRawOvFtT\nFor Thermo Fisher only. TIC estimation done with the orbitrap cell.\n\n\nAGC Fill\nTaken from the Thermo RAW file."
  },
  {
    "objectID": "output_tables.html#mzrange-table",
    "href": "output_tables.html#mzrange-table",
    "title": "Output Tables",
    "section": "9 MzRange Table",
    "text": "9 MzRange Table\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nRaw file\nThe name of the RAW-file the mass spectral data was derived from.\n\n\nm/z\nThe mass-over-charge value.\n\n\nPeaks / Da\nThe average number of peaks detected per Dalton.\n\n\nSingle peaks / Da\nThe average number of single peaks detected per Dalton.\n\n\nIsotope patterns / Da\nThe average number of isotope patterns detected per Dalton.\n\n\nSingle isotope patterns / Da\nThe average number of single isotope patterns detected per Dalton.\n\n\nSILAC pairs / Da\nThe average number of SILAC pairs detected per Dalton.\n\n\nIdentified SILAC pairs / Da\nThe percentage of SILAC pairs actually identified.\n\n\nSILAC identification rate [%]\nThe percentage of the detected SILAC pairs that were identified.\n\n\nAIF Peaks / Da\nThe average number of AIF peaks detected per Dalton.\n\n\nAIF Single peaks / Da\nThe average number of AIF single peaks detected per Dalton.\n\n\nAIF Isotope patterns / Da\nThe average number of AIF isotope patterns detected per Dalton.\n\n\nAIF Single isotope patterns / Da\nThe average number of AIF single isotope patterns detected per Dalton.\n\n\nAIF SILAC pairs / Da\nThe average number of AIF SILAC pairs detected per Dalton.\n\n\nMS/MS / Da\nThe average number of MS/MS events per Dalton.\n\n\nIdentified MS/MS / Da\nThe average number of identified MS/MS events per Dalton.\n\n\nIdentification rate [%]\nThe percentage of tandem MS scans that were identified."
  },
  {
    "objectID": "output_tables.html#msms-scans-table",
    "href": "output_tables.html#msms-scans-table",
    "title": "Output Tables",
    "section": "10 ms/ms Scans Table",
    "text": "10 ms/ms Scans Table\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nRaw file\nName of the RAW file the spectral MS/MS data was extracted from.\n\n\nScan number\nRAW file derived scan number for the MS/MS spectrum.\n\n\nRetention time\nTime point along the elution profile at which the MS/MS data was recorded.\n\n\nIon injection time\nThe ion inject time for the MS/MS scan. This can be used to determine if this time equals to the maximum ion inject time, general indicative of a lower quality spectrum.\n\n\nTotal ion current\nThe total ion current of the MS/MS scan. For Thermo data this value is calculated by summing all the intensity values found in the mass spectral data, which is different from the Xcalibur reported TIC (Xcalibur TIC is about 25% of the value reported here).\n\n\nCollision energy\nThe collision energy used for the fragmentation that resulted in this MS/MS scan.\n\n\nSummations\nFor time of flight instruments only.\n\n\nBase peak intensity\nThe intensity of the most intense ion in the spectrum.\n\n\nElapsed time\nThe time the MS/MS scan took to complete.\n\n\nIdentified\nWhen marked with ‘+’ this particular MS/MS scan was identified as a peptide; when marked with ‘-’ no identification was made.\n\n\nMS/MS IDs\nUnique identifier linking this identification to the MS/MS scans.\n\n\nSequence\nThe identified AA sequence of the peptide.\n\n\nLength\n“The length of the sequence stored in the column Sequence”.”\n\n\nFiltered peaks\nNumber of peaks after the ‘top X per 100 Da’ filtering.\n\n\nm/z\nRecalibrated m/z of the precursor ion.\n\n\nMass\nCharge corrected mass of the precursor ion.\n\n\nCharge\nCharge state of the precursor ion.\n\n\nType\nThe type of precursor ion as identified by MaxQuant. ISO - isotopic cluster. PEAK - single peak. MULTI - labeling cluster.\n\n\nFragmentation\nThe type of fragmentation used to create the MS/MS spectrum. CID - Collision Induced Dissociation. HCD - High energy Collision induced Dissociation. ETD - Electron Transfer Dissociation.\n\n\nMass analyzer\nThe mass analyzer used to record the MS/MS spectrum. ITMS - Ion trap. FTMS - Fourier transform ICR or orbitrap cell. TOF - Time of flight.\n\n\nParent intensity fraction\nThe percentage the parent ion intensity makes up of the total intensity in the selection window.\n\n\nFraction of total spectrum\nThe percentage the parent ion intensity makes up of the total intensity of the whole MS spectrum.\n\n\nBase peak fraction\nThe percentage the parent ion intensity in comparison to the highest peak in he MS spectrum.\n\n\nPrecursor full scan number\nThe full scan number where the precursor ion was selected for fragmentation.\n\n\nPrecursor intensity\nThe intensity of the precursor ion at the scannumber it was selected.\n\n\nPrecursor apex fraction\nThe fraction the intensity of the precursor ion makes up of the peak (apex) intensity.\n\n\nPrecursor apex offset\nHow many full scans the precursor ion is offset from the peak (apex) position.\n\n\nPrecursor apex offset time\nHow much time the precursor ion is offset from the peak (apex) position.\n\n\nScan event number\nThis number indicates which MS/MS scan this one is in the consecutive order of the MS/MS scans that are acquired after an MS scan.\n\n\nModifications\nPost-translational modifications contained within the sequence. When no modifications exist, this is set to ‘unmodified’. Note: This column only set when this MS/MS spectrum has been identified.\n\n\nModified sequence\nSequence representation of the peptide including location(s) of modified AAs. Note: This column only set when this MS/MS spectrum has been identified.\n\n\nProteins\nIdentifiers of proteins this peptide is associated with. Note: This column only set when this MS/MS spectrum has been identified.\n\n\nScore\nThe score of the identification (higher is better). Note: This column only set when this MS/MS spectrum has been identified.\n\n\nFraction\nThe identifier of the fraction the sample was taken from.\n\n\ncolName\n\n\n\nDN Sequence\n\n\n\nDN Score\n\n\n\nDN Normalized Score\n\n\n\nDN nterm mass\n\n\n\nDN cterm mass\n\n\n\nDN missing mass\n\n\n\nDN Sequence2\n\n\n\nDN Score2\n\n\n\nDN Normalized Score2\n\n\n\nDN nterm mass2\n\n\n\nDN cterm mass2\n\n\n\nDN missing mass2\n\n\n\nDN Score diff\n\n\n\nDP Mass Difference\nThis dependent peptide’s mass difference to the associated identified peptide.\n\n\nDP Time Difference\nThis dependent peptide’s time difference to the associated identified peptide.\n\n\nDP Score\nThe andromeda identification score.\n\n\nDP PEP\nPosterior Error Probability of the identification. This value essentially operates as a p-value, where smaller is more significant.\n\n\nDP Positional Probability\n\n\n\nDP Base Sequence\n\n\n\nDP Probabilities\n\n\n\nDP AA\n\n\n\nDP Base Scan Number\n\n\n\nDP Mod Scan Number\n\n\n\nDP Decoy\n\n\n\nDP Proteins\n\n\n\nDP Cluster Index\n\n\n\nDP Cluster Mass\n\n\n\nDP Cluster Mass SD\n\n\n\nDP Cluster Size Total\n\n\n\nDP Cluster Size Forward\n\n\n\nDP Cluster Size Reverse\n\n\n\nDP Modification\nPost-translational modifications contained within the sequence. When no modifications exist, this is set to ‘unmodified’.\n\n\nDP Peptide Length Difference\n\n\n\nDP Gene Names\nNames of proteins the identified peptide is associated with.\n\n\nDP Protein Names\nDescriptions of the proteins the identified peptide is associated with.\n\n\nIntens Comp Factor\nTaken from the Thermo RAW file.\n\n\nCTCD Comp\nTaken from the Thermo RAW file.\n\n\nRawOvFtT\nFor Thermo Fisher only. TIC estimation done with the orbitrap cell.\n\n\nAGC Fill\nTaken from the Thermo RAW file.\n\n\nScan index\nConsecutive index of the MS/MS spectrum.\n\n\nMS scan index\nConsecutive index of the MS spectrum prior to this MS/MS spectrum.\n\n\nMS scan number\nScan number of the MS spectrum prior to this MS/MS spectrum."
  },
  {
    "objectID": "output_tables.html#msms-table",
    "href": "output_tables.html#msms-table",
    "title": "Output Tables",
    "section": "11 ms/ms Table",
    "text": "11 ms/ms Table\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nRaw file\nThe name of the RAW file the mass spectral data was read from.\n\n\nScan number\nThe RAW-file derived scan number of the MS/MS spectrum.\n\n\nScan index\nThe consecutive index of the MS/MS spectrum.\n\n\nSequence\nThe identified AA sequence of the peptide.\n\n\nLength\nThe length of the sequence stored in the column “Sequence”.\n\n\n“Missed cleavages (” + enzyme + “)”\nNumber of missed enzymatic cleavages.\n\n\nMissed cleavages\nNumber of missed enzymatic cleavages.\n\n\nModifications\nPost-translational modifications contained within the identified peptide sequence.\n\n\nModified sequence\nSequence representation including the post-translational modifications (abbreviation of the modification in brackets before the modified AA). The sequence is always surrounded by underscore characters (’_’).\n\n\ntitle + ” Probabilities”\n“Sequence representation of the peptide including PTM positioning probabilities ([0..1], where 1 is best match) for ’” + title + “’.”\n\n\ntitle + ” Score Diffs”\n\n\n\nTables.ModificationList[t].Name\n\n\n\nProteins\nThe identifiers of the proteins the identified peptide is associated with.\n\n\nGene Names\nNames of genes the identified peptide is associated with.\n\n\nProtein Names\nDescriptions of the proteins the identified peptide is associated with.\n\n\nCharge\nThe charge state of the precursor ion.\n\n\nFragmentation\nThe type of fragmentation used to create the MS/MS spectrum. CID - Collision Induced Dissociation. HCD - High energy Collision induced Dissociation. ETD - Electron Transfer Dissociation.\n\n\nMass analyzer\nThe mass analyzer used to record the MS/MS spectrum. ITMS - Ion trap. FTMS - Fourier transform ICR or orbitrap cell. TOF - Time of flight.\n\n\nType\nThe type of precursor ion as identified by MaxQuant. ISO - isotopic cluster. PEAK - single peak. MULTI - labeling cluster.\n\n\nScan event number\n\n\n\nIsotope index\n\n\n\nm/z\nThe mass-over-charge of the precursor ion.\n\n\nMass\nThe charge corrected mass of the precursor ion.\n\n\nMass Error [ppm]\nMass error of the recalibrated mass-over-charge value of the precursor ion in comparison to the predicted monoisotopic mass of the identified peptide sequence.\n\n\nSimple Mass Error [ppm]\n\n\n\nRetention time\nThe uncalibrated retention time in minutes where the MS/MS spectrum has been acquired.\n\n\nPEP\nPosterior Error Probability of the identification. This value essentially operates as a p-value, where smaller is more significant.\n\n\nScore\nAndromeda score for the best associated MS/MS spectrum.\n\n\nDelta score\nScore difference to the second best identified peptide with a different amino acid sequence.\n\n\nScore diff\nScore difference to the second best positioning of modifications identified peptide with the same amino acid sequence.\n\n\nLocalization prob\n\n\n\nCombinatorics\nNumber of possible distributions of the modifications over the peptide sequence.\n\n\nLabeling State\nLabeling state of the precursor isotope pattern used to identify the peptide.\n\n\nPIF\nShort for Parent Ion Fraction; indicates the fraction the target peak makes up of the total intensity in the inclusion window.\n\n\nFraction of total spectrum\nThe percentage the parent ion intensity makes up of the total intensity of the whole spectrum.\n\n\nBase peak fraction\nThe percentage the parent ion intensity in comparison to the highest peak in he MS spectrum.\n\n\nPrecursor Full ScanNumber\nThe full scannumber where the precursor ion was selected for fragmentation.\n\n\nPrecursor Intensity\nThe intensity of the precursor ion at the scannumber it was selected.\n\n\nPrecursor Apex Fraction\nThe fraction the intensity of the precursor ion makes up of the peak (apex) intensity.\n\n\nPrecursor Apex Offset\nHow many full scans the precursor ion is offset from the peak (apex) position.\n\n\nPrecursor Apex Offset Time\nHow much time the precursor ion is offset from the peak (apex) position.\n\n\n“Diagnostic peak” + modName + ” ” + diagAa[i]\n\n\n\nMatches\nThe species of the peaks in the fragmentation spectrum after TopN filtering.\n\n\nIntensities\nThe intensities of the peaks in the fragmentation spectrum after TopN filtering.\n\n\nMass Deviations [Da]\nThe mass deviation of each peak in the fragmentation spectrum in absolute mass units.\n\n\nMass Deviations [ppm]\nThe mass deviation of each peak in the fragmentation spectrum in parts per million.\n\n\nMasses\nThe masses-over-charge of the peaks in the fragmentation spectrum.\n\n\nNumber of Matches\nThe number of peaks matching to the predicted fragmentation spectrum.\n\n\nIntensity coverage\nThe fraction of intensity in the MS/MS spectrum that is annotated.\n\n\nPeak coverage\nThe fraction of peaks in the MS/MS spectrum that are annotated.\n\n\nNeutral loss level\nHow many neutral losses were applied to each fragment in the Andromeda scoring.\n\n\nETD identification type\nFor ETD spectra several different combinations of ion series are scored. Here the highest scoring combination is indicated\n\n\nReverse\nWhen marked with ‘+’, this particular peptide was found to be part of a protein derived from the reversed part of the decoy database. These should be removed for further data analysis.\n\n\nAll scores\n\n\n\nAll sequences\n\n\n\nAll modified sequences\n\n\n\nid\nA unique (consecutive) identifier for each row in the msms table, which is used to cross-link the information in this file with the information stored in the other files.\n\n\nProtein group IDs\nThe identifier of the protein-group this redundant peptide sequence is associated with, which can be used to look up the extended protein information in the file ‘proteinGroups.txt’. As a single peptide can be linked to multiple proteins (e.g. in the case of razor-proteins), multiple id’s can be stored here separated by a semicolon. As a protein can be identified by multiple peptides, the same id can be found in different rows.\n\n\nPeptide ID\nThe identifier of the non-redundant peptide sequence.\n\n\nMod. peptide ID\nIdentifier of the associated modification summary stored in the file ‘modificationSpecificPeptides.txt’.\n\n\nEvidence ID\nIdentifier of the associated evidence stored in the file ‘evidence.txt’.\n\n\nt + ” site IDs”\n“Identifier of the oxidation summary stored in the file ’” + t + “Sites.txt’.”\n\n\n“Reporter intensity” + i\n\n\n\n“Reporter intensity not corrected” + i\n\n\n\nReporter PIF\n\n\n\nReporter fraction"
  },
  {
    "objectID": "output_tables.html#aif-msms-table",
    "href": "output_tables.html#aif-msms-table",
    "title": "Output Tables",
    "section": "12 AIF ms/ms Table",
    "text": "12 AIF ms/ms Table\n====== AIF MS/MS ======\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nid\nA unique (consecutive) identifier for each row in the AIF MS/MS table, which is used to cross-link the information in this file with the information stored in the other files.\n\n\nProtein group IDs\nThe identifier of the protein group this redundant peptide sequence is associated with, which can be used to look up the extended protein information in the file ‘proteinGroups.txt’. As a single peptide can be linked to multiple proteins (e.g. in the case of razor-proteins), multiple id’s can be stored here separated by a semicolon. As a protein can be identified by multiple peptides, the same id can be found in different rows.\n\n\nPeptide ID\nThe identifier of the non-redundant peptide sequence.\n\n\nMod. peptide ID\nIdentifier of the associated modification summary stored in the file ‘modificationSpecificPeptides.txt’.\n\n\nEvidence ID\nIdentifier for analyzed peptide evidence associated with the protein group referenced against the evidences table.\n\n\nt + ” site IDs”\n\n\n\nRaw file\nName of the RAW file the spectral data was extracted from, which led to the identification of this peptide.\n\n\nSequence\nThe identified AA sequence of the peptide.\n\n\nLength\nThe length of the sequence stored in the column “Sequence”.\n\n\n“Missed Cleavages (” + enzyme + “)”\nNumber of missed enzymatic cleavages.\n\n\nMissed Cleavages\nNumber of missed enzymatic cleavages.\n\n\nModifications\nPost-translational modifications contained within the sequence. When no modifications exist, this is set to ‘unmodified’. Note: This column only set when this MS/MS spectrum has been identified.\n\n\nModified Sequence\nSequence representation of the peptide including location(s) of modified AAs. Note: This column only set when this MS/MS spectrum has been identified.\n\n\nTables.ModificationList[t].Name + ” Probabilities”\n\n\n\nTables.ModificationList[t].Name + ” Score Diffs”\n\n\n\nTables.ModificationList[t].Name\n\n\n\nProteins\nThe IPI identifiers of the proteins the identified peptide is associated with.\n\n\nCharge\nThe charge of the precursor ion.\n\n\nm/z\nThe mass-over-charge of the precursor ion.\n\n\nMass\nThe charge corrected mass of the precursor ion.\n\n\nRetention time\nThe uncalibrated retention time in minutes in the elution profile of the precursor ion.\n\n\nPrecursor intensity\nThe intensity of the precursor ion.\n\n\nPEP\nPosterior Error Probability of the identification. This value essentially operates as a p-value, where smaller is more significant.\n\n\nScore\nAndromeda identification score for the MS/MS spectrum.\n\n\nDelta score\nScore difference to the second best identified peptide.\n\n\nCombinatorics\nNumber of possible distributions of the modifications over the peptide sequence.\n\n\nMatches\n\n\n\nIntensities\nThe intensities of the peaks in the fragmentation spectrum after top-N filtering.\n\n\nMass Deviations\nThe search engine allowed mass deviations of the peaks in the fragmentation spectrum.\n\n\nMasses\nThe masses-over-charge of the peaks in the fragmentation spectrum.\n\n\nCharges\n\n\n\nCorrelations\n\n\n\nNumber of Matches\n\n\n\nReverse\nWhen marked with ‘+’, this particular peptide was found to be part of a protein derived from the reversed part of the decoy database. These should be removed for further data analysis."
  },
  {
    "objectID": "unstructuredtxtupload.html",
    "href": "unstructuredtxtupload.html",
    "title": "Unstructured Text Upload",
    "section": "",
    "text": "Type: - Matrix Upload\nSource code: UnstructuredTxtUpload.cs"
  },
  {
    "objectID": "unstructuredtxtupload.html#file",
    "href": "unstructuredtxtupload.html#file",
    "title": "Unstructured Text Upload",
    "section": "3.1 File",
    "text": "3.1 File\nSpecifies the file path of the text file that should be uploaded (default: empty). It can be specified manually by typing in the path or the file can be browsed by using the “Select” button."
  },
  {
    "objectID": "unstructuredtxtupload.html#split-into-columns",
    "href": "unstructuredtxtupload.html#split-into-columns",
    "title": "Unstructured Text Upload",
    "section": "3.2 Split into columns",
    "text": "3.2 Split into columns\nIf checked the lines of the specified text file are split into several columns (default: FALSE)."
  },
  {
    "objectID": "unstructuredtxtupload.html#separator",
    "href": "unstructuredtxtupload.html#separator",
    "title": "Unstructured Text Upload",
    "section": "3.3 Separator",
    "text": "3.3 Separator\nThis parameter is just relevant, if the parameter “Split into columns” is TRUE.\nIt specifies how the values within a row of the text file are separated (default: Tab). The separation type can be selected from a predefined list:\n\nTab\nComma"
  },
  {
    "objectID": "unstructuredtxtupload.html#parameter-window",
    "href": "unstructuredtxtupload.html#parameter-window",
    "title": "Unstructured Text Upload",
    "section": "3.4 Parameter window",
    "text": "3.4 Parameter window\n\n\n\nRaw upload"
  },
  {
    "objectID": "andromeda_modifications_table.html",
    "href": "andromeda_modifications_table.html",
    "title": "Andromeda modifications table",
    "section": "",
    "text": "For the here shown step by step description Andromeda was used within MaxQuant (version 1.5.3.8).\n\n\nOpen MaxQuant and go to the Andromeda configuration tab. The “Modifications” page is already selected Figure 1.\n\n\n\nFigure 1: Andromeda modification page\n\n\n\n\nFirst we will have a look at a modification to understand how modifications are defined in MaxQuant.\nChoose the “Phospho (STY)” modification in the table on the left hand side. You can either browse through the table or use the \"Find...\" function of Andromeda by right clicking on the table and choosing it from the appearing menu. Then a pop-up window will show up and you can specify what you are searching and whether the term should be searched (parameter “Look in”) in the whole table or in a specific column. in Figure 2 we search in the “Name” column.\n\n\n\nFigure 2: Andromeda search modification window\n\n\nThe row will be selected and the settings of the modification appear on the right hand side of the Andromeda window (s. Figure 3. Only one modification is defined together for S, T and Y. This is important for the proper calculation of localization scores for phosphorylation sites. You will notice that a neutral loss of a phosphate is only defined for serine and threonine by clicking on the amino acids in the window on the right.\nA diagnostic peak of composition \\(C_8H_{10}O_4P\\) is only defined for tyrosine, which is the characteristic immonium ion for tyrosine phosphorylation. This will only be relevant for fragmentation spectra in which the lower mass range is available.\n\n\n\nFigure 3: Andromeda modification information\n\n\n\n\n\nNow, we will add a new Modification. You can visit unimod.org and select a modification that has not been defined yet in MaxQuant and add this modification to the modification list in MaxQuant. Here we are adding Dehydroalanine from Tyrosine. All the information that we need can be extracted from the unimod homepage (Figure 4) like the compositional change as well as the site specificity.\n\n\n\nFigure 4: Information extracted from unimod can be used to add modifications to the Andromeda search\n\n\nFirst click the “Add” button (left side of the ribbon on Figure 5). Then a new row will be added at the end of the table and a new modification form will appear on the right hand side that can be edited.\n\n\n\nFigure 5: Add modification to the andromeda search\n\n\nThen you just have to transfer the information from the unimod table to the form. Note that when your done you have to press the “Modify table” button to transfer the changes you made on the right side to the table on the left. And to save the table to the modifications.xml file you press the button “Save changes” (highlighted in Figure 6.\nTo have the added modification available in MaxQuant you have to open a new MaxQuant window.\n\n\n\nFigure 6: Save modification\n\n\n\n\n\nNote that the isotopic and isobaric labels are also defined in this table. Labels have written “Label” in the “Type” column and are the labels that can be used in MaxQuant for MS1 level quantification. Isobaric labels can also be identified by their term “isobaric Label” in the “Type” column.\nNow we define a new hypothetical SILAC label, His8 (\\(His^{13}C_5^{15}N_3\\)). (s. Figure 7) Therefore, we add a new entry to the modifications table.\n\n\n\nFigure 7: Add a new label\n\n\nThen the form on the right can be edited. It is important to keep in mind that we are not just adding heavy amino acids, but also have to remove the same amount of “normal” amino acids. Don’t forget to press the “Modify table” button when your done to transfer the changes you made on the right side to the table on the left. And to save the table to the modifications.xml file you have to click the “Save changes” button.\nTo have the added modification available in MaxQuant you have to open a new MaxQuant window.\n\n\n\nFigure 8: save the changed label"
  },
  {
    "objectID": "andromeda_modifications_table.html#open-the-modifications-table",
    "href": "andromeda_modifications_table.html#open-the-modifications-table",
    "title": "Andromeda modifications table",
    "section": "",
    "text": "Open MaxQuant and go to the Andromeda configuration tab. The “Modifications” page is already selected Figure 1.\n\n\n\nFigure 1: Andromeda modification page\n\n\n\n\nFirst we will have a look at a modification to understand how modifications are defined in MaxQuant.\nChoose the “Phospho (STY)” modification in the table on the left hand side. You can either browse through the table or use the \"Find...\" function of Andromeda by right clicking on the table and choosing it from the appearing menu. Then a pop-up window will show up and you can specify what you are searching and whether the term should be searched (parameter “Look in”) in the whole table or in a specific column. in Figure 2 we search in the “Name” column.\n\n\n\nFigure 2: Andromeda search modification window\n\n\nThe row will be selected and the settings of the modification appear on the right hand side of the Andromeda window (s. Figure 3. Only one modification is defined together for S, T and Y. This is important for the proper calculation of localization scores for phosphorylation sites. You will notice that a neutral loss of a phosphate is only defined for serine and threonine by clicking on the amino acids in the window on the right.\nA diagnostic peak of composition \\(C_8H_{10}O_4P\\) is only defined for tyrosine, which is the characteristic immonium ion for tyrosine phosphorylation. This will only be relevant for fragmentation spectra in which the lower mass range is available.\n\n\n\nFigure 3: Andromeda modification information\n\n\n\n\n\nNow, we will add a new Modification. You can visit unimod.org and select a modification that has not been defined yet in MaxQuant and add this modification to the modification list in MaxQuant. Here we are adding Dehydroalanine from Tyrosine. All the information that we need can be extracted from the unimod homepage (Figure 4) like the compositional change as well as the site specificity.\n\n\n\nFigure 4: Information extracted from unimod can be used to add modifications to the Andromeda search\n\n\nFirst click the “Add” button (left side of the ribbon on Figure 5). Then a new row will be added at the end of the table and a new modification form will appear on the right hand side that can be edited.\n\n\n\nFigure 5: Add modification to the andromeda search\n\n\nThen you just have to transfer the information from the unimod table to the form. Note that when your done you have to press the “Modify table” button to transfer the changes you made on the right side to the table on the left. And to save the table to the modifications.xml file you press the button “Save changes” (highlighted in Figure 6.\nTo have the added modification available in MaxQuant you have to open a new MaxQuant window.\n\n\n\nFigure 6: Save modification\n\n\n\n\n\nNote that the isotopic and isobaric labels are also defined in this table. Labels have written “Label” in the “Type” column and are the labels that can be used in MaxQuant for MS1 level quantification. Isobaric labels can also be identified by their term “isobaric Label” in the “Type” column.\nNow we define a new hypothetical SILAC label, His8 (\\(His^{13}C_5^{15}N_3\\)). (s. Figure 7) Therefore, we add a new entry to the modifications table.\n\n\n\nFigure 7: Add a new label\n\n\nThen the form on the right can be edited. It is important to keep in mind that we are not just adding heavy amino acids, but also have to remove the same amount of “normal” amino acids. Don’t forget to press the “Modify table” button when your done to transfer the changes you made on the right side to the table on the left. And to save the table to the modifications.xml file you have to click the “Save changes” button.\nTo have the added modification available in MaxQuant you have to open a new MaxQuant window.\n\n\n\nFigure 8: save the changed label"
  },
  {
    "objectID": "user_intereface.html",
    "href": "user_intereface.html",
    "title": "The Viewer",
    "section": "",
    "text": "The user interface of the Viewer, which is packed with MaxQuant is located at the “Viewer” tab of the MaxQuant software (highlighted by a red rectangle in Figure 1). The title bar along the top has the MaxQuant logo on the left, followed by an icon that can be used to rename the session, which will be displayed and is by default Session 1 - MaxQuant - name of the currently displayed raw file. The ribbon of the “Viewer” tab contains three groups of functions: the Map controls (highlighted by a petrol blue rectangle to the left), the Feature controls (highlighted by a yellow rectangle in the middle) and the Table navigation (highlighted by a red-brown rectangle on the right hand side). The functionalities of all buttons within each category can be obtained from their tool tips.\n\n\n\nFigure 1: Viewer Ribbon\n\n\nThe Viewer window (s. Figure 2) is split into four different areas: the map view (top left), the MS-feature view (bottom left), the table view (top right) and the protein view (bottome right). Each view can be manipulated with the corresponding buttons. The left window with the map view and the MS-feature view can be either split horizontally or vertically by the button highlighted by the blue rectangle in Figure 1.\n\n\n\nFigure 2: Viewer window"
  },
  {
    "objectID": "quantiles.html",
    "href": "quantiles.html",
    "title": "Quantiles",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: Quantiles.cs"
  },
  {
    "objectID": "quantiles.html#number-of-quantiles",
    "href": "quantiles.html#number-of-quantiles",
    "title": "Quantiles",
    "section": "3.1 Number of quantiles",
    "text": "3.1 Number of quantiles\nDefined number of quantiles (default: 5), each of the selected expression/numerical columns will be transformed into."
  },
  {
    "objectID": "quantiles.html#columns",
    "href": "quantiles.html#columns",
    "title": "Quantiles",
    "section": "3.2 Columns",
    "text": "3.2 Columns\nSelected expression/numerical columns that should be transformed into quantiles (default: all expression columns are selected)."
  },
  {
    "objectID": "viewer_tutorials.html",
    "href": "viewer_tutorials.html",
    "title": "Viewer - Tutorials",
    "section": "",
    "text": "Tutorials explaining how to use the viewer can be found in our YouTube channel.\nA few examples are listed below:\nMaxQuant Viewer tutorials\nFrom our 2023 MaxQunat Summer School in Boston\n\nMaxQuant basic I + II\nFrom our 2022 MaxQunat Summer School in Barcelona\n\nMaxQuant Basics I and II\nFrom our online MaxQunat SummerSchool in 2021.\n\n\nMaxQuant Viewer\nFrom our 2019 MaxQunat Summer School in Madison"
  },
  {
    "objectID": "uniquevalues.html",
    "href": "uniquevalues.html",
    "title": "Unique Values",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: UniqueValues.cs"
  },
  {
    "objectID": "uniquevalues.html#text-columns",
    "href": "uniquevalues.html#text-columns",
    "title": "Unique Values",
    "section": "3.1 Text columns",
    "text": "3.1 Text columns\nSelected text columns, whose values should be made unique (default: no columns are selected)."
  },
  {
    "objectID": "convertmultinumeric.html",
    "href": "convertmultinumeric.html",
    "title": "Convert multi-numeric column",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: ConvertMultiNumeric.cs"
  },
  {
    "objectID": "convertmultinumeric.html#operation",
    "href": "convertmultinumeric.html#operation",
    "title": "Convert multi-numeric column",
    "section": "3.1 Operation",
    "text": "3.1 Operation\nSelected operations that should be applied to multi-numeric columns to gain a numeric column with one value per row (default: no operations are selected). For each selected operation a separate numeric column is generated. The operations can be selected from a predefined list:\n\nCount\nSum\nProduct\nAverage\nMedian"
  },
  {
    "objectID": "convertmultinumeric.html#columns",
    "href": "convertmultinumeric.html#columns",
    "title": "Convert multi-numeric column",
    "section": "3.2 Columns",
    "text": "3.2 Columns\nSelected multi-numeric columns that will be transformed applying each of the selected operations (default: all multi-numeric columns are selected)."
  },
  {
    "objectID": "removeemptycolumns.html",
    "href": "removeemptycolumns.html",
    "title": "Remove Empty Columns",
    "section": "",
    "text": "1 General\n\nType: - Matrix Processing\nHeading: - Rearrange\nSource code: RemoveEmptyColumns.cs\n\n\n\n2 Brief description\nColumns containing no values or only invalid values will be removed.\nOutput: Same matrix but with empty columns removed.\n\n\n\n3 Parameters\n“Remove empty columns” has no parameters."
  },
  {
    "objectID": "andromeda_instructions.html",
    "href": "andromeda_instructions.html",
    "title": "Andromeda - Start",
    "section": "",
    "text": "Andromeda1 is a peptide search engine based on probabilistic scoring. On proteome data, Andromeda performs as well as Mascot, a widely used commercial search engine, as judged by sensitivity and specificity analysis based on target decoy searches.\nIt can handle data with arbitrarily high fragment mass accuracy, it is also able to assign and score complex patterns of post-translational modifications, such as highly phosphorylated peptides, and accommodates extremely large databases. Andromeda can function independently or integrated into MaxQuant. This combination enables analysis of large datasets on a desktop computer. Identification of co-fragmented peptides improves the number of identified peptides.\nTo run Andromeda, you will need .NET framework 4.5.\n\n1 Documentation outline\nThis documentation is organized as a wiki, so if you find anything that is wrong or hard to understand, please let us know. The wiki can be browsed by using the links below or by searching with the magnifying glass in the upper right corner.\n\nmaxquant - Download and installation\nAndromeda User Interface\nAndromeda Configuration\nAndromeda Tutorial\nGoogle groups\nmaxquant Bug reporting\nGlossary\n\nYou can find raw file format examples to test Andromeda here.\nFor additional training, consider attending the annual MaxQuant Summer School. Also watching some MaxQuant videos provides more insight.\n\n\n\n\n\nReferences\n\n1. Cox, J. et al. Andromeda: A Peptide Search Engine Integrated into the MaxQuant Environment. Journal of Proteome Research 10, 1794–1805 (2011)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cox Docs",
    "section": "",
    "text": "Welcome to coxdocs.org, the home of the documentation for\n\nMaxQuant\nPerseus\nAndromeda"
  },
  {
    "objectID": "Glossary.html",
    "href": "Glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "===== A =====\n===== B =====\n===== C =====\n===== D =====\n===== E =====\n===== F =====\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nFDR\nFalse Discovery Rate\n\n\nFTICR\nFourier transform ion cyclotron resonance mass spectrometry\n\n\n\n\n\n\n\n===== G =====\n===== H =====\n===== I =====\n\n\n\n\n\nterm\ndefinition\n\n\n\n\niBAQ\nIntensity Based Absolute Quantification\n\n\nICAT\nIsotope-coded affinity tag\n\n\niTRAQ\nIsobaric tag for relative and absolute quantitation\n\n\n\n\n\n\n\n===== J =====\n===== K =====\n===== L =====\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nLFQ\nLabel-free quantification\n\n\n\n\n\n\n\n===== M =====\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nMALDI\nMatrix-assisted laser desorption/ionization\n\n\n\n\n\n\n\n===== N =====\n===== O =====\n===== P =====\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nPAGE\nPolyacrylamide gel electrophoresis\n\n\nPEP\nPosterior Error Probability\n\n\n\n\n\n\n\n===== Q =====\n===== R =====\n===== S =====\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nSDS\nsodium dodecyl sulfate\n\n\nSILAC\nstable isotope labeling by/with amino acids in cell culture\n\n\nSWIFT\nStored waveform inverse Fourier transform\n\n\n\n\n\n\n\n===== T =====\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nTMT\nTandem mass tag\n\n\n\n\n\n\n\n===== U =====\n===== V =====\n===== W =====\n===== X =====\n===== Y =====\n===== Z =====\n\nWe welcome suggestions for additional entries to this glossary, or corrections to existing entries. For technical reasons, we have not made this page editable by users. Please use the following contact possibilities instead.\n\nThe glossary was created using the glossary package1\n\n\n\n\nReferences\n\n1. DeBruine, L. Glossary: Glossaries for markdown and quarto documents. (2023)."
  },
  {
    "objectID": "performancecurves.html",
    "href": "performancecurves.html",
    "title": "Performance curves",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: PerformanceCurves.cs"
  },
  {
    "objectID": "performancecurves.html#indicated-are",
    "href": "performancecurves.html#indicated-are",
    "title": "Performance curves",
    "section": "2.1 Indicated are",
    "text": "2.1 Indicated are\nSpecification whether rows containing the “Indicator” in the categorical column specified in “In column” correspond to the class under observation or not (default: False)."
  },
  {
    "objectID": "performancecurves.html#in-column",
    "href": "performancecurves.html#in-column",
    "title": "Performance curves",
    "section": "2.2 In column",
    "text": "2.2 In column\nSelected categorical column containing the class membership of each instance (row) of the class under observation (default: first categorical column in the matrix)."
  },
  {
    "objectID": "performancecurves.html#indicator",
    "href": "performancecurves.html#indicator",
    "title": "Performance curves",
    "section": "2.3 Indicator",
    "text": "2.3 Indicator\nRows containing the defined string are counted as true or false depending on the selection in “Indicated are” (default: \\(+\\))."
  },
  {
    "objectID": "performancecurves.html#scores",
    "href": "performancecurves.html#scores",
    "title": "Performance curves",
    "section": "2.4 Scores",
    "text": "2.4 Scores\nSelected expression columns containing the scores by which the rows are ranked to calculate the specified quantities (default: first expression column of the matrix is selected)."
  },
  {
    "objectID": "performancecurves.html#large-values-are-good",
    "href": "performancecurves.html#large-values-are-good",
    "title": "Performance curves",
    "section": "2.5 Large values are good",
    "text": "2.5 Large values are good\nIf checked the larger the score value the better (default: checked). Otherwise the lower the value the better."
  },
  {
    "objectID": "performancecurves.html#display-quantity",
    "href": "performancecurves.html#display-quantity",
    "title": "Performance curves",
    "section": "2.6 Display quantity",
    "text": "2.6 Display quantity\nSelected quantities that will be calculated (default: no quantities are selected). The quantities can be selected from a predefined list:\n\n\\(TP/(TP+FP)\\) (Precision)\n\\(TP/(TP+FN)\\) (Recall)\n\\(FP/TP\\)\n\\(TP/NP\\)\n\\(TP/(TP+FN)\\) (Sensitivity)\n\\(TN/(TN+FP)\\) (Specificity)"
  },
  {
    "objectID": "renamecolumnsregexp.html",
    "href": "renamecolumnsregexp.html",
    "title": "Rename Column by Reg. Exp.",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: RenameColumnsRegexp.cs"
  },
  {
    "objectID": "renamecolumnsregexp.html#regular-expression",
    "href": "renamecolumnsregexp.html#regular-expression",
    "title": "Rename Column by Reg. Exp.",
    "section": "3.1 Regular expression",
    "text": "3.1 Regular expression\nSpecified regular expression that is applied to all column names to rename them (default: no string).\nThe general concept of regular expressions can be found under Regular_expression. If you already know generally how regular expressions work, you may only need to glance at a the Quick Reference or at an even quicker Cheat Sheet.\n\\"
  },
  {
    "objectID": "andromeda_enzymes.html",
    "href": "andromeda_enzymes.html",
    "title": "Andromeda Enzymes - the proteases table",
    "section": "",
    "text": "For the here shown step by step description Andromeda was used within MaxQuant (version 1.5.3.8).\n\n\nOpen MaxQuant and go to the Andromeda configuration tab. There select the Data type “Proteases” (s. Figure 1).\n\n\n\nFigure 1: Adding new Proteases\n\n\n\n\n\nIn most studies samples are digested using Trypsin. In the “Proteases” table you will find two different definitions for Trypsin. The first definition cleaves at the carboxyl side of the amino acids lysine or arginine, except when either is followed by proline (see Description on the right hand side of the Andromeda window). That’s the classical definition. Additional comments in Figure 2 are in black and blue.\n\n\n\nFigure 2: An example of added Trypsin protease to the table\n\n\nHowever the commonly used definition is “Trypsin/P”, which also cleaves at carboxyl side of the amino acids lysine or arginine, also if a proline follows (highlighted in red in Figure 3). Additional comments in Figure 3 are in black and blue.\n\n\n\nFigure 3: TrypsinP cleaves at the carboxyl side of the AA\n\n\n\n\n\nLet’s assume Chymotrypsin is not yet provided in Andromeda and we want to add it. From the literature we know Chymotrypsin cleaves c-terminal after Phenylalanine (F), Tryptophan (W) and Tyrosine (Y).\nFirst click the “Add” button as shown in Figure 4. Then a new row will be added at the end of the table and a new protease form will appear on the right hand side that can be edited.\n\n\n\nFigure 4: Adding Chymotrypsin\n\n\nThen you just have to fill in the form by defining a name, a description and the specificity. Don’t forget to click the “Modify table” button when your done to transfer the changes you made in the form to the table on the left. And to save the table you have to click the “Save changes” button. Additional comments on the screenshot are in black and blue in Figure 5.\nTo have the added modification available in MaxQuant you have to open a new MaxQuant window.\n\n\n\nFigure 5: save added protease\n\n\nComment: Note that you also can do completely unspecific searches in MaxQuant. For this no definition of an enzyme is necessary."
  },
  {
    "objectID": "andromeda_enzymes.html#open-the-proteases-table",
    "href": "andromeda_enzymes.html#open-the-proteases-table",
    "title": "Andromeda Enzymes - the proteases table",
    "section": "",
    "text": "Open MaxQuant and go to the Andromeda configuration tab. There select the Data type “Proteases” (s. Figure 1).\n\n\n\nFigure 1: Adding new Proteases"
  },
  {
    "objectID": "andromeda_enzymes.html#viewing-examples",
    "href": "andromeda_enzymes.html#viewing-examples",
    "title": "Andromeda Enzymes - the proteases table",
    "section": "",
    "text": "In most studies samples are digested using Trypsin. In the “Proteases” table you will find two different definitions for Trypsin. The first definition cleaves at the carboxyl side of the amino acids lysine or arginine, except when either is followed by proline (see Description on the right hand side of the Andromeda window). That’s the classical definition. Additional comments in Figure 2 are in black and blue.\n\n\n\nFigure 2: An example of added Trypsin protease to the table\n\n\nHowever the commonly used definition is “Trypsin/P”, which also cleaves at carboxyl side of the amino acids lysine or arginine, also if a proline follows (highlighted in red in Figure 3). Additional comments in Figure 3 are in black and blue.\n\n\n\nFigure 3: TrypsinP cleaves at the carboxyl side of the AA"
  },
  {
    "objectID": "andromeda_enzymes.html#adding-a-new-protease",
    "href": "andromeda_enzymes.html#adding-a-new-protease",
    "title": "Andromeda Enzymes - the proteases table",
    "section": "",
    "text": "Let’s assume Chymotrypsin is not yet provided in Andromeda and we want to add it. From the literature we know Chymotrypsin cleaves c-terminal after Phenylalanine (F), Tryptophan (W) and Tyrosine (Y).\nFirst click the “Add” button as shown in Figure 4. Then a new row will be added at the end of the table and a new protease form will appear on the right hand side that can be edited.\n\n\n\nFigure 4: Adding Chymotrypsin\n\n\nThen you just have to fill in the form by defining a name, a description and the specificity. Don’t forget to click the “Modify table” button when your done to transfer the changes you made in the form to the table on the left. And to save the table you have to click the “Save changes” button. Additional comments on the screenshot are in black and blue in Figure 5.\nTo have the added modification available in MaxQuant you have to open a new MaxQuant window.\n\n\n\nFigure 5: save added protease\n\n\nComment: Note that you also can do completely unspecific searches in MaxQuant. For this no definition of an enzyme is necessary."
  },
  {
    "objectID": "binaryupload.html",
    "href": "binaryupload.html",
    "title": "Binary Upload",
    "section": "",
    "text": "Type: - Matrix Upload\nSource code: BinaryUpload.cs"
  },
  {
    "objectID": "binaryupload.html#file",
    "href": "binaryupload.html#file",
    "title": "Binary Upload",
    "section": "3.1 File",
    "text": "3.1 File\nSpecifies the file path of the binary file that should be uploaded (default: empty). It can be specified manually by typing in the path or the file can be browsed by using the “Select” button. All file extensions are supported."
  },
  {
    "objectID": "significanceb.html",
    "href": "significanceb.html",
    "title": "Significance B",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Outliers\nSource code: SignificanceB.cs"
  },
  {
    "objectID": "significanceb.html#ratio-columns",
    "href": "significanceb.html#ratio-columns",
    "title": "Significance B",
    "section": "3.1 Ratio columns",
    "text": "3.1 Ratio columns\nSelected expression columns containing the ratios for which “Significance B” should be calculated (default: no columns are selected).\nHint: The number of selected ratio columns must be the same as the number of selected intensity columns."
  },
  {
    "objectID": "significanceb.html#intensity-columns",
    "href": "significanceb.html#intensity-columns",
    "title": "Significance B",
    "section": "3.2 Intensity columns",
    "text": "3.2 Intensity columns\nSelected expression/numerical columns containing the intensities for which “Significance B” should be calculated (default: no columns are selected).\nHint: The number of selected intensity columns must be the same as the number of selected ratio columns."
  },
  {
    "objectID": "significanceb.html#side",
    "href": "significanceb.html#side",
    "title": "Significance B",
    "section": "3.3 Side",
    "text": "3.3 Side\nTo apply a two-sided test, where the null hypothesis can be rejected regardless of the direction of the effect “both” has to be selected (default). “left” and “right” are the respective one-sided tests.\n\n3.3.1 Use for truncation\nThe truncation can be based on p-values or the Benjamini-Hochberg correction for multiple hypothesis testing (default: Benjamini-Hochberg FDR). Rows with a test result below a specified value (parameter below) are reported as significant."
  },
  {
    "objectID": "significanceb.html#threshold-value",
    "href": "significanceb.html#threshold-value",
    "title": "Significance B",
    "section": "3.4 Threshold value",
    "text": "3.4 Threshold value\nBased on a specified threshold a specific row is reported as significant (default: 0.05). Depending on the chosen truncation score this threshold value is applied to the p-value or to the Benjamini-Hochberg FDR."
  },
  {
    "objectID": "andromeda_configurations.html",
    "href": "andromeda_configurations.html",
    "title": "Andromeda Configurations",
    "section": "",
    "text": "The Andromeda search engine1 offers a large variety of already defined modifications, proteases and sequence databases. But sometimes for specialized studies additional configurations are necessary. Therefore it is possible to configure the search engine according to special needs. You can add, remove, duplicate or modify modifications, enzymes and protein sequence databases. Also rearranging the order in the lists is possible to e.g. easier compare things. This rearrangements have no effect on the later analyses.\nOn the following pages are step by step descriptions how to configure…\n\nAndromeda modifications table\nAndromeda Enzymes - the proteases table\nAndromeda Protdatabases - the (protein) sequence databases table\n\nFor question we would love to hear from you under Contact\n\n\n\n\nReferences\n\n1. Cox, J. et al. Andromeda: A Peptide Search Engine Integrated into the MaxQuant Environment. Journal of Proteome Research 10, 1794–1805 (2011)."
  },
  {
    "objectID": "combinecategoricalcolumns.html",
    "href": "combinecategoricalcolumns.html",
    "title": "Combine categorical columns",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: CombineCategoricalColumns.cs"
  },
  {
    "objectID": "combinecategoricalcolumns.html#first-column",
    "href": "combinecategoricalcolumns.html#first-column",
    "title": "Combine categorical columns",
    "section": "3.1 First column",
    "text": "3.1 First column\nFirst selected categorical column, whose values should be concatenated to the second one (default: first categorical column of the matrix). The new generated categorical column contains the two values concatenated with a “_” in between."
  },
  {
    "objectID": "combinecategoricalcolumns.html#second-column",
    "href": "combinecategoricalcolumns.html#second-column",
    "title": "Combine categorical columns",
    "section": "3.2 Second column",
    "text": "3.2 Second column\nSecond selected categorical column, whose values should be concatenated to the first one (default: first categorical column of the matrix). The new generated categorical column contains the two values concatenated with a “_” in between."
  },
  {
    "objectID": "creategenelist.html",
    "href": "creategenelist.html",
    "title": "Create Gene list",
    "section": "",
    "text": "Type: - Matrix Upload\nSource code: CreateGeneList.cs\n\n===== Brief description =====\nStart with a list of all protein-coding genes from an organism."
  },
  {
    "objectID": "creategenelist.html#organism",
    "href": "creategenelist.html#organism",
    "title": "Create Gene list",
    "section": "2.1 Organism",
    "text": "2.1 Organism\nSpecification of the organism for which a gene list should be created (default: first file in \\conf\\perseus\\genelists). The organisms or the corresponding text files that should be uploaded can be selected from all files, which are located in \\conf\\perseus\\genelists in your Perseus folder."
  },
  {
    "objectID": "creategenelist.html#parameter-window",
    "href": "creategenelist.html#parameter-window",
    "title": "Create Gene list",
    "section": "2.2 Parameter window",
    "text": "2.2 Parameter window\n\n\n\nCreate Gene list windows"
  },
  {
    "objectID": "createrandommatrix.html",
    "href": "createrandommatrix.html",
    "title": "Create randome matrix",
    "section": "",
    "text": "Type: - Matrix Upload\nSource code: CreateRandomMatrix.cs"
  },
  {
    "objectID": "createrandommatrix.html#number-of-rows",
    "href": "createrandommatrix.html#number-of-rows",
    "title": "Create randome matrix",
    "section": "3.1 Number of rows",
    "text": "3.1 Number of rows\nSpecifies the number of rows the randomly created matrix should have (default: 100). Rows are called “Row 1”, Row 2”, etc."
  },
  {
    "objectID": "createrandommatrix.html#number-of-columns",
    "href": "createrandommatrix.html#number-of-columns",
    "title": "Create randome matrix",
    "section": "3.2 Number of columns",
    "text": "3.2 Number of columns\nSpecifies the number of columns the randomly created matrix should have (default: 10). Columns are called “Column 1”, “Column 2”, etc."
  },
  {
    "objectID": "createrandommatrix.html#percentage-of-missing-values",
    "href": "createrandommatrix.html#percentage-of-missing-values",
    "title": "Create randome matrix",
    "section": "3.3 Percentage of missing values",
    "text": "3.3 Percentage of missing values\nSpecifies the percentage of missing values the created matrix should contain (default: 0)."
  },
  {
    "objectID": "createrandommatrix.html#mode",
    "href": "createrandommatrix.html#mode",
    "title": "Create randome matrix",
    "section": "3.4 Mode",
    "text": "3.4 Mode\nDefines how many normal distributions should be included in the matrix (default: One normal distribution). The number of normal distributions can be specified from a predefined list:\n\nOne normal distribution (parameter window A)\nTwo normal distributions (parameter window B)\nMany normal distributions (parameter window C)\n\n\n3.4.1 Distance\nThis parameter is just relevant, if the parameter “Mode” is set to “Two normal distributions”. It defines the distance between the two generated normal distributions (default: 2).\n\n\n3.4.2 How many\nThis parameter is just relevant, if the parameter “Mode” is set to “Many normal distributions”. It defines how many normal distributions should be in the generated matrix (default: 3).\n\n\n3.4.3 Box size\nThis parameter is just relevant, if the parameter “Mode” is set to “Many normal distributions”. It specifies the edge length of the hyper cubes in which the centers of the normal distributions are placed at random (default: 2)."
  },
  {
    "objectID": "createrandommatrix.html#parameter-window",
    "href": "createrandommatrix.html#parameter-window",
    "title": "Create randome matrix",
    "section": "3.5 Parameter window",
    "text": "3.5 Parameter window\n\n\n\nCreate random matrix"
  },
  {
    "objectID": "processtextcolumns.html",
    "href": "processtextcolumns.html",
    "title": "Process text column",
    "section": "",
    "text": "===== General =====\n===== Brief description =====\nValues in string columns can be manipulated according to a regular expression."
  },
  {
    "objectID": "processtextcolumns.html#columns",
    "href": "processtextcolumns.html#columns",
    "title": "Process text column",
    "section": "1.1 Columns",
    "text": "1.1 Columns\nSelected text columns, whose values should be manipulated by the defined regular expression (default: no columns are selected)."
  },
  {
    "objectID": "processtextcolumns.html#regular-expression",
    "href": "processtextcolumns.html#regular-expression",
    "title": "Process text column",
    "section": "1.2 Regular expression",
    "text": "1.2 Regular expression\nSpecified regular expression that is applied to the selected text columns (default: “^([^;]+)”).\nA regular expression is a sequence of characters that forms a search pattern with a special syntax. A good general introduction can be found, as always, on Wikipedia. If you already know generally how regular expressions work, you may only need to glance at the quick reference or at an even quicker one.\nHere are a few examples:\n\n\n\n\n\n\n\nRegular expression\nEffect\n\n\n\n\n^([^;]+)\nSelect all the characters from the beginning of the line, up to but not including the first semicolon. This is the default.\n\n\nTAG = ([^,; ]*)\nLook for the first instance of “TAG =”, with any amount of whitespace (or none) around the equal sign, and return what follows after the whitespace until a comma or semicolon is reached.\n\n\n([ACTG]+)\nreturn the first string consisting only of the letters A, C, T, and G.\n\n\n(20[01][0-9]-[01][0-9]-[0-3][0-9])\nSelect a date between 2000 and 2019 of the form 2014-08-19."
  },
  {
    "objectID": "processtextcolumns.html#replacement-string",
    "href": "processtextcolumns.html#replacement-string",
    "title": "Process text column",
    "section": "1.3 Replacement string",
    "text": "1.3 Replacement string\nYou can provide a replacement string here for more flexibility. Leave empty if unsure.\nExamples:\n\n\n\n\n\n\n\nRegular expression\nEffect\n\n\n\n\n$1\nReplace the original string with the first capture group, i.e. the part of the original string inside the first parentheses ’‘(..)’’."
  },
  {
    "objectID": "processtextcolumns.html#keep-original-columns",
    "href": "processtextcolumns.html#keep-original-columns",
    "title": "Process text column",
    "section": "1.4 Keep original columns",
    "text": "1.4 Keep original columns\nIf checked, the original columns are retained unchanged, and new columns are appended to hold the results (default: unchecked). The name of a new column is created by appending underscores to the name of the original column until it is unique. If this box is not checked, then the strings in the original columns are overwritten by the results."
  },
  {
    "objectID": "processtextcolumns.html#strings-separated-by-semicolons-are-independent",
    "href": "processtextcolumns.html#strings-separated-by-semicolons-are-independent",
    "title": "Process text column",
    "section": "1.5 Strings separated by semicolons are independent",
    "text": "1.5 Strings separated by semicolons are independent\nIf checked, each string is split into substrings at the semicolons, and the regular expression is applied independently to each substring (default: unchecked). The results are separated by semicolons and concatenated into a single string, which is returned. This is useful for columns where any row may contain multiple entries. If not checked, the string is evaluated as a whole and the only first match returned."
  },
  {
    "objectID": "searchtextcolumns.html",
    "href": "searchtextcolumns.html",
    "title": "Search text column",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Rearrange\nSource code: SearchTextColumns.cs"
  },
  {
    "objectID": "searchtextcolumns.html#find-what",
    "href": "searchtextcolumns.html#find-what",
    "title": "Search text column",
    "section": "3.1 Find what",
    "text": "3.1 Find what\nSpecified text/term that is searched in a selected text column (default: empty)."
  },
  {
    "objectID": "searchtextcolumns.html#look-in",
    "href": "searchtextcolumns.html#look-in",
    "title": "Search text column",
    "section": "3.2 Look in",
    "text": "3.2 Look in\nSelected text column that should be searched for the specified term (default: first text column of the matrix)."
  },
  {
    "objectID": "searchtextcolumns.html#match-case",
    "href": "searchtextcolumns.html#match-case",
    "title": "Search text column",
    "section": "3.3 Match case",
    "text": "3.3 Match case\nThe cells of the text column will be searched for a matching substring (default: checked). The results will be in a new generated categorical column called “Search: original column name”. “+” indicates, whether a match was successful."
  },
  {
    "objectID": "searchtextcolumns.html#match-whole-word",
    "href": "searchtextcolumns.html#match-whole-word",
    "title": "Search text column",
    "section": "3.4 Match whole word",
    "text": "3.4 Match whole word\nThe cells of the text column will be searched to match the whole word of the specified term (default: unchecked). The results will be in a new generated categorical column called “Search: original column name”. “+” indicates, whether a match was successful."
  },
  {
    "objectID": "perseus_instructions.html",
    "href": "perseus_instructions.html",
    "title": "Perseus",
    "section": "",
    "text": "The Perseus software platform supports biological and biomedical researchers in interpreting protein quantification, interaction and post-translational modification data. Perseus contains a comprehensive portfolio of statistical tools for high-dimensional omics data analysis covering normalization, pattern recognition, time-series analysis, cross-omics comparisons and multiple-hypothesis testing (for an overview see Figure 1). A machine learning module supports the classification and validation of patient groups for diagnosis and prognosis, and it also detects predictive protein signatures. Central to Perseus is a user-friendly, interactive workflow environment that provides complete documentation of computational methods used in a publication(Tyanova, Temu, and Cox 2016)."
  },
  {
    "objectID": "perseus_instructions.html#report-a-bug",
    "href": "perseus_instructions.html#report-a-bug",
    "title": "Perseus",
    "section": "4.1 Report a bug",
    "text": "4.1 Report a bug\nFor question we would love to hear from you under Contact"
  },
  {
    "objectID": "combineexpressioncolumns.html",
    "href": "combineexpressioncolumns.html",
    "title": "Combine Expression Columns",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Basic (Processing)\nSource code: not public."
  },
  {
    "objectID": "combineexpressioncolumns.html#operation",
    "href": "combineexpressioncolumns.html#operation",
    "title": "Combine Expression Columns",
    "section": "3.1 Operation",
    "text": "3.1 Operation\nSpecifies the operation (default: \\(x-y\\)), how a pair of columns should be combined into a single column. Numbers with \\(.\\) as decimal point, \\(+\\), \\(-\\), \\(*\\), \\(/\\) and ^ as well as scientific notation (e.g. \\(5.4e{-12}\\)) can be used. A set of predefined functions are also available, whose argument has to be enclosed by round brackets, e.g. \\(sin(2*x-y)\\)."
  },
  {
    "objectID": "combineexpressioncolumns.html#x",
    "href": "combineexpressioncolumns.html#x",
    "title": "Combine Expression Columns",
    "section": "3.2 x",
    "text": "3.2 x\nSelected expression columns that are the first partners of pairs of columns (default: no expression columns are selected). The number of selected columns in the “x” and “y” field must be the same."
  },
  {
    "objectID": "combineexpressioncolumns.html#y",
    "href": "combineexpressioncolumns.html#y",
    "title": "Combine Expression Columns",
    "section": "3.3 y",
    "text": "3.3 y\nSelected expression columns that are the second partners of pairs of columns (default: no expression columns are selected). The number of selected columns in the “x” and “y” field must be the same."
  },
  {
    "objectID": "combineexpressioncolumns.html#keep-original-columns",
    "href": "combineexpressioncolumns.html#keep-original-columns",
    "title": "Combine Expression Columns",
    "section": "3.4 Keep original columns",
    "text": "3.4 Keep original columns\nIf checked the original columns will be retained in the output matrix (default: checked)."
  },
  {
    "objectID": "viewer_gettingStarted.html",
    "href": "viewer_gettingStarted.html",
    "title": "Viewer - Getting started",
    "section": "",
    "text": "The Viewer module can either be used to get some prior information out of loaded raw files or to find some follow up hypotheses after raw files have already been processed.\n\n1 Raw files prior processing\nTo view MS spectra of raw files, load the files using the Load (to load single files) or Load folder (to load a whole folder) options.\n\n\n\nFigure 1: Load raw files\n\n\n\n\n2 Raw files post processing with MaxQuant\nFile organization is important for the correct display of annotated spectra. Raw files should be in the same folder as all index files, the mqpar.xml file and all output folders created by MaxQuant during the processing (that includes the combined folder). The easiest way to load the entire data is to load the mqpar.xml file. Make sure that the file paths are correct if using this option.\n\n\n\nFigure 2: Load mqpar.xml"
  },
  {
    "objectID": "andromeda_tutorial.html",
    "href": "andromeda_tutorial.html",
    "title": "Andromeda Tutorial",
    "section": "",
    "text": "Tutorials explaining how to use the Andromeda search tool can be found in our YouTube channel.\nA few examples are listed below:\nConfiguration of the Andromeda search engine\nFrom our online MaxQunat Summer in 2021\n\nAndromeda search engine\nFrom our 2018 MaxQunat Summer in Madison\n\nTutorial - Configuration of the Andromeda search engine\nFrom our 2018 MaxQunat Summer in Barcelona"
  },
  {
    "objectID": "maxquant_instructions.html",
    "href": "maxquant_instructions.html",
    "title": "MaxQuant",
    "section": "",
    "text": "MaxQuant is a proteomics software package designed for analyzing large mass-spectrometric data sets. It is specifically aimed at high-resolution MS data. Several labeling techniques as well as label-free quantification are supported. MaxQuant is freely available and can be downloaded from this site. The download includes the search engine Andromeda, which is integrated into MaxQuant as well as the viewer application for inspection of raw data and identification and quantification results. For statistical analysis of MaxQuant output, we offer the Perseus framework.\n\n1 Documentation outline\n\nDownload and installation\nFirst steps in MaxQuant\nViewer\nAndromeda\nOutput Tables\nGoogle groups\nmaxquant Bug reporting\nGlossary\n\nFor additional training, consider attending the annual MaxQuant Summer School. Also watching some MaxQuant videos provides more insight.\n\nFor question we would love to hear from you under Contact\n\n\n2 Bibliography\nFor a deep-dive into the technique and progress behind MaxQuant, many papers of varying degrees of details were published over the last decades. For further reading, you can look at a small list of the more important corner stones of the MaxQuant development history.1 (Note that the paper has a large supplement containing in-depth descriptions of algorithms),2,3,4,5,6 (Note that this paper explains how to run MaxQuant in detail.),7\n\n\n\n\n\nReferences\n\n1. Cox, J. & Mann, M. MaxQuant enables high peptide identification rates, individualized p.p.b.-range mass accuracies and proteome-wide protein quantification. Nature Biotechnology 26, 1367–1372 (2008).\n\n\n2. Cox, J., Michalski, A. & Mann, M. Software Lock Mass by Two-Dimensional Minimization of Peptide Mass Errors. Journal of the American Society for Mass Spectrometry 22, 1373–1380 (2011).\n\n\n3. Schaab, C., Geiger, T., Stoehr, G., Cox, J. & Mann, M. Analysis of High Accuracy, Quantitative Proteomics Data in the MaxQB Database. Molecular & Cellular Proteomics 11, M111.014068 (2012).\n\n\n4. Cox, J. et al. Accurate Proteome-wide Label-free Quantification by Delayed Normalization and Maximal Peptide Ratio Extraction, Termed MaxLFQ. Molecular & Cellular Proteomics 13, 2513–2526 (2014).\n\n\n5. Tyanova, S. et al. Visualization of LC-MS/MS proteomics data in MaxQuant. PROTEOMICS 15, 1453–1456 (2015).\n\n\n6. Tyanova, S., Temu, T. & Cox, J. The MaxQuant computational platform for mass spectrometry-based shotgun proteomics. Nature Protocols 11, 2301–2319 (2016).\n\n\n7. Sinitcyn, P. et al. MaxQuant goes Linux. Nature Methods 15, 401–401 (2018)."
  },
  {
    "objectID": "zscore.html",
    "href": "zscore.html",
    "title": "Z Score",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: ZScore.cs"
  },
  {
    "objectID": "zscore.html#matrix-access",
    "href": "zscore.html#matrix-access",
    "title": "Z Score",
    "section": "3.1 Matrix access",
    "text": "3.1 Matrix access\nSpecifies whether the z-scoring is performed on rows or columns (default: Rows).\n\n3.1.1 Grouping\nThis parameter is just relevant, if the “Matrix access” is set to “Rows”. It specifies, whether the normalization should be applied separately on groups (default: )."
  },
  {
    "objectID": "zscore.html#use-median",
    "href": "zscore.html#use-median",
    "title": "Z Score",
    "section": "3.2 Use median",
    "text": "3.2 Use median\nIf checked, the median and not the mean of each row/column is used for the calculation of the z-score of each matrix cell (default: unchecked)."
  },
  {
    "objectID": "zscore.html#report-mean-and-std.-dev.",
    "href": "zscore.html#report-mean-and-std.-dev.",
    "title": "Z Score",
    "section": "3.3 Report mean and std. dev.",
    "text": "3.3 Report mean and std. dev.\nIf checked, the mean and the standard deviation used for the calculation are reported (default: unchecked). In case the z-scoring is based on rows (“Matrix access” = “Rows”), the calculated mean and standard deviation appear in 2 newly generated numeric columns called “Mean” and “Std. dev.” containing the mean and standard deviation of each row. In case the calculation is based on columns (“Matrix access” = “Columns”), 2 new numeric rows are generated containing the mean and standard deviation of each column."
  },
  {
    "objectID": "rank.html",
    "href": "rank.html",
    "title": "Rank",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: Rank.cs"
  },
  {
    "objectID": "rank.html#matrix-access",
    "href": "rank.html#matrix-access",
    "title": "Rank",
    "section": "3.1 Matrix access",
    "text": "3.1 Matrix access\nDefines whether the values in expression columns or rows should be ranked (default: Rows)."
  },
  {
    "objectID": "unitvector.html",
    "href": "unitvector.html",
    "title": "Unit Vector",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: UnitVector.cs"
  },
  {
    "objectID": "unitvector.html#matrix-access",
    "href": "unitvector.html#matrix-access",
    "title": "Unit Vector",
    "section": "3.1 Matrix access",
    "text": "3.1 Matrix access\nSpecifies whether rows or columns should be regarded as high-dimensional vectors and be transformed into unit vectors (default: Rows)."
  },
  {
    "objectID": "scaletointerval.html",
    "href": "scaletointerval.html",
    "title": "Scale to interval",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: ScaleToInterval.cs"
  },
  {
    "objectID": "scaletointerval.html#matrix-access",
    "href": "scaletointerval.html#matrix-access",
    "title": "Scale to interval",
    "section": "3.1 Matrix access",
    "text": "3.1 Matrix access\nDefines if rows or columns should be scaled to an interval (default: Rows). The lowest value of each column/row results in the value determined at the “Minimum” parameter and the largest value of the row/column is the value determined at the “Maximum” parameter."
  },
  {
    "objectID": "scaletointerval.html#minimum",
    "href": "scaletointerval.html#minimum",
    "title": "Scale to interval",
    "section": "3.2 Minimum",
    "text": "3.2 Minimum\nDefines the lower bound of the interval all the values within a row/column will be scaled to (default: 0)."
  },
  {
    "objectID": "scaletointerval.html#maximum",
    "href": "scaletointerval.html#maximum",
    "title": "Scale to interval",
    "section": "3.3 Maximum",
    "text": "3.3 Maximum\nDefines the upper bound of the interval all the values within a row/column will be scaled to (default: 1)."
  },
  {
    "objectID": "widthadjustment.html",
    "href": "widthadjustment.html",
    "title": "Width adjustment",
    "section": "",
    "text": "1 General\n\nType: - Matrix Processing\nHeading: - Normalization\nSource code: WidthAdjustment.cs\n\n\n\n2 Brief description\nThe first, second and third quartiles (\\(q1\\), \\(q2\\), \\(q3\\)) are calculated from the distribution of all values. The second quartile (which is the median) is subtracted from each value to center the distribution. Then we divide by the width in an asymmetric way. All values that are positive after subtraction of the median are divided by \\(q3 - q2\\) while all negative values are divided by \\(q2 - q1\\).\n\n\n\n3 Parameters\n“Width adjustment” has no parameters."
  },
  {
    "objectID": "subtract.html",
    "href": "subtract.html",
    "title": "Subtract",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: Subtract.cs"
  },
  {
    "objectID": "subtract.html#matrix-access",
    "href": "subtract.html#matrix-access",
    "title": "Subtract",
    "section": "3.1 Matrix access",
    "text": "3.1 Matrix access\nSpecifies whether the subtraction is performed on rows or columns (default: Rows). If the subtraction is performed on rows, the “Grouping” can be specified as well (default: ).\n\n3.1.1 Grouping\nThis parameter is just relevant, if the “Matrix access” is set to “Rows”. It specifies, whether the normalization should be applied separately on groups (default: )."
  },
  {
    "objectID": "subtract.html#subtract-what",
    "href": "subtract.html#subtract-what",
    "title": "Subtract",
    "section": "3.2 Subtract what",
    "text": "3.2 Subtract what\nDefines what value should be subtracted from all entries in expression columns (default: Median). The subtrahend can be selected from a predefined list:\n\nMean\nMedian\nMost frequent value\nTukey’s biweight"
  },
  {
    "objectID": "divide.html",
    "href": "divide.html",
    "title": "Divide",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: Divide.cs"
  },
  {
    "objectID": "divide.html#matrix-access",
    "href": "divide.html#matrix-access",
    "title": "Divide",
    "section": "3.1 Matrix access",
    "text": "3.1 Matrix access\nSpecifies whether the division is performed on rows or columns (default: Rows)."
  },
  {
    "objectID": "divide.html#divide-by-what",
    "href": "divide.html#divide-by-what",
    "title": "Divide",
    "section": "3.2 Divide by what",
    "text": "3.2 Divide by what\nDefines by what value all entries in expression columns should be divided (default: Median). The divisor can be selected from a predefined list:\n\nSum\nMean\nMedian\nMost frequent value\nTukey’s biweight"
  },
  {
    "objectID": "normalizebycolumn.html",
    "href": "normalizebycolumn.html",
    "title": "Modify by column",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: not public."
  },
  {
    "objectID": "normalizebycolumn.html#columns",
    "href": "normalizebycolumn.html#columns",
    "title": "Modify by column",
    "section": "3.1 Columns",
    "text": "3.1 Columns\nSelected expression/numerical column(s) that should be modified by the values of the “Control column” using the the action specified in “Modify by” (default: all expression columns are selected)."
  },
  {
    "objectID": "normalizebycolumn.html#control-column",
    "href": "normalizebycolumn.html#control-column",
    "title": "Modify by column",
    "section": "3.2 Control column",
    "text": "3.2 Control column\nOne expression/numerical column that is used to modify all selected expression/numerical columns in the field “Columns” using the action specified in “Modify by” (default: first expression column in the matrix)."
  },
  {
    "objectID": "normalizebycolumn.html#modify-by",
    "href": "normalizebycolumn.html#modify-by",
    "title": "Modify by column",
    "section": "3.3 Modify by",
    "text": "3.3 Modify by\nDefines the operation that is applied between the selected “Columns” and the “Control column” (default: Subtraction). The operation can be chosen from a predefined list of operations:\n\nAddition\nMultiplication\nSubtraction\nDivision"
  },
  {
    "objectID": "subtractrowcluster.html",
    "href": "subtractrowcluster.html",
    "title": "Subtract row cluster",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: SubtractRowCluster.cs"
  },
  {
    "objectID": "subtractrowcluster.html#indicator-column",
    "href": "subtractrowcluster.html#indicator-column",
    "title": "Subtract row cluster",
    "section": "3.1 Indicator column",
    "text": "3.1 Indicator column\nSelected categorical column that should be used for filtering the rows that should be used to calculate the subtrahend for the normalization (default: first categorical column in the matrix)."
  },
  {
    "objectID": "subtractrowcluster.html#value",
    "href": "subtractrowcluster.html#value",
    "title": "Subtract row cluster",
    "section": "3.2 Value",
    "text": "3.2 Value\nSpecifies the value/text term that will be searched in the previously defined “Indicator column” (default: +). The average of rows containing the value/text term is subtracted from all other rows."
  },
  {
    "objectID": "unzscore.html",
    "href": "unzscore.html",
    "title": "Un Z-Score",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Normalization\nSource code: UnZScore.cs"
  },
  {
    "objectID": "unzscore.html#matrix-access",
    "href": "unzscore.html#matrix-access",
    "title": "Un Z-Score",
    "section": "3.1 Matrix access",
    "text": "3.1 Matrix access\nSpecifies whether the un-z-scoring is performed on the rows or columns (default: Rows). The selection depends on what was used before in the normalization process."
  },
  {
    "objectID": "unzscore.html#mean",
    "href": "unzscore.html#mean",
    "title": "Un Z-Score",
    "section": "3.2 Mean",
    "text": "3.2 Mean\nSelected numerical row/column containing the mean values that were used for the z-scoring (default: column called “Mean” or first numerical column in the matrix)."
  },
  {
    "objectID": "unzscore.html#std.-dev.",
    "href": "unzscore.html#std.-dev.",
    "title": "Un Z-Score",
    "section": "3.3 Std. dev.",
    "text": "3.3 Std. dev.\nSelected numerical row/column containing the standard deviation values that were used for the z-scoring (default: column called “Std.dev.” or first numerical column in the matrix)."
  },
  {
    "objectID": "filtercategoricalcolumn.html",
    "href": "filtercategoricalcolumn.html",
    "title": "Filter rows based on categorical column",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Filter rows\nSource code: FilterCategoricalColumn.cs"
  },
  {
    "objectID": "filtercategoricalcolumn.html#column",
    "href": "filtercategoricalcolumn.html#column",
    "title": "Filter rows based on categorical column",
    "section": "3.1 Column",
    "text": "3.1 Column\nSelected categorical column the filtering is based on (default: first categorical column of the matrix)."
  },
  {
    "objectID": "filtercategoricalcolumn.html#values",
    "href": "filtercategoricalcolumn.html#values",
    "title": "Filter rows based on categorical column",
    "section": "3.2 Values",
    "text": "3.2 Values\nRows with the containing values will be kept/discarded depending on the selected “Mode” (default: no values are selected)."
  },
  {
    "objectID": "filtercategoricalcolumn.html#mode",
    "href": "filtercategoricalcolumn.html#mode",
    "title": "Filter rows based on categorical column",
    "section": "3.3 Mode",
    "text": "3.3 Mode\nThe rows with the selected values will be kept/discarded depending on the selected “Mode” (default: “Remove matching rows”). If “Remove matching rows” is selected, rows having the values will be removed while all other rows will be kept. If “Keep matching rows” is selected, the opposite will happen."
  },
  {
    "objectID": "filtercategoricalcolumn.html#filter-mode",
    "href": "filtercategoricalcolumn.html#filter-mode",
    "title": "Filter rows based on categorical column",
    "section": "3.4 Filter mode",
    "text": "3.4 Filter mode\nThe “Filter mode” defines, whether the input matrix will be reduced (“Reduce matrix” = default) or a new categorical column called “Filter” will be generated containing the categories “Keep” and “Discard” (“Filter mode” = “Add categorical column”)."
  },
  {
    "objectID": "filternumericalcolumn.html",
    "href": "filternumericalcolumn.html",
    "title": "Filter rows based on numerical/expression column",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Filter rows\nSource code: FilterNumericalColumn.cs"
  },
  {
    "objectID": "filternumericalcolumn.html#number-of-columns",
    "href": "filternumericalcolumn.html#number-of-columns",
    "title": "Filter rows based on numerical/expression column",
    "section": "3.1 Number of columns",
    "text": "3.1 Number of columns\nThe filtering is based on relations of expression/numerical columns. Up to five columns (default: 1) can be selected. Depending on the number of chosen columns drop down box(es) appear on the pop-up window named “x”, “y”, “z”, “a” and “b”. In these drop down boxes expression/numerical columns can be specified, which can then be used in the relations that should be applied for filtering the matrix."
  },
  {
    "objectID": "filternumericalcolumn.html#number-of-relations",
    "href": "filternumericalcolumn.html#number-of-relations",
    "title": "Filter rows based on numerical/expression column",
    "section": "3.2 Number of relations",
    "text": "3.2 Number of relations\nUp to five relations using the previously specified columns can be included in the filtering process (default:1). Depending on the selected number of relations text fields on the pop-up window appear named “Relation 1”, “Relation 2”, “Relation 3”, “Relation 4” and “Relation 5”.\nIn each text field a relation for the filtering process can be defined using the variables of the parameter “Number of columns”. For the relations numbers with “.” as decimal point, “+”, “-”, “*”, “/” and “^” as well as scientific notation (e.g. “5.4e-12”) can be used."
  },
  {
    "objectID": "filternumericalcolumn.html#combine-through",
    "href": "filternumericalcolumn.html#combine-through",
    "title": "Filter rows based on numerical/expression column",
    "section": "3.3 Combine through",
    "text": "3.3 Combine through\nDefines how the specified relations are combined (default: intersection). Depending on the specified combination mode either rows, which fulfill the “intersection” (default) of the relations are kept or the ones fulfilling the “union”."
  },
  {
    "objectID": "filternumericalcolumn.html#filter-mode",
    "href": "filternumericalcolumn.html#filter-mode",
    "title": "Filter rows based on numerical/expression column",
    "section": "3.4 Filter mode",
    "text": "3.4 Filter mode\nThe “Filter mode” defines, whether the input matrix will be reduced (“Reduce matrix” = default) or a new categorical column called “Filter” will be generated containing the categories “Keep” and “Discard” (“Filter mode” = “Add categorical column”)."
  },
  {
    "objectID": "filtertextualcolumn.html",
    "href": "filtertextualcolumn.html",
    "title": "Filter rows based on text column",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Filter rows\nSource code: FilterTextualColumn.cs"
  },
  {
    "objectID": "filtertextualcolumn.html#column",
    "href": "filtertextualcolumn.html#column",
    "title": "Filter rows based on text column",
    "section": "3.1 Column",
    "text": "3.1 Column\nSelected text column the filtering is based on (default: first text column in the matrix)."
  },
  {
    "objectID": "filtertextualcolumn.html#search-string",
    "href": "filtertextualcolumn.html#search-string",
    "title": "Filter rows based on text column",
    "section": "3.2 Search string",
    "text": "3.2 Search string\nSpecified text string that should be searched in the previously defined text column (default: empty)."
  },
  {
    "objectID": "filtertextualcolumn.html#match-case",
    "href": "filtertextualcolumn.html#match-case",
    "title": "Filter rows based on text column",
    "section": "3.3 Match case",
    "text": "3.3 Match case\nIf checked, the cells of the text column will be searched for a matching substring (default: unchecked). The results will be in a new generated categorical column called “Search: original column name”. “+” indicates, whether a match was successful."
  },
  {
    "objectID": "filtertextualcolumn.html#match-whole-word",
    "href": "filtertextualcolumn.html#match-whole-word",
    "title": "Filter rows based on text column",
    "section": "3.4 Match whole word",
    "text": "3.4 Match whole word\nIf checked, the text column will be searched to match the whole word of the specified term (default: checked). The results will be in a new generated categorical column called “Search: original column name”. “+” indicates, whether a match was successful."
  },
  {
    "objectID": "filtertextualcolumn.html#mode",
    "href": "filtertextualcolumn.html#mode",
    "title": "Filter rows based on text column",
    "section": "3.5 Mode",
    "text": "3.5 Mode\nThe rows with the selected values will be kept/discarded depending on the selected “Mode” (default: “Remove matching rows”). If “Remove matching rows” is selected, rows having the values will be removed while all other rows will be kept. If “Keep matching rows” is selected, the opposite will happen."
  },
  {
    "objectID": "filtertextualcolumn.html#filter-mode",
    "href": "filtertextualcolumn.html#filter-mode",
    "title": "Filter rows based on text column",
    "section": "3.6 Filter mode",
    "text": "3.6 Filter mode\nThe “Filter mode” defines, whether the input matrix will be reduced (“Reduce matrix” = default) or a new categorical column called “Filter” will be generated containing the categories “Keep” and “Discard” (“Filter mode” = “Add categorical column”)."
  },
  {
    "objectID": "filtervalidvaluesrows.html",
    "href": "filtervalidvaluesrows.html",
    "title": "Filter rows based on valid values",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Filter rows\nSource code: FilterValidValuesRows.cs"
  },
  {
    "objectID": "filtervalidvaluesrows.html#min.-number-of-values",
    "href": "filtervalidvaluesrows.html#min.-number-of-values",
    "title": "Filter rows based on valid values",
    "section": "3.1 Min. number of values",
    "text": "3.1 Min. number of values\nDefines the minimal number of valid values each row needs to have in the expression columns to survive the filtering process (default: 3)."
  },
  {
    "objectID": "filtervalidvaluesrows.html#mode-seq-mode",
    "href": "filtervalidvaluesrows.html#mode-seq-mode",
    "title": "Filter rows based on valid values",
    "section": "3.2 Mode {seq-mode}",
    "text": "3.2 Mode {seq-mode}\nDefines, which expression columns are counted to define, if a row has enough valid values to survive the filtering process (default: In total). There are three options available:\n\nIn total (includes all expression columns)\nIn each group\nIn at least one group\n\n\n3.2.1 Grouping\nThis parameter is just relevant, if (seq-mode?) is set to “In each group” or “In at least one group”. It defines the grouping of the expression columns that should be used by selecting a categorical row (default: first categorical row of the matrix)."
  },
  {
    "objectID": "filtervalidvaluesrows.html#values-should-be",
    "href": "filtervalidvaluesrows.html#values-should-be",
    "title": "Filter rows based on valid values",
    "section": "3.3 Values should be",
    "text": "3.3 Values should be\nDefines the restriction for a value to be classified as valid (default: Valid). There are seven different possibilities to specify, which entry is counted as a valid value (default: Valid):\n\nValid\nGreater than\nGreater or equal\nLess than\nLess or equal\nBetween\nOutside\n\n\n3.3.1 Minimum\nThis parameter is just relevant, if “Values should be” is set to “Greater than”, “Greater or equal”, “Between” or “Outside”. It defines a lower bound to apply the operation specified in “Values should be” (default: 0).\n\n\n3.3.2 Maximum\nThis parameter is just relevant, if “Values should be” is set to “Less than”, “Less or equal”, “Between” or “Outside”. It defines a upper bound to apply the operation specified in “Values should be” (default: 0)."
  },
  {
    "objectID": "filtervalidvaluesrows.html#filter-mode",
    "href": "filtervalidvaluesrows.html#filter-mode",
    "title": "Filter rows based on valid values",
    "section": "3.4 Filter mode",
    "text": "3.4 Filter mode\nThe “Filter mode” defines, whether the input matrix will be reduced (“Reduce matrix” = default) or a new categorical column called “Filter” will be generated containing the categories “Keep” and “Discard” (“Filter mode” = “Add categorical column”)."
  },
  {
    "objectID": "filtervalidvaluesrows.html#seq-mode",
    "href": "filtervalidvaluesrows.html#seq-mode",
    "title": "Filter rows based on valid values",
    "section": "3.2 Mode",
    "text": "3.2 Mode\nDefines, which expression columns are counted to define, if a row has enough valid values to survive the filtering process (default: In total). There are three options available:\n\nIn total (includes all expression columns)\nIn each group\nIn at least one group\n\n\n3.2.1 Grouping\nThis parameter is just relevant, if (seq-mode?) is set to “In each group” or “In at least one group”. It defines the grouping of the expression columns that should be used by selecting a categorical row (default: first categorical row of the matrix)."
  },
  {
    "objectID": "filtervalidvaluesrows.html#sec-mode",
    "href": "filtervalidvaluesrows.html#sec-mode",
    "title": "Filter rows based on valid values",
    "section": "3.2 Mode",
    "text": "3.2 Mode\nDefines, which expression columns are counted to define, if a row has enough valid values to survive the filtering process (default: In total). There are three options available:\n\nIn total (includes all expression columns)\nIn each group\nIn at least one group\n\n\n3.2.1 Grouping\nThis parameter is just relevant, if Mode (Section 3.2) is set to “In each group” or “In at least one group”. It defines the grouping of the expression columns that should be used by selecting a categorical row (default: first categorical row of the matrix)."
  },
  {
    "objectID": "filterrandomrows.html",
    "href": "filterrandomrows.html",
    "title": "Filter rows based on random sampling",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Filter rows\nSource code: FilterRandomRows.cs"
  },
  {
    "objectID": "filterrandomrows.html#number-of-rows",
    "href": "filterrandomrows.html#number-of-rows",
    "title": "Filter rows based on random sampling",
    "section": "3.1 Number of rows",
    "text": "3.1 Number of rows\nThe filtering is based on random decisions, where a given number of rows is kept (default: total number of rows in the matrix)."
  },
  {
    "objectID": "filterrandomrows.html#filter-mode",
    "href": "filterrandomrows.html#filter-mode",
    "title": "Filter rows based on random sampling",
    "section": "3.2 Filter mode",
    "text": "3.2 Filter mode\nThe “Filter mode” defines, whether the input matrix will be reduced (“Reduce matrix” = default) or a new categorical column called “Filter” will be generated containing the categories “Keep” and “Discard” (“Filter mode” = “Add categorical column”)."
  },
  {
    "objectID": "filtercategoricalrow.html",
    "href": "filtercategoricalrow.html",
    "title": "Filter columns based on categorical row",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Filter columns\nSource code: FilterCategoricalRow.cs"
  },
  {
    "objectID": "filtercategoricalrow.html#row",
    "href": "filtercategoricalrow.html#row",
    "title": "Filter columns based on categorical row",
    "section": "3.1 Row",
    "text": "3.1 Row\nSelected categorical row the filtering is based on (default: first categorical row in the matrix).\n\n3.1.1 Values\nSelected values out of all values of the specified categorical row that should be present to keep/discard the column (default: no values are selected)."
  },
  {
    "objectID": "filtercategoricalrow.html#mode",
    "href": "filtercategoricalrow.html#mode",
    "title": "Filter columns based on categorical row",
    "section": "3.2 Mode",
    "text": "3.2 Mode\nThe columns with the selected values will be kept/discarded depending on the selected “Mode” (default: “Remove matching columns”). If “Remove matching columns” is selected, rows having the values will be removed while all other columns will be kept. If “Keep matching columns” is selected, the opposite will happen."
  },
  {
    "objectID": "filtercategoricalrow.html#filter-mode",
    "href": "filtercategoricalrow.html#filter-mode",
    "title": "Filter columns based on categorical row",
    "section": "3.3 Filter mode",
    "text": "3.3 Filter mode\nThe “Filter mode” defines, whether the input matrix will be reduced (“Reduce matrix” = default) or a new categorical row called “Filter” will be generated containing the categories “Keep” and “Discard” (“Filter mode” = “Add categorical row”)."
  },
  {
    "objectID": "filtervalidvaluescolumns.html",
    "href": "filtervalidvaluescolumns.html",
    "title": "Filter columns based on valid values",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Filter columns\nSource code: FilterValidValuesColumns.cs"
  },
  {
    "objectID": "filtervalidvaluescolumns.html#min.-number-of-values",
    "href": "filtervalidvaluescolumns.html#min.-number-of-values",
    "title": "Filter columns based on valid values",
    "section": "3.1 Min. number of values",
    "text": "3.1 Min. number of values\nSpecifies minimal number of valid values each expression column needs to contain to survive the filtering process (default: 3)."
  },
  {
    "objectID": "filtervalidvaluescolumns.html#mode",
    "href": "filtervalidvaluescolumns.html#mode",
    "title": "Filter columns based on valid values",
    "section": "3.2 Mode",
    "text": "3.2 Mode\nDefines, which expression columns are counted to define, if a row has enough valid values to survive the filtering process (default: In total)."
  },
  {
    "objectID": "filtervalidvaluescolumns.html#values-should-be",
    "href": "filtervalidvaluescolumns.html#values-should-be",
    "title": "Filter columns based on valid values",
    "section": "3.3 Values should be",
    "text": "3.3 Values should be\nDefines the restriction for a value to be classified as valid (default: Valid). There are seven different possibilities to specify, which entry is counted as a valid value (default: Valid):\n\nValid\nGreater than\nGreater or equal\nLess than\nLess or equal\nBetween\nOutside\n\n\n3.3.1 Minimum\nThis parameter is just relevant, if “Values should be” is set to “Greater than”, “Greater or equal”, “Between” or “Outside”. It defines a lower bound to apply the operation specified in “Values should be” (default: 0).\n\n\n3.3.2 Maximum\nThis parameter is just relevant, if “Values should be” is set to “Less than”, “Less or equal”, “Between” or “Outside”. It defines a upper bound to apply the operation specified in “Values should be” (default: 0)."
  },
  {
    "objectID": "filtervalidvaluescolumns.html#filter-mode",
    "href": "filtervalidvaluescolumns.html#filter-mode",
    "title": "Filter columns based on valid values",
    "section": "3.4 Filter mode",
    "text": "3.4 Filter mode\nThe “Filter mode” defines, whether the input matrix will be reduced (“Reduce matrix” = default) or a new categorical column called “Filter” will be generated containing the categories “Keep” and “Discard” (“Filter mode” = “Add categorical column”)."
  },
  {
    "objectID": "createqualitymatrix.html",
    "href": "createqualitymatrix.html",
    "title": "Create quality matrix",
    "section": "",
    "text": "1 General\n\nType: - Matrix Processing\nHeading: - Quality\nSource code: CreateQualityMatrix.cs\n\n\n\n2 Brief description\nCreate a matrix of quality values from a set of numerical columns. There has to be one numerical column per expression column.\n\n\n\n3 Parameters\nTo each of the expression columns in the matrix one numerical column has to be assigned (default: to all expression columns the first numerical column in the matrix is assigned).\n\n\n4 Parameter window"
  },
  {
    "objectID": "filterquality.html",
    "href": "filterquality.html",
    "title": "Filter quality",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Quality\nSource code: not public."
  },
  {
    "objectID": "filterquality.html#filter-method",
    "href": "filterquality.html#filter-method",
    "title": "Filter quality",
    "section": "3.1 Filter method",
    "text": "3.1 Filter method\nDefines the filter method that will be applied to the values in the expression columns (default: From quality matrix). If “From quality matrix” is selected, the filtering is just based on the previously created quality matrix and a threshold must be specified (see parameter window A). If “Compare main to quality matrix” is chosen, the values of the two matrices are compared to each other in the way it is specified in “Values should be” (see parameter window B).\n\n3.1.1 Threshold\nThis parameter is just relevant, if the “Filter method” is “From quality matrix”. It specifies which values of the matrix will be kept and which ones will be discarded (default: 0). Values lower than the defined “Threshold” will be filtered.\n\n\n3.1.2 Values should be\nThis parameter is just relevant, if the “Filter method” is “Compare main to quality matrix”. It specifies how the values of the main matrix should be compared to the values of the quality matrix (default: Greater than). The operation how to compare the values of the two matrices can be chosen from a predefined list:\n\nGreater than\nGreater or equal\nLess than\nLess or equal"
  },
  {
    "objectID": "converttonan.html",
    "href": "converttonan.html",
    "title": "Convert to NaN",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Quality\nSource code: not public."
  },
  {
    "objectID": "converttonan.html#values-should-be",
    "href": "converttonan.html#values-should-be",
    "title": "Convert to NaN",
    "section": "3.1 Values should be",
    "text": "3.1 Values should be\nSpecifies how the expression values of the matrix should be compared to the defined “Threshold” (default: Greater than). The operation how to compare the values can be chosen from a predefined list:\n\nGreater than\nGreater or equal\nLess than\nLess or equal"
  },
  {
    "objectID": "converttonan.html#threshold",
    "href": "converttonan.html#threshold",
    "title": "Convert to NaN",
    "section": "3.2 Threshold",
    "text": "3.2 Threshold\nValue defining which expression values should be converted to NaN (default: 0)."
  },
  {
    "objectID": "addannotationtomatrix.html",
    "href": "addannotationtomatrix.html",
    "title": "Add annotation",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. columns\nSource code: AddAnnotationToMatrix.cs"
  },
  {
    "objectID": "addannotationtomatrix.html#source",
    "href": "addannotationtomatrix.html#source",
    "title": "Add annotation",
    "section": "3.1 Source",
    "text": "3.1 Source\nSpecified path to the file containing the annotations that should be added to the matrix (default: first file in Perseus-version /conf/annotations/). The file can be selected from all files in Perseus-version /conf/annotations/.\n\n3.1.1 ENSG column\nSelected text column that contains the base identifier, which are going to be matched to the annotations (default: first text column in the matrix).\n\n\n3.1.2 Annotations to be added\nSelected annotations that should be added (default: no annotations are selected). The annotations can be selected from a list of annotations defined by the tab separated columns in the file specified in “Source”."
  },
  {
    "objectID": "addannotationtomatrix.html#additional-sources",
    "href": "addannotationtomatrix.html#additional-sources",
    "title": "Add annotation",
    "section": "3.2 Additional sources",
    "text": "3.2 Additional sources\nSelected files containing the annotations that should additionally be added to the matrix (default: no files are selected). Additional sources can be selected from all files in Perseus-version conf/annotations."
  },
  {
    "objectID": "backtobaseidentifiers.html",
    "href": "backtobaseidentifiers.html",
    "title": "To base identifiers",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. columns\nSource code: BackToBaseIdentifiers.cs"
  },
  {
    "objectID": "backtobaseidentifiers.html#source",
    "href": "backtobaseidentifiers.html#source",
    "title": "To base identifiers",
    "section": "3.1 Source",
    "text": "3.1 Source\nSpecified path to the file containing the annotations that should be mapped back to the base identifiers (default: first file in Perseus-version /conf/annotations/). The file should be the same that was used to add the annotations, also it can be selected from all files in Perseus-version /conf/annotations/."
  },
  {
    "objectID": "backtobaseidentifiers.html#identifiers",
    "href": "backtobaseidentifiers.html#identifiers",
    "title": "To base identifiers",
    "section": "3.2 Identifiers",
    "text": "3.2 Identifiers\nSelected text column containing the identifiers that should be matched back to UniProt identifiers (default: first text column in the matrix).\nComment: Only text columns can be matched back not categorical ones, because there is no unique match."
  },
  {
    "objectID": "backtobaseidentifiers.html#identifier-type",
    "href": "backtobaseidentifiers.html#identifier-type",
    "title": "To base identifiers",
    "section": "3.3 Identifier type",
    "text": "3.3 Identifier type\nSelected type of the identifiers that will be mapped back (default: Gene name). The identifier type can be selected from a predefined list:\n\nENSG\nENSP\nENST\nFlybase\nGene name\nMGI\nPDB\nUniProt names\nWormbase\nEC\neggNOG\n\n==== Parameter window"
  },
  {
    "objectID": "fisherexacttestproces.html",
    "href": "fisherexacttestproces.html",
    "title": "Fisher exact test",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. columns\nSource code: not public."
  },
  {
    "objectID": "fisherexacttestproces.html#input-type",
    "href": "fisherexacttestproces.html#input-type",
    "title": "Fisher exact test",
    "section": "3.1 Input type",
    "text": "3.1 Input type\nSpecification whether the sub-population that is tested for contingency against all other categorical columns is taken directly from a categorical column (“Categorical column” is default) or, if it is defined by a threshold on a numerical/expression column (“Numerical column”).\n\n3.1.1 Column\nThis parameter is just relevant, if “Input type” is set to “Categorical column”. The selected categorical column is checked against all other categorical columns for association between the occurrence of terms (default: first categorical column in the matrix).\n\n\n3.1.2 Columns\nThis parameter is just relevant, if “Input type” is set to “Numerical column”. The selected expression/numerical columns are used as a threshold to define the set of interest. The set is then checked against all categorical columns for association between the occurrence of terms (default: all expression and numerical columns are selected).\n\n\n3.1.3 Threshold\nThis parameter is just relevant, if “Input type” is set to “Numerical column”. It defines the threshold, which rows are kept/discarded to define the set of interest (default: 2).\n\n\n3.1.4 Selection is\nThis parameter is just relevant, if “Input type” is set to “Numerical column”. It defines, whether the values in the selected “Columns” should be “Larger than threshold” or “Less than threshold” (default: Larger than threshold)."
  },
  {
    "objectID": "fisherexacttestproces.html#sec-truncation",
    "href": "fisherexacttestproces.html#sec-truncation",
    "title": "Fisher exact test",
    "section": "3.2 Use for truncation",
    "text": "3.2 Use for truncation\nThe truncation can be based on p-values or the Benjamini-Hochberg correction for multiple hypothesis testing (default: Benjamini-Hochberg, FDR). Rows with a test result below a specified value (Section 3.3) are reported as significant."
  },
  {
    "objectID": "fisherexacttestproces.html#sec-threshold-value",
    "href": "fisherexacttestproces.html#sec-threshold-value",
    "title": "Fisher exact test",
    "section": "3.3 Threshold value",
    "text": "3.3 Threshold value\nBased on a specified threshold (default: 0.02) a specific row is reported as significant. Depending on the chosen truncation score (Section 3.2) this threshold value is applied to the p-value or to the Benjamini-Hochberg FDR."
  },
  {
    "objectID": "fisherexacttestproces.html#relative-enrichment",
    "href": "fisherexacttestproces.html#relative-enrichment",
    "title": "Fisher exact test",
    "section": "3.4 Relative enrichment",
    "text": "3.4 Relative enrichment\nSelected text column, where all rows having the same identifier will be counted as one entity in the Fisher exact test (default: ). The main application is for post-translational modification sites. Then one should select here protein or gene identifiers. This will make sure that multiple sites from the same protein (or gene) are counted only once for the enrichment analysis."
  },
  {
    "objectID": "averagecategories.html",
    "href": "averagecategories.html",
    "title": "Average categories",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. columns\nSource code: AverageCategories.cs"
  },
  {
    "objectID": "averagecategories.html#categories",
    "href": "averagecategories.html#categories",
    "title": "Average categories",
    "section": "3.1 Categories",
    "text": "3.1 Categories\nSelected categorical columns that are used to specify, which rows should be summarized (default: all categorical columns are selected)."
  },
  {
    "objectID": "averagecategories.html#average-type",
    "href": "averagecategories.html#average-type",
    "title": "Average categories",
    "section": "3.2 Average type",
    "text": "3.2 Average type\nSelected operation that should be used to average the values of the expression columns (default: median). The operation can be selected from a predefined list of operations:\n\nMedian\nMean\nSum\nStandard deviation"
  },
  {
    "objectID": "averagecategories.html#min.-size",
    "href": "averagecategories.html#min.-size",
    "title": "Average categories",
    "section": "3.3 Min. size",
    "text": "3.3 Min. size\nThe minimal occurrence of a certain term within a categorical column so that the rows will be summarized into one row (default: 3)."
  },
  {
    "objectID": "categorycounting.html",
    "href": "categorycounting.html",
    "title": "Category counting",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. columns\nSource code: CategoryCounting.cs"
  },
  {
    "objectID": "categorycounting.html#categories",
    "href": "categorycounting.html#categories",
    "title": "Category counting",
    "section": "3.1 Categories",
    "text": "3.1 Categories\nSelected categorical columns for which the absolute and relative occurrence of each term gets counted and displayed in two newly generated numerical columns called “Count” and “Percentage of total” (default: all categorical columns are selected)."
  },
  {
    "objectID": "categorycounting.html#min.-count",
    "href": "categorycounting.html#min.-count",
    "title": "Category counting",
    "section": "3.2 Min. count",
    "text": "3.2 Min. count\nMinimal occurrence of a certain term to be displayed in the output table (default: 1)."
  },
  {
    "objectID": "categorycounting.html#selection",
    "href": "categorycounting.html#selection",
    "title": "Category counting",
    "section": "3.3 Selection",
    "text": "3.3 Selection\nSelected categorical column in which the “Value” will be searched and counted for each term in the “Categories” field specified categorical columns (default: ). Two new numerical columns called “Selection count” and “Selection percentage” are generated in the output table containing the absolute and relative amounts."
  },
  {
    "objectID": "categorycounting.html#value",
    "href": "categorycounting.html#value",
    "title": "Category counting",
    "section": "3.4 Value",
    "text": "3.4 Value\nDefines the value that is searched in the categorical column specified in “Selection” (default: +)."
  },
  {
    "objectID": "onedimannotationenrichment.html",
    "href": "onedimannotationenrichment.html",
    "title": "1D annotation enrichment",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. columns\nSource code: not public."
  },
  {
    "objectID": "onedimannotationenrichment.html#columns",
    "href": "onedimannotationenrichment.html#columns",
    "title": "1D annotation enrichment",
    "section": "3.1 Columns",
    "text": "3.1 Columns\nSelected expression/numerical columns that should be processed (default: no expression/numerical columns are selected)."
  },
  {
    "objectID": "onedimannotationenrichment.html#use-for-truncation",
    "href": "onedimannotationenrichment.html#use-for-truncation",
    "title": "1D annotation enrichment",
    "section": "3.2 Use for truncation",
    "text": "3.2 Use for truncation\nThe truncation can be based on p-values or the Benjamini-Hochberg correction for multiple hypothesis testing (default: Benjamini-Hochberg FDR). Rows with a test result below a specified value (“Threshold value”) are reported as significant."
  },
  {
    "objectID": "onedimannotationenrichment.html#side",
    "href": "onedimannotationenrichment.html#side",
    "title": "1D annotation enrichment",
    "section": "3.3 Side",
    "text": "3.3 Side\nTo apply a two-sided test, where the null hypothesis can be rejected regardless of the direction of the effect “both” has to be selected (default). “high” and “low” are the respective one-sided tests."
  },
  {
    "objectID": "onedimannotationenrichment.html#threshold-value",
    "href": "onedimannotationenrichment.html#threshold-value",
    "title": "1D annotation enrichment",
    "section": "3.4 Threshold value",
    "text": "3.4 Threshold value\nBased on a specified threshold (default: 0.02) a row is reported as significant, if its test result is below the defined value. Depending on the chosen truncation score this threshold value is applied to the p-value or to the Benjamini-Hochberg FDR"
  },
  {
    "objectID": "onedimannotationenrichment.html#relative-enrichment",
    "href": "onedimannotationenrichment.html#relative-enrichment",
    "title": "1D annotation enrichment",
    "section": "3.5 Relative enrichment",
    "text": "3.5 Relative enrichment\nSelected text column, where all rows having the same identifier will be counted as one entity in the 1D annotation enrichment analysis (default: &lt;None&gt;). The main application is for posttranslational modification sites. Then one should select here protein or gene identifiers. This will make sure that multiple sites from the same protein (or gene) are counted only once for the enrichment analysis."
  },
  {
    "objectID": "twodimannotationenrichment.html",
    "href": "twodimannotationenrichment.html",
    "title": "2D annotation enrichment",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. columns\nSource code: not public.\n\n\n\nFor every term in the categorical columns it is tested whether the corresponding expression values have a distribution in two-dimensional planes of expression values that is deviating from the global distribution. For details see Cox and Mann (2012) (Cox and Mann 2012) .\nOutput: The output matrix contains a list of terms from all categorical columns that are significantly biased compared to the global distribution."
  },
  {
    "objectID": "twodimannotationenrichment.html#brief-description",
    "href": "twodimannotationenrichment.html#brief-description",
    "title": "2D annotation enrichment",
    "section": "",
    "text": "For every term in the categorical columns it is tested whether the corresponding expression values have a distribution in two-dimensional planes of expression values that is deviating from the global distribution. For details see Cox and Mann (2012) (Cox and Mann 2012) .\nOutput: The output matrix contains a list of terms from all categorical columns that are significantly biased compared to the global distribution."
  },
  {
    "objectID": "twodimannotationenrichment.html#columns1",
    "href": "twodimannotationenrichment.html#columns1",
    "title": "2D annotation enrichment",
    "section": "2.1 Columns1",
    "text": "2.1 Columns1\nSelected numerical/expression columns that are used as x-axis for the testing of the 2D distributions (default: no expression/numerical columns are selected).\nHint: The selected number of columns in “Columns1” have to be equal to the selected ones in “Columns2”."
  },
  {
    "objectID": "twodimannotationenrichment.html#columns2",
    "href": "twodimannotationenrichment.html#columns2",
    "title": "2D annotation enrichment",
    "section": "2.2 Columns2",
    "text": "2.2 Columns2\nSelected numerical/expression columns that are used as y-axis for the testing of the 2D distributions (default: no expression/numerical columns are selected).\nHint: The selected number of columns in “Columns2” have to be equal to the selected ones in “Columns1”."
  },
  {
    "objectID": "twodimannotationenrichment.html#use-for-truncation",
    "href": "twodimannotationenrichment.html#use-for-truncation",
    "title": "2D annotation enrichment",
    "section": "2.3 Use for truncation",
    "text": "2.3 Use for truncation\nThe truncation can be based on p-values or the Benjamini-Hochberg correction for multiple hypothesis testing (default: Benjamini-Hochberg FDR). Rows with a test result below a specified value (“Threshold value”) are reported as significant."
  },
  {
    "objectID": "twodimannotationenrichment.html#threshold-value",
    "href": "twodimannotationenrichment.html#threshold-value",
    "title": "2D annotation enrichment",
    "section": "2.4 Threshold value",
    "text": "2.4 Threshold value\nBased on a specified threshold (default: 0.02) a row is reported as significant, if its test result is below the defined value. Depending on the chosen truncation score this threshold value is applied to the p-value or to the Benjamini-Hochberg FDR."
  },
  {
    "objectID": "twodimannotationenrichment.html#relative-enrichment",
    "href": "twodimannotationenrichment.html#relative-enrichment",
    "title": "2D annotation enrichment",
    "section": "2.5 Relative enrichment",
    "text": "2.5 Relative enrichment\nSelected text column, where all rows having the same identifier will be counted as one entity in the 2D annotation enrichment analysis (default: &lt;None&gt;). The main application is for post-translational modification sites. Then one should select here protein or gene identifiers.\nThis will make sure that multiple sites from the same protein (or gene) are counted only once for the enrichment analysis."
  },
  {
    "objectID": "createcategoricalannotrow.html",
    "href": "createcategoricalannotrow.html",
    "title": "Categorical annotation rows",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. rows\nSource code: CreateCategoricalAnnotRow.cs"
  },
  {
    "objectID": "createcategoricalannotrow.html#action",
    "href": "createcategoricalannotrow.html#action",
    "title": "Categorical annotation rows",
    "section": "3.1 Action",
    "text": "3.1 Action\nDefines the action that should be applied to a categorical annotation row (default: Create). The action can be selected from a predefined list:\n\nCreate\nCreate from experiment name\nEdit\nRename\nDelete\nWrite template file\nRead from file\n\nEach of the above listed options has different parameters, which are explained below in more detail and grouped according to the action.\n\n3.1.1 Create\n\n3.1.1.1 Row name\nThis parameter is just relevant, if “Action” is set to “Create”. It defines the name of the new generated categorical annotation row (default: Group1).\n\n\n3.1.1.2 Here: Column 1 … Column 12\nThis parameter is just relevant, if “Action” is set to “Create”. For each of the expression columns in the matrix the category value of that column in the categorical annotation row can be specified (default: each expression column has its own category indicated by the name of the expression column).\n\n\n\n3.1.2 Create from experiment name\n\n3.1.2.1 Pattern\nThis parameter is just relevant, if “Action” is set to “Create from experiment name”. It specifies the pattern that will be applied to the column names to group the columns and generate a new categorical annotation row (default: …_01,02,03). The Pattern can be selected from a predefined list:\n\n…_01,02,03\n(LFQ) intensity …_01,02,03\n(Normalized) ratio H/L …_01,02,03\nmatch regular expression\nreplace regular expression\n\n\n\n3.1.2.2 Regex\nThis parameter is just relevant, if “Action” is set to “Create from experiment name” and the parameter “Pattern” is set to “match regular expression” or “replace regular expression” (default: empty text field). Here a regular expression can be typed in, which should be applied to the column names to group the columns. The general rules for regular expressions apply here.\n\n\n3.1.2.3 Replace with\nThis parameter is just relevant, if “Action” is set to “Create from experiment name” and the parameter “Pattern” is set to “replace regular expression” (default: empty text field). Columns matching the defined regular expression in the field “Regex” get the value specified in the “Replace with” field and are therefore grouped.\n\n\n\n3.1.3 Edit\n\n3.1.3.1 Category row\nThis parameter is just relevant, if “Action” is set to “Edit”. It specifies the selected categorical row that should be edited (default: first categorical column in the matrix).\n\n\n3.1.3.2 Here: Column 1…Column 12\nThis parameter is just relevant, if “Action” is set to “Edit”. For each of the expression columns in the matrix the value in the categorical row can be edited by typing into the defined text field after the column name (default: category values of each expression column in that row).\n\n\n\n3.1.4 Rename\n\n3.1.4.1 Category row\nThis parameter is just relevant, if “Action” is set to “Rename”. It specifies the selected categorical row that should be renamed (default: first category row in the matrix).\n\n\n3.1.4.2 New name\nThis parameter is just relevant, if “Action” is set to “Rename”. It defines the new name of the categorical row (default: empty).\n\n\n3.1.4.3 New description\nThis parameter is just relevant, if “Action” is set to “Rename”. It defines the new description of the categorical row (default: empty).\n\n\n\n3.1.5 Delete\n\n3.1.5.1 Category row\nThis parameter is just relevant, if “Action” is set to “Delete”. It specifies the selected categorical row that should be deleted (default: first category row in the matrix).\n\n\n\n3.1.6 Write template file\n\n3.1.6.1 Output file\nThis parameter is just relevant, if “Action” is set to “Write template file”. It specifies the file name and path, where a grouping template of a categorical annotation rows is saved in a tab separated text file (default: Groups.txt). The first column of the output file is named “Name” and contains the names of the columns. The second column has the column names as values and can be edited manually. After editing the file can be read using “Read from file” (see below).\n\n\n\n3.1.7 Read from file\n\n3.1.7.1 Input file\nThis parameter is just relevant, if “Action” is set to “Read from file”. It defines the file name and path of a tab separated file containing information about a new grouping of the columns of a matrix (default: empty). The first column is called “Name” and contains the names of the columns of the matrix. The second column has the name of the new grouping and contains the values of each column of the matrix."
  },
  {
    "objectID": "createnumericalannotrow.html",
    "href": "createnumericalannotrow.html",
    "title": "Numerical annotation rows",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. rows\nSource code: CreateNumericalAnnotRow.cs\n\n\n\nAdd or edit numerical annotation rows. This could for instance define the times of samples for time series data.\nOutput: Same matrix with numerical annotation row added or modified."
  },
  {
    "objectID": "createnumericalannotrow.html#brief-description",
    "href": "createnumericalannotrow.html#brief-description",
    "title": "Numerical annotation rows",
    "section": "",
    "text": "Add or edit numerical annotation rows. This could for instance define the times of samples for time series data.\nOutput: Same matrix with numerical annotation row added or modified."
  },
  {
    "objectID": "createnumericalannotrow.html#action",
    "href": "createnumericalannotrow.html#action",
    "title": "Numerical annotation rows",
    "section": "2.1 Action",
    "text": "2.1 Action\nDefines the action that should be applied to a numerical annotation row (default: Create). The action can be selected from a predefined list:\n\nCreate\nEdit\nRename\nDelete\n\nEach of the above listed options has different parameters, which are explained below in more detail and grouped according to the action.\n\n2.1.1 Create\n\n2.1.1.1 Row name\nThis parameter is just relevant, if “Action” is set to “Create”. It defines the name of the new generated numerical annotation row (default: Quantity1).\n\n\n2.1.1.2 Here: Column 1 … Column 12\nThis parameter is just relevant, if “Action” is set to “Create”. For each of the expression columns in the matrix the numerical value of that column in the numerical annotation row can be specified (default: each expression column has an own numerical group indicated by a number).\n\n\n\n2.1.2 Edit\n\n2.1.2.1 Numerical row\nThis parameter is just relevant, if “Action” is set to “Edit”. It specifies the selected numerical row that should be edited (default: first numerical column in the matrix).\n\n\n2.1.2.2 Here: Column 1…Column 12\nThis parameter is just relevant, if “Action” is set to “Edit”. For each of the expression columns in the matrix the value in the numerical row can be edited by typing into the defined text field after the column name (default: numerical value of each expression column in that row).\n\n\n\n2.1.3 Rename\n\n2.1.3.1 Numerical row\nThis parameter is just relevant, if “Action” is set to “Rename”. It specifies the selected numerical row that should be renamed (default: first numerical row in the matrix).\n\n\n2.1.3.2 New name\nThis parameter is just relevant, if “Action” is set to “Rename”. It defines the new name of the numerical row (default: empty).\n\n\n2.1.3.3 New description\nThis parameter is just relevant, if “Action” is set to “Rename”. It defines the new description of the numerical row (default: empty).\n\n\n\n2.1.4 Delete\n\n2.1.4.1 Numerical row\nThis parameter is just relevant, if “Action” is set to “Delete”. It specifies the selected categorical row that should be deleted (default: first category row in the matrix)."
  },
  {
    "objectID": "averagegroups.html",
    "href": "averagegroups.html",
    "title": "Average Groups",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. rows\nSource code: AverageGroups.cs"
  },
  {
    "objectID": "averagegroups.html#grouping",
    "href": "averagegroups.html#grouping",
    "title": "Average Groups",
    "section": "3.1 Grouping",
    "text": "3.1 Grouping\nDefines, which grouping specified in a categorical row should be used to average values (default: first categorical row in the matrix)."
  },
  {
    "objectID": "averagegroups.html#average-type",
    "href": "averagegroups.html#average-type",
    "title": "Average Groups",
    "section": "3.2 Average type",
    "text": "3.2 Average type\nSpecifies which operation should be applied for the averaging (default: Median). The operation can be selected from a predefined list:\n\nMedian\nMean\nSum\nGeometric mean"
  },
  {
    "objectID": "averagegroups.html#min.-valid-values-per-group",
    "href": "averagegroups.html#min.-valid-values-per-group",
    "title": "Average Groups",
    "section": "3.3 Min. valid values per group",
    "text": "3.3 Min. valid values per group\nDefines the minimal values a group must contain to calculate the average (default: 1)."
  },
  {
    "objectID": "averagegroups.html#keep-original-data",
    "href": "averagegroups.html#keep-original-data",
    "title": "Average Groups",
    "section": "3.4 Keep original data",
    "text": "3.4 Keep original data\nIf checked the original data will be kept In the output matrix (default: unchecked)."
  },
  {
    "objectID": "averagegroups.html#add-variation",
    "href": "averagegroups.html#add-variation",
    "title": "Average Groups",
    "section": "3.5 Add variation",
    "text": "3.5 Add variation\nSpecifies, whether a measure of group-wise variation should be calculated and displayed in a numerical column (default: &lt;None&gt;). The measure can be selected from a predefined list:\n\n&lt;None&gt;\nStandard deviation\nError of mean"
  },
  {
    "objectID": "jointermsincategoricalrow.html",
    "href": "jointermsincategoricalrow.html",
    "title": "Join terms in categorical row",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Annot. rows\nSource code: JoinTermsInCategoricalRow.cs"
  },
  {
    "objectID": "jointermsincategoricalrow.html#row",
    "href": "jointermsincategoricalrow.html#row",
    "title": "Join terms in categorical row",
    "section": "3.1 Row",
    "text": "3.1 Row\nSelected categorical row that the filtering should be based on (default: first categorical row in the matrix)."
  },
  {
    "objectID": "jointermsincategoricalrow.html#values",
    "href": "jointermsincategoricalrow.html#values",
    "title": "Join terms in categorical row",
    "section": "3.2 Values",
    "text": "3.2 Values\nSelected values that should be joined to one group (default: no values are selected)."
  },
  {
    "objectID": "jointermsincategoricalrow.html#new-term",
    "href": "jointermsincategoricalrow.html#new-term",
    "title": "Join terms in categorical row",
    "section": "3.3 New term",
    "text": "3.3 New term\nDefines the new value the above joined values should get (default: empty)."
  },
  {
    "objectID": "onesampletestprocessing.html",
    "href": "onesampletestprocessing.html",
    "title": "One-sample tests",
    "section": "",
    "text": "1 General\n\nType: - Matrix Processing\nHeading: - Tests\nSource code: not public.\n\n\n\n2 Brief description\nOne sample-test for determining if the mean is significantly different from a fixed value (typically 0).\nOutput: Two numerical columns are added, one containing the p-value, the other containing the difference between the mean and the fixed value (which is usually 0). In addition there is a categorical column added in which it is indicated by a ‘+’ when the row is significant with respect to the specified criteria."
  },
  {
    "objectID": "twosampletestprocessing.html",
    "href": "twosampletestprocessing.html",
    "title": "Two-sample tests",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Tests\nSource code: not public."
  },
  {
    "objectID": "twosampletestprocessing.html#grouping",
    "href": "twosampletestprocessing.html#grouping",
    "title": "Two-sample tests",
    "section": "3.1 Grouping",
    "text": "3.1 Grouping\nThe grouping(s) of columns to be used in the test. Each test takes two groups as input. Multiple tests can be performed simultaneously by specifying more than one pair of groups.\n\n3.1.1 First group (right)\nAll ‘right’ groups of the two sample tests are defined here. The number of groups selected here equals the number of different tests performed.\n\n\n3.1.2 Second groups mode\nSpecify here how the ‘left’ groups of the two sample tests are specified. Possible ways are to specify for each individual ‘right’ group the corresponding ‘left’ group, to use one single control group, or to always use the complement of each individual ‘right’ group as the ‘left’ group."
  },
  {
    "objectID": "twosampletestprocessing.html#test",
    "href": "twosampletestprocessing.html#test",
    "title": "Two-sample tests",
    "section": "3.2 Test",
    "text": "3.2 Test\nDefines what kind of test should be applied (default: T-test). The test can be selected from a predefined list:\n\nT-test\nWelch test\n\n\n3.2.1 S0\nThis parameter defines the artificial within groups variance (default: 0). It controls the relative importance of the resulted p-value and difference between means. At \\(s0=0\\) only the p-value matters, while at nonzero s0 also the difference of means plays a role. See (Tusher, Tibshirani, and Chu 2001) for details.\n\n\n3.2.2 Side\nTo apply a two-sided test, where the null hypothesis can be rejected regardless of the direction of the effect “both” has to be selected (default). “left” and “right” are the respective one-sided tests."
  },
  {
    "objectID": "twosampletestprocessing.html#valid-value-filter",
    "href": "twosampletestprocessing.html#valid-value-filter",
    "title": "Two-sample tests",
    "section": "3.3 Valid value filter",
    "text": "3.3 Valid value filter\nSpecify here how rows are filtered regarding the number and percentage of valid values. This criterion will be applied to each test individually, not just once to the whole matrix. The absolute number and relative percentage filters are both applied together.\n\n3.3.1 Min. number of valid values\nHere the required number of valid values is specified. How this threshold is applied (in total, per group, etc.) is specified in the next field.\n\n\n3.3.2 Min. number mode\nSpecify here how the threshold is applied.\n\n\n3.3.3 Min. percentage of valid values\nHere the required percentage of valid values is specified. How this threshold is applied (in total, per group, etc.) is specified in the next field. Values can range from 0 to 100.\n\n\n3.3.4 Min. percentage mode\nSpecify here how the above threshold is applied."
  },
  {
    "objectID": "twosampletestprocessing.html#use-for-truncation",
    "href": "twosampletestprocessing.html#use-for-truncation",
    "title": "Two-sample tests",
    "section": "3.4 Use for truncation",
    "text": "3.4 Use for truncation\nDefines on what value the truncation is based on (default: Permutation-based FDR). Choose here whether the truncation should be based on the p-values, on permutation-based FDR values or, if the Benjamini-Hochberg correction for multiple hypothesis testing should be applied.\n\n3.4.1 Threshold p-value\nThis parameter is just relevant, if the parameter “Use for truncation” is set to “P-value”. Rows with a test result below this value are reported as significant (default: 0.05).\n\n\n3.4.2 FDR\nThis parameter is just relevant, if the parameter “Use for truncation” is set to “Benjamini-Hochberg FDR” or “Permutation-based FDR”. Rows with a test result below this value are reported as significant (default: 0.05).\n\n\n3.4.3 Number of randomizations\nSpecifies the number of randomizations that should be applied (default: 250).\n\n\n3.4.4 Preserve grouping in randomizations\nDefines, whether the grouping specified in a categorical row should be preserved in the randomizations (default: &lt;None&gt;). It can be selected from a list including all available groupings of the matrix."
  },
  {
    "objectID": "twosampletestprocessing.html#calculate-combined-score",
    "href": "twosampletestprocessing.html#calculate-combined-score",
    "title": "Two-sample tests",
    "section": "3.5 Calculate combined score",
    "text": "3.5 Calculate combined score\nIn case multiple two sample tests are performed, the combined score helps to define a global set of significant items over all the tests combined. A global q-value can be calculated based on permutations of the whole matrix.\n\n3.5.1 Mode\nHere the user can define the combined score which is either the p-value from the best test or the product over all tests.\n\n\n3.5.2 Combined q-value\nIn case this is checked, a combined q-value based on the combined score and permutations of the whole matrix is calculated."
  },
  {
    "objectID": "twosampletestprocessing.html#log10",
    "href": "twosampletestprocessing.html#log10",
    "title": "Two-sample tests",
    "section": "3.6 -Log10",
    "text": "3.6 -Log10\nIf checked, \\(-Log_{10}(test\\ value)\\) is reported in the output matrix (default). Otherwise the test-value is reported."
  },
  {
    "objectID": "twosampletestprocessing.html#suffix",
    "href": "twosampletestprocessing.html#suffix",
    "title": "Two-sample tests",
    "section": "3.7 Suffix",
    "text": "3.7 Suffix\nThe entered suffix will be attached to newly generated columns (default: empty). That way columns from multiple runs of the test can be distinguished more easily."
  },
  {
    "objectID": "multiplesampletestprocessing.html",
    "href": "multiplesampletestprocessing.html",
    "title": "Multiple-samples tests",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Tests\nSource code: not public."
  },
  {
    "objectID": "multiplesampletestprocessing.html#grouping",
    "href": "multiplesampletestprocessing.html#grouping",
    "title": "Multiple-samples tests",
    "section": "3.1 Grouping",
    "text": "3.1 Grouping\nSelected categorical row that defines the grouping of columns that should be used in the test (default: first categorical row in the matrix)."
  },
  {
    "objectID": "multiplesampletestprocessing.html#test",
    "href": "multiplesampletestprocessing.html#test",
    "title": "Multiple-samples tests",
    "section": "3.2 Test",
    "text": "3.2 Test\nDefines what kind of test should be applied (default: ANOVA). The test can be selected from a predefined list:\n\nANOVA\nKruskal Wallis\n\n\n3.2.1 S0\nArtificial within groups variance (default: 0). It controls the relative importance of t-test p-value and difference between means. At \\(s0=0\\) only the p-value matters, while at nonzero s0 also the difference of means plays a role. See (Tusher, Tibshirani, and Chu 2001) for details."
  },
  {
    "objectID": "multiplesampletestprocessing.html#use-for-truncation",
    "href": "multiplesampletestprocessing.html#use-for-truncation",
    "title": "Multiple-samples tests",
    "section": "3.3 Use for truncation",
    "text": "3.3 Use for truncation\nDefines on what value the truncation is based on (default: Permutation-based FDR). Choose here whether the truncation should be based on the p-values, on permutation-based FDR-values or, if the Benjamini-Hochberg correction for multiple hypothesis testing should be applied.\n\n3.3.1 Threshold p-value\nThis parameter is just relevant, if the parameter “Use for truncation” is set to “P-value”. Rows with a test result below this value are reported as significant (default: 0.05).\n\n\n3.3.2 FDR\nThis parameter is just relevant, if the parameter “Use for truncation” is set to “Benjamini-Hochberg FDR” or “Permutation-based FDR”. Rows with a test result below this value are reported as significant (default: 0.05).\n\n\n3.3.3 Number of randomizations\nSpecifies the number of randomizations that should be applied (default: 250).\n\n\n3.3.4 Preserve grouping in randomizations\nDefines, whether the grouping specified in a categorical row should be preserved in the randomizations (default: &lt;None&gt;). It can be selected from a list including all available groupings of the matrix."
  },
  {
    "objectID": "multiplesampletestprocessing.html#log10",
    "href": "multiplesampletestprocessing.html#log10",
    "title": "Multiple-samples tests",
    "section": "3.4 Log10",
    "text": "3.4 Log10\nIf checked, \\(-Log_{10}(test\\ value)\\) is reported in the output matrix (default). Otherwise the test-value is reported."
  },
  {
    "objectID": "multiplesampletestprocessing.html#suffix",
    "href": "multiplesampletestprocessing.html#suffix",
    "title": "Multiple-samples tests",
    "section": "3.5 Suffix",
    "text": "3.5 Suffix\nThe entered suffix will be attached to newly generated columns (default: empty). That way columns from multiple runs of the test can be distinguished more easily."
  },
  {
    "objectID": "twowayanova.html",
    "href": "twowayanova.html",
    "title": "Two-way ANOVA",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Tests\nSource code: not public."
  },
  {
    "objectID": "twowayanova.html#first-grouping",
    "href": "twowayanova.html#first-grouping",
    "title": "Two-way ANOVA",
    "section": "3.1 First Grouping",
    "text": "3.1 First Grouping\nSelected categorical row that defines the first grouping of columns that should be used in the test (default: first categorical row in the matrix)."
  },
  {
    "objectID": "twowayanova.html#second-grouping",
    "href": "twowayanova.html#second-grouping",
    "title": "Two-way ANOVA",
    "section": "3.2 Second Grouping",
    "text": "3.2 Second Grouping\nSelected categorical row that defines the second grouping of columns that should be used in the test (default: first categorical row in the matrix)."
  },
  {
    "objectID": "twowayanova.html#third-grouping",
    "href": "twowayanova.html#third-grouping",
    "title": "Two-way ANOVA",
    "section": "3.3 Third Grouping",
    "text": "3.3 Third Grouping\nSelected categorical row that defines the third grouping of columns that should be used in the test (default: first categorical row in the matrix)."
  },
  {
    "objectID": "twowayanova.html#log10",
    "href": "twowayanova.html#log10",
    "title": "Two-way ANOVA",
    "section": "3.4 -Log10",
    "text": "3.4 -Log10\nIf checked, \\(-Log_{10}(test\\ value)\\) is reported in the output matrix (default). Otherwise the test-value is reported."
  },
  {
    "objectID": "twowayanova.html#suffix",
    "href": "twowayanova.html#suffix",
    "title": "Two-way ANOVA",
    "section": "3.5 Suffix",
    "text": "3.5 Suffix\nThe entered suffix will be attached to newly generated columns (default: empty). That way columns from multiple runs of the test can be distinguished more easily."
  },
  {
    "objectID": "replacemissingfromgaussian.html",
    "href": "replacemissingfromgaussian.html",
    "title": "Replace missing values from normal distribution",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Imputation\nSource code: ReplaceMissingFromGaussian.cs"
  },
  {
    "objectID": "replacemissingfromgaussian.html#width",
    "href": "replacemissingfromgaussian.html#width",
    "title": "Replace missing values from normal distribution",
    "section": "3.1 Width",
    "text": "3.1 Width\nDefines the width of the Gaussian distribution relative to the standard deviation of measured values (default: 0.3). A value of 0.5 would mean that the width of the distribution used for drawing random numbers is half of the standard deviation of the data."
  },
  {
    "objectID": "replacemissingfromgaussian.html#down-shift",
    "href": "replacemissingfromgaussian.html#down-shift",
    "title": "Replace missing values from normal distribution",
    "section": "3.2 Down shift",
    "text": "3.2 Down shift\nSpecifies the amount by which the distribution used for the random numbers is shifted downwards (default: 1.8). This is in units of the standard deviation of the valid data."
  },
  {
    "objectID": "replacemissingfromgaussian.html#mode",
    "href": "replacemissingfromgaussian.html#mode",
    "title": "Replace missing values from normal distribution",
    "section": "3.3 Mode",
    "text": "3.3 Mode\nSpecifies whether the replacement of missing values should be applied to each expression column separately (default) or on the whole matrix at once (“Total matrix”)."
  },
  {
    "objectID": "replacemissingfromgaussian.html#columns",
    "href": "replacemissingfromgaussian.html#columns",
    "title": "Replace missing values from normal distribution",
    "section": "3.4 Columns",
    "text": "3.4 Columns\nSelected expression columns, where missing values should be replaced (default: all expression columns are selected)."
  },
  {
    "objectID": "replaceimputedbynan.html",
    "href": "replaceimputedbynan.html",
    "title": "Replace missing values by NaN",
    "section": "",
    "text": "1 General =====\n\nType: - Matrix Processing\nHeading: - Imputation\nSource code: ReplaceImputedByNan.cs\n\n\n\n2 Brief description\nReplaces all values that have been imputed with NaN.\nOutput: Same matrix but with imputed values deleted.\n\n\n\n3 Parameters\n“Replace imputed values by NaN” has no parameters."
  },
  {
    "objectID": "replacemissingbyconstant.html",
    "href": "replacemissingbyconstant.html",
    "title": "Replace missing values by constant",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Imputation\nSource code: ReplaceMissingByConstant.cs"
  },
  {
    "objectID": "replacemissingbyconstant.html#value",
    "href": "replacemissingbyconstant.html#value",
    "title": "Replace missing values by constant",
    "section": "3.1 Value",
    "text": "3.1 Value\nSpecifies the value that is going to replace missing values in all expression columns."
  },
  {
    "objectID": "expandsitetable.html",
    "href": "expandsitetable.html",
    "title": "Expand site table",
    "section": "",
    "text": "1 General\n\nType: - Matrix Processing\nHeading: - Modifications\nSource code: ExpandSiteTable.cs\n\n\n\n2 Brief description\nThe ___1, ___2 and ___3 versions of MaxQuant output table columns are rearranged in the matrix to become a single column each.\n\n\n\n3 Parameters\n“Expand site table” has no parameters."
  },
  {
    "objectID": "addlinearmotifs.html",
    "href": "addlinearmotifs.html",
    "title": "Add linear motifs",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Modifications\nSource code: not public."
  },
  {
    "objectID": "addlinearmotifs.html#sequence-window",
    "href": "addlinearmotifs.html#sequence-window",
    "title": "Add linear motifs",
    "section": "3.1 Sequence window",
    "text": "3.1 Sequence window\nSelected text column that contains the sequence windows around the sites (default: first text column in the matrix)."
  },
  {
    "objectID": "addmodificationcounts.html",
    "href": "addmodificationcounts.html",
    "title": "Add modification counts",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Modifications\nSource code: AddModificationCounts.cs"
  },
  {
    "objectID": "addmodificationcounts.html#modifications",
    "href": "addmodificationcounts.html#modifications",
    "title": "Add modification counts",
    "section": "3.1 Modifications",
    "text": "3.1 Modifications\nSelected modifications for which the corresponding sites are counted (default: all modifications are selected). The list of modifications includes:\n\nAcetylation\nMethylation\nO-GlcNAc\nPhosphorylation\nSumoyalation\nUbiquitination"
  },
  {
    "objectID": "addmodificationcounts.html#uniprot-column",
    "href": "addmodificationcounts.html#uniprot-column",
    "title": "Add modification counts",
    "section": "3.2 Uniprot column",
    "text": "3.2 Uniprot column\nSelected text column that contains the Uniprot identifiers (default: first text column in the matrix)."
  },
  {
    "objectID": "addknownsites.html",
    "href": "addknownsites.html",
    "title": "Add known sites",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Modifications\nSource code: AddKnownSites.cs"
  },
  {
    "objectID": "addknownsites.html#modification",
    "href": "addknownsites.html#modification",
    "title": "Add known sites",
    "section": "3.1 Modification",
    "text": "3.1 Modification\nSelected modification for which the known sites should be added (default: Phosphorylation). The modification can be selected from a predefined list:\n\nAcetylation\nMethylation\nO-GlcNAc\nPhosphorylation\nSumoyalation\nUbiquitination"
  },
  {
    "objectID": "addknownsites.html#uniprot-column",
    "href": "addknownsites.html#uniprot-column",
    "title": "Add known sites",
    "section": "3.2 Uniprot column",
    "text": "3.2 Uniprot column\nSelected text column that contains the Uniprot identifiers (default: first text column in the matrix)."
  },
  {
    "objectID": "addknownsites.html#sequence-column",
    "href": "addknownsites.html#sequence-column",
    "title": "Add known sites",
    "section": "3.3 Sequence column",
    "text": "3.3 Sequence column\nSelected text column that contains the sequence windows around the sites (default: first text column in the matrix)."
  },
  {
    "objectID": "kinasesubstraterelations.html",
    "href": "kinasesubstraterelations.html",
    "title": "Kinase-substrate relations",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Modifications\nSource code: KinaseSubstrateRelations.cs"
  },
  {
    "objectID": "kinasesubstraterelations.html#uniprot-column",
    "href": "kinasesubstraterelations.html#uniprot-column",
    "title": "Kinase-substrate relations",
    "section": "3.1 Uniprot column",
    "text": "3.1 Uniprot column\nSelected text column that contains the Uniprot identifiers (default: first text column in the matrix)."
  },
  {
    "objectID": "kinasesubstraterelations.html#sequence-window",
    "href": "kinasesubstraterelations.html#sequence-window",
    "title": "Kinase-substrate relations",
    "section": "3.2 Sequence window",
    "text": "3.2 Sequence window\nSelected text column that contains the sequence windows around the sites (default: first text column in the matrix)."
  },
  {
    "objectID": "addsequencefeatures.html",
    "href": "addsequencefeatures.html",
    "title": "Add sequence features",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Modifications\nSource code: AddSequenceFeatures.cs"
  },
  {
    "objectID": "addsequencefeatures.html#proteins",
    "href": "addsequencefeatures.html#proteins",
    "title": "Add sequence features",
    "section": "3.1 Proteins",
    "text": "3.1 Proteins\nSelected text column containing the Uniprot IDs (default: first text column of the matrix)."
  },
  {
    "objectID": "addsequencefeatures.html#positions-within-proteins",
    "href": "addsequencefeatures.html#positions-within-proteins",
    "title": "Add sequence features",
    "section": "3.2 Positions within proteins",
    "text": "3.2 Positions within proteins\nSelected text column containing the positions within the proteins to add site-specific features (default: first text column of the matrix). The column is generated by MaxQuant and is called “Positions”."
  },
  {
    "objectID": "addsequencefeatures.html#add-status-column",
    "href": "addsequencefeatures.html#add-status-column",
    "title": "Add sequence features",
    "section": "3.3 Add status column",
    "text": "3.3 Add status column\nIf checked additional information of Uniprot about the protein sites is added (default: unchecked)."
  },
  {
    "objectID": "addregulatorysites.html",
    "href": "addregulatorysites.html",
    "title": "Add regulatory sites",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Modifications\nSource code: AddRegulatorySites.cs"
  },
  {
    "objectID": "addregulatorysites.html#uniprot-column",
    "href": "addregulatorysites.html#uniprot-column",
    "title": "Add regulatory sites",
    "section": "3.1 Uniprot column",
    "text": "3.1 Uniprot column\nSelected text column that contains the UniProt identifiers (default: first text column in the matrix)."
  },
  {
    "objectID": "addregulatorysites.html#sequence-window",
    "href": "addregulatorysites.html#sequence-window",
    "title": "Add regulatory sites",
    "section": "3.2 Sequence window",
    "text": "3.2 Sequence window\nSelected text column that contains the sequence windows around the sites (default: first text column in the matrix)."
  },
  {
    "objectID": "shortenmotifs.html",
    "href": "shortenmotifs.html",
    "title": "Shorten motif length",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Modifications\nSource code: ShortenMotifs.cs"
  },
  {
    "objectID": "shortenmotifs.html#sequence-window",
    "href": "shortenmotifs.html#sequence-window",
    "title": "Shorten motif length",
    "section": "3.1 Sequence window",
    "text": "3.1 Sequence window\nSelected text column that contains the amino acid sequences (default: first text column in the matrix)."
  },
  {
    "objectID": "shortenmotifs.html#start",
    "href": "shortenmotifs.html#start",
    "title": "Shorten motif length",
    "section": "3.2 Start",
    "text": "3.2 Start\nStart position of the newly generated shorter sequences, which are displayed in a new generated text column called “Short sequence window” (default: 6). The flanks will be measured with respect to this position.\nHint: Start + Length cannot exceed the length of any protein sequence in the selected text column."
  },
  {
    "objectID": "shortenmotifs.html#length",
    "href": "shortenmotifs.html#length",
    "title": "Shorten motif length",
    "section": "3.3 Length",
    "text": "3.3 Length\nLength of the newly generated sequences (default: 11). Flanking regions of this length will be kept surrounding the central position."
  },
  {
    "objectID": "genericclusteringproc.html",
    "href": "genericclusteringproc.html",
    "title": "Generic clustering",
    "section": "",
    "text": "Type: - Matrix Processing\nHeading: - Clustering\nSource code: not public."
  },
  {
    "objectID": "genericclusteringproc.html#method",
    "href": "genericclusteringproc.html#method",
    "title": "Generic clustering",
    "section": "3.1 Method",
    "text": "3.1 Method\nSelected method that should be applied to cluster the data (default: K-means). The result will be displayed in newly generated categorical column named “Clusters”."
  },
  {
    "objectID": "genericclusteringproc.html#number-of-clusters",
    "href": "genericclusteringproc.html#number-of-clusters",
    "title": "Generic clustering",
    "section": "3.2 Number of clusters",
    "text": "3.2 Number of clusters\nDefines the number of clusters the data should be clustered into (default: 10)."
  },
  {
    "objectID": "scatterplotanalysis.html",
    "href": "scatterplotanalysis.html",
    "title": "Scatter plot analysis",
    "section": "",
    "text": "Type: - Matrix Analysis\nHeading: - Visualization\nSource code: not public."
  },
  {
    "objectID": "scatterplotanalysis.html#matrix-access",
    "href": "scatterplotanalysis.html#matrix-access",
    "title": "Scatter plot analysis",
    "section": "3.1 Matrix access",
    "text": "3.1 Matrix access\nSpecifies whether columns (default) or rows are plotted against each other."
  },
  {
    "objectID": "profileplot.html",
    "href": "profileplot.html",
    "title": "Profile plot",
    "section": "",
    "text": "1 General\n\nType: - Matrix Analysis\nHeading: - Visualization\nSource code: not public.\n\n\n\n2 Brief description\nDisplay each row of the matrix as a quantitative profile with each column defining a data point. Profiles can be queried by similarity to a reference profile.\n\n\n\n3 Parameters\n“Profile plot” has no parameters."
  },
  {
    "objectID": "histogram.html",
    "href": "histogram.html",
    "title": "Histogram",
    "section": "",
    "text": "Type: - Matrix Analysis\nHeading: - Visualization\nSource code: not public."
  },
  {
    "objectID": "histogram.html#columns",
    "href": "histogram.html#columns",
    "title": "Histogram",
    "section": "3.1 Columns",
    "text": "3.1 Columns\nSelected expression columns, whose values get displayed in separate histograms (default: all expression columns are selected)."
  },
  {
    "objectID": "multiscatteranalysis.html",
    "href": "multiscatteranalysis.html",
    "title": "Multi scatter plot",
    "section": "",
    "text": "Type: - Matrix Analysis\nHeading: - Visualization\nSource code: not public."
  },
  {
    "objectID": "multiscatteranalysis.html#rows",
    "href": "multiscatteranalysis.html#rows",
    "title": "Multi scatter plot",
    "section": "3.1 Rows",
    "text": "3.1 Rows\nFirst partner(s) of the respective multi scatter plot(s). Selected expression columns that will appear in y-direction in the resulting multi scatter plot. (default: all expression columns are selected)."
  },
  {
    "objectID": "multiscatteranalysis.html#columns",
    "href": "multiscatteranalysis.html#columns",
    "title": "Multi scatter plot",
    "section": "3.2 Columns",
    "text": "3.2 Columns\nSecond partner(s) of the respective multi scatter plot(s). Selected expression columns that will appear in x-direction in the resulting multi scatter plot. (default: all expression columns are selected)."
  },
  {
    "objectID": "scatterplot3danalysis.html",
    "href": "scatterplot3danalysis.html",
    "title": "3D plot",
    "section": "",
    "text": "1 General\n\nType: - Matrix Analysis\nHeading: - Visualization\nSource code: not public.\n\n\n\n2 Brief description\nPlot three columns or three rows against each other as x, y and z values in a scatter plot.\n\n\n\n3 Parameters\n“3D plot” has no parameters."
  },
  {
    "objectID": "hierarchicalcluster.html",
    "href": "hierarchicalcluster.html",
    "title": "Hierarchical clustering",
    "section": "",
    "text": "Type: - Matrix Analysis\nHeading: - Clustering/PCA\nSource code: not public."
  },
  {
    "objectID": "hierarchicalcluster.html#row-tree",
    "href": "hierarchicalcluster.html#row-tree",
    "title": "Hierarchical clustering",
    "section": "3.1 Row tree",
    "text": "3.1 Row tree\nIf checked rows will be clustered and a tree (dendrogram) is generated (default: checked).\n\n3.1.1 Distance\nSelected distance that will be used for the clustering process (default: Euclidean). The distance can be selected from a predefined list:\n\nEuclidean\nL1\nMaximum\nLp\nPearson correlation\nSpearman correlation\nCosine\nCanberra\n\n\n\n3.1.2 Linkage\nSelected clustering method that will be applied (default: Average). It can be selected from a predefined list:\n\nAverage\nComplete\nSingle\n\n\n\n3.1.3 Constraint\nSelected constraint that should be preserved from the input data (default: None). The used constraint can be selected from a predefined list of constraints:\n\nNone\nPreserve order\nPreserve order (periodic)\n\n\n\n3.1.4 Preprocess with k-means\nSpecifies, whether the data should be pre-processed using k-means before applying clustering and generating a heatmap (default: checked).\n\n\n3.1.5 Number of clusters\nThis parameter is just relevant, if the parameter “Preprocess with k-means” is checked. Defines the number of clusters that will be created by the k-means algorithm (default: 300)."
  },
  {
    "objectID": "hierarchicalcluster.html#column-tree",
    "href": "hierarchicalcluster.html#column-tree",
    "title": "Hierarchical clustering",
    "section": "3.2 Column tree",
    "text": "3.2 Column tree\nIf checked, columns will be clustered and a tree (dendrogram) is generated (default: checked).\n\n3.2.1 Distance\nSelected distance that will be used for the clustering process (default: Euclidean). The distance can be selected from a predefined list:\n\nEuclidean\nL1\nMaximum\nLp\nPearson correlation\nSpearman correlation\n\n\n\n3.2.2 Linkage\nSelected clustering method that will be applied (default: Average). It can be selected from a predefined list:\n\nAverage\nComplete\nSingle\n\n\n\n3.2.3 Constraint\nSelected constraint that should be preserved from the input data (default: None). The used constraint can be selected from a predefined list of constraints:\n\nNone\nPreserve order\nPreserve order (periodic)\nPreserve grouping\n\n\n\n3.2.4 Preprocess with k-means\nSpecifies, whether the data should be pre-processed using k-means before applying clustering and generating a heatmap (default: checked).\n\n\n3.2.5 Number of clusters\nThis parameter is just relevant, if the parameter “Preprocess with k-means” is checked. Defines the number of clusters that will be created by the k-means algorithm (default: 300)."
  },
  {
    "objectID": "hierarchicalcluster.html#which-columns-to-use",
    "href": "hierarchicalcluster.html#which-columns-to-use",
    "title": "Hierarchical clustering",
    "section": "3.3 Which columns to use",
    "text": "3.3 Which columns to use\nList of all expression/numerical columns in the data set (default: all numerical columns; the expression columns are selected see parameter “Use for clustering”)."
  },
  {
    "objectID": "hierarchicalcluster.html#use-for-clustering",
    "href": "hierarchicalcluster.html#use-for-clustering",
    "title": "Hierarchical clustering",
    "section": "3.4 Use for clustering",
    "text": "3.4 Use for clustering\nSelected expression/numerical columns that should be used for the clustering (default: all expression columns are selected)."
  },
  {
    "objectID": "hierarchicalcluster.html#display-in-heat-map-but-do-not-use-for-clustering",
    "href": "hierarchicalcluster.html#display-in-heat-map-but-do-not-use-for-clustering",
    "title": "Hierarchical clustering",
    "section": "3.5 Display in heat map but do not use for clustering",
    "text": "3.5 Display in heat map but do not use for clustering\nSelected expression/numerical columns that should be displayed in the output heat map, but are not used for the clustering (default: empty)."
  },
  {
    "objectID": "principalcomponentanalysis.html",
    "href": "principalcomponentanalysis.html",
    "title": "Principle component analysis",
    "section": "",
    "text": "Type: - Matrix Analysis\nHeading: - Clustering/PCA\nSource code: not public."
  },
  {
    "objectID": "principalcomponentanalysis.html#category-enrichment-in-components",
    "href": "principalcomponentanalysis.html#category-enrichment-in-components",
    "title": "Principle component analysis",
    "section": "3.1 Category enrichment in components",
    "text": "3.1 Category enrichment in components\nSpecifies, whether each term in all categorical columns will be tested for enrichment at high or low values in the loadings for the first few components (default: unchecked).\n\n3.1.1 Number of components\nThis parameter is just relevant, if the parameter “Category enrichment in components” is checked. It specifies the number of principal components that will be used for the transformation (default: 5).\n\n\n3.1.2 Cutoff method\nThis parameter is just relevant, if the parameter “Category enrichment in components” is checked. It defines the method that is used to calculate the cutoff of potential principal components (default: Benjamini-Hochberg FDR) . The method can be selected from a predefined list:\n\nBenjamini-Hochberg FDR\np-value\n\n\n\n3.1.3 Threshold\nThis parameter is just relevant, if the parameter “Category enrichment in components” is checked. It defines the threshold value of the previously specified used cutoff method (default: 0.05).\n\n\n3.1.4 Relative enrichment\nThis parameter is just relevant, if the parameter “Category enrichment in components” is checked. It defines, which categorical column will be used to group rows in the enrichment test (default: &lt;None&gt;). All rows having the same identifier will be counted as one entity in the enrichment test. The main application is for posttranslational modification sites. Then one should select here protein or gene identifiers. This will make sure that multiple sites from the same protein (or gene) are counted only once for the enrichment analysis."
  }
]